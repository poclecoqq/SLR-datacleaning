"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"BB2CURGI","journalArticle","2021","Singh, Shashank; Singh, Shailendra","HINDIA: a deep-learning-based model for spell-checking of Hindi language","Neural Computing and Applications","","09410643","10.1007/s00521-020-05207-9","","The spelling error is a mistake occurred while typing the text document. The applications like search engines, information retrieval, emails, etc., require user typing. In such applications, good spell-checker is essential to rectify the misspelling. Spell-checkers for western languages like English are very powerful and can handle any type of spelling errors, whereas in the case of Indian languages like Hindi, Urdu, Bengali, Kannada, Assamese, etc., the available spell-checkers are very basic ones. These spell-checkers are developed using traditional methods like statistical methods and rule-based methods. This article presents a novel model HINDIA to handle the spelling errors of the Hindi language, one of the most spoken languages in India. It utilizes a deep-learning method for spelling error detection and correction. The proposed spell-checking model works in two phases. In the first phase model identifies the erroneous words in the input sample and in the second phase it replaces the wrong words with the most probable correct words. Model HINDIA is developed using the attention-based encoderdecoder bidirectional recurrent neural network (BiRNN) which uses long short-term memory cells. Several modifications in the BiRNN have been made and network is fine-tuned to process the spelling errors of Hindi language. It uses publicly available dataset monolingual corpus developed by IIT Mumbai for training and testing. The performance of the proposed model is evaluated in two scenarios. In the first scenario where the testing dataset is generated using split function. HINDIA performs significantly well with precision 0.86, recall 0.72, f-measure 0.78 and accuracy 0.80. Further, in the second scenario, where a dataset is manually generated its performance is fairly good with precision 0.81, recall 0.72, f-measure 0.76 and accuracy 0.74. Model HINDIA gives better performance than the deep-learning-based Malayalam spell-checker and some other deep-learning-based correction models present in the literature.  2020, Springer-Verlag London Ltd., part of Springer Nature.","2021","2022-06-10 02:10:49","2022-08-10 19:20:14","","3825-3840","","8","33","","Neural Computing and Applications","","","","","","","","","","","","","","","Publisher: Springer Science and Business Media Deutschland GmbH","","","http://dx.doi.org/10.1007/s00521-020-05207-9","Long short-term memory; Learning systems; Recurrent neural networks; Errors; Statistical tests; Search engines; Spell-checker, Encoder–decoder recurrent neural network, Long short-term memory, Spelling, Deep-learning; ACTIVITY RECOGNITION; Deep-learning; Encoder-decoder recurrent neural network; SENSORS; Spell-checker; Spelling; Long short-term memory, Encoder–decoder recurrent neural network, Spelling, Spell-checker, Deep-learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YKP3HGNR","book","2019","Ilyas, Ihab F.; Chu, Xu","Data Cleaning","","978-1-4503-7152-0","","","","","2019","2022-06-10 02:42:54","2022-08-10 19:16:51","","","","","","","","","","","","","Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4DEWVPN9","conferencePaper","2017","Vu, HT; Huang, CC","A multi-task convolutional neural network with spatial transform for parking space detection","2017 IEEE International Conference on …","","","","https://ieeexplore.ieee.org/abstract/document/8296584/","… To overcome these problems, we propose a deep learning framework to infer the parking status … The results show our system can reduce the error detection rate and thereby increase …","2017","2022-07-29 19:21:54","2022-08-10 19:12:56","","","","","","","","","","","","","ieeexplore.ieee.org","","","","","","","","","","","","http://dx.doi.org/10.1109/ICIP.2017.8296584","Deep learning; Convolutional neural networks; Convolution; Image processing; Lighting","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G2FGHHR2","conferencePaper","2016","DiTomaso, D; Boraten, T; Kodi, A; ...","Dynamic error mitigation in NoCs using intelligent prediction techniques","2016 49th Annual IEEE …","","","","https://ieeexplore.ieee.org/abstract/document/7783734/","… We propose to utilize machine learning techniques to train a decision tree which can be … a static single error correction and double error detection (SECDED) technique resulting in an …","2016","2022-07-29 19:22:06","2022-08-10 19:18:32","","","","","","","","","","","","","ieeexplore.ieee.org","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZBRN8LKH","conferencePaper","2019","Doggett, EV; Wolak, AMC; Tsatsoulis, PD; ...","Neural pixel error detection","ACM SIGGRAPH 2019 …","","","10.1145/3306307.3328197","https://dl.acm.org/doi/abs/10.1145/3306307.3328197","… In sum, we show that simple neural network methods such as autoencoders can perform admirably for real-world production QC tasks, improving scalability for a studio QC workflow. …","2019","2022-07-29 20:06:18","2022-08-10 20:38:08","","","","","","","","","","","","","dl.acm.org","","","","","","","","","","","","http://dx.doi.org/10.1145/3306307.3328197","Anomaly detection; Machine learning; Neural networks; Quality control; Error detection; Pixels; Interactive computer graphics; Machinery; pixel errors, quality control, video, neural networks, anomaly detection, autoencoder","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"99IVZLFL","journalArticle","2020","Alkhatib, M; Monem, AA; Shaalan, K","Deep learning for Arabic error detection and correction","ACM Transactions on Asian and …","","","10.1145/3373266","https://dl.acm.org/doi/abs/10.1145/3373266","… In this article, we present how neural network models can be … novel deep learning framework for performing error detection … For developing a computational spelling error detection and …","2020","2022-07-29 20:07:25","2022-08-10 19:17:52","","","","Query date: 2022-07-28 20:03:59","","","","","","","","","","","","","","","","","","Publisher: dl.acm.org","","","http://dx.doi.org/10.1145/3373266","Deep learning; Error detection; Deep neural networks; Natural language processing systems; error correction, word embedding, bidirectional long short-term memory, Error detection, polynomial network classifier","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H2RA6JGG","conferencePaper","2020","Fu, EY; Yang, Z; Leong, HV; Ngai, G; Do, C; ...","Exploiting Active Learning in Novel Refractive Error Detection with Smartphones","Proceedings of the 28th …","","","10.1145/3394171.3413748","https://dl.acm.org/doi/abs/10.1145/3394171.3413748","… lutional Neural Network features encoding information of human eyes from pre-trained gaze estimation model. This enables more effective training on refractive error detection models …","2020","2022-07-29 20:07:30","2022-08-10 19:19:23","","","","","","","","","","","","","dl.acm.org","","","","","","","","","","","","http://dx.doi.org/10.1145/3394171.3413748","Learning systems; Error detection; Convolutional neural networks; Labeled data; Smartphones; Image processing; Ophthalmology; mobile heathcare, computer-aided diagnosis, vision screening, active learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7RSRZY7Q","book","2020","Chen, X","Approximate and Bit-Width Configurable Arithmetic Logic Unit Design for Deep Learning Accelerator","","","","","https://search.proquest.com/openview/777cbe2c13c2a611b65186d2f27aae91/1?pq-origsite=gscholar&cbl=51922&diss=y","… An efficient error detection and correction block is designed … deep learning applications in a more energy efficient way. This section provided an overview of prior work on deep learning …","2020","2022-07-29 20:07:55","2022-08-10 19:14:17","","","","","","","","","","Query date: 2022-07-28 20:03:59","","","search.proquest.com","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YRAYD5II","conferencePaper","2020","Zhang, L; Zheng, T; Xue, J","Error Heuristic Based Text-Only Error Correction Method for Automatic Speech Recognition","International Conference on Neural Information …","","","10.1007/978-3-030-63830-6_62","https://link.springer.com/chapter/10.1007/978-3-030-63830-6_62","… With the fast development of deep learning, automatic … error knowledge from an error detection model as a heuristic to … due to the development of deep learning. Although the accuracy …","2020","2022-07-29 20:08:04","2022-08-10 19:19:21","","","","","","","","","","","","","Springer","","","","","","","","","","","","http://dx.doi.org/10.1007/978-3-030-63830-6_62","Deep learning; Error correction; Speech recognition; Heuristic methods; Transfer learning; Character recognition; Transfer learning, ASR error detection, Error heuristic, ASR error correction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HYQP8V9A","journalArticle","2021","He, Z","English grammar error detection using recurrent neural networks","Scientific Programming","","","","https://www.hindawi.com/journals/sp/2021/7058723/","… error detection [11–13], this paper proposes a grammatical error detection method [14–17] based on deep learning [18… (1) is article uses the recurrent neural network technology to solve …","2021","2022-07-29 20:08:57","2022-08-10 19:18:41","","","","Query date: 2022-07-28 18:03:11","","","","","","","","","","","","","","","","","","Publisher: hindawi.com","","","http://dx.doi.org/10.1155/2021/7058723","Long short-term memory; Error detection; Encoding (symbols); Disasters; Vector spaces","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8LVSRULP","journalArticle","2021","He, Y","Automatic Detection of Grammatical Errors in English Verbs Based on RNN Algorithm: Auxiliary Objectives for Neural Error Detection Models","Computational Intelligence and Neuroscience","","","","https://www.hindawi.com/journals/cin/2021/6052873/","… On this basis, in order to propose a more reliable and accurate method, this study explores an automatic grammar error detection method based on recurrent neural network (RNN), and …","2021","2022-07-29 20:08:58","2022-08-10 19:15:01","","","","Query date: 2022-07-28 18:03:11","","","","","","","","","","","","","","","","","","Publisher: hindawi.com","","","http://dx.doi.org/10.1155/2021/6052873","Recurrent neural networks; Error detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8ZWE2V3H","journalArticle","2021","Liu, W; Chang, CH","A Forward Error Compensation Approach for Fault Resilient Deep Neural Network Accelerator Design","Proceedings of the 5th Workshop on Attacks and …","","","10.1145/3474376.3487281","https://dl.acm.org/doi/abs/10.1145/3474376.3487281","… the threats on deployed deep neural network (DNN) systems … noise-tolerance of neural network models to resist random … shadow flip flops for error detection and lightweight circuit for …","2021","2022-07-29 20:09:04","2022-08-10 20:37:43","","","","Query date: 2022-07-28 18:03:11","","","","","","","","","","","","","","","","","","Publisher: dl.acm.org","","","","deep neural network accelerator, hardware security, fault injection attack","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EQN84426","conferencePaper","2021","Ma, YS; Yoo, S; Kim, T","Selecting test inputs for DNNs using differential testing with subspecialized model instances","Proceedings of the 29th ACM Joint Meeting on …","","","10.1145/3468264.3473131","https://dl.acm.org/doi/abs/10.1145/3468264.3473131","… Interestingly, our approach shows the highest error detection rate for ResNet, which is the model … We expect unsupervised learning to be a good fit, as it can be applied even in cases in …","2021","2022-07-29 20:09:07","2022-08-10 20:38:47","","","","","","","","","","","","","dl.acm.org","","","","","","","","","","","","http://dx.doi.org/10.1145/3468264.3473131","Deep learning; Testing; Diffrential Testing, Test Oracle, Machine Learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7J66CHI5","conferencePaper","2021","Chawla, J; Thakurdesai, N; Godase, A; ...","Error Diagnosis of Deep Monocular Depth Estimation Models","2021 IEEE/RSJ …","","","","https://ieeexplore.ieee.org/abstract/document/9636673/","… We propose error diagnosis methods for the depth maps produced by deep neural network-based techniques. First, we propose an error diagnostic method – Depth Error Detection …","2021","2022-07-29 20:09:12","2022-08-10 20:37:45","","","","","","","","","","","","","ieeexplore.ieee.org","","","","","","","","","","","","http://dx.doi.org/10.1109/IROS51168.2021.9636673","Deep learning; Error detection; Error correction; Computer vision","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A2BBJ9GV","journalArticle","2021","Eshky, A; Cleland, J; Ribeiro, MS; Sugden, E; ...","Automatic audiovisual synchronisation for ultrasound tongue imaging","Speech …","","","","https://www.sciencedirect.com/science/article/pii/S0167639321000583","… in order to find the thresholds for error detection. We use these … by a self-supervised neural network, exploiting the correlation … Our approach used a self-supervised neural network which …","2021","2022-07-29 20:09:13","2022-08-10 19:14:47","","","","Query date: 2022-07-28 18:03:11","","","","","","","","","","","","","","","","","","Publisher: Elsevier","","","","Automatic audiovisual synchronisation; Synchronisation error tolerance; Ultrasound tongue imaging; Automatic audiovisual synchronisation, Synchronisation error tolerance, Ultrasound tongue imaging","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2IALBN8S","journalArticle","2022","Zhao, J; Yan, J; Xue, T; Wang, S; Qiu, X; Yao, X; ...","A deep learning method for oriented and small wheat spike detection (OSWSDet) in UAV images","… and Electronics in …","","","","https://www.sciencedirect.com/science/article/pii/S0168169922004045","… Along with various technological developments, deep-learning-based methods have … cause error detection and miss detection problems. This paper proposes a deep learning method …","2022","2022-07-29 20:11:18","2022-08-10 19:12:35","","","","Query date: 2022-07-28 19:22:13","","","","","","","","","","","","","","","","","","Publisher: Elsevier","","","http://dx.doi.org/10.1016/j.compag.2022.107087","Deep learning; Error detection; Aircraft detection; Unmanned aerial vehicles (UAV); Antennas; YOLOv5; Orientation feature; Unmanned aerial vehicle (UAV); Wheat spike detection; YOLOv5, Orientation feature, Unmanned aerial vehicle (UAV), Wheat spike detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"97SJIUFX","journalArticle","2022","Wu, F; Huang, S; Cheng, L","Analyzing the Application of Multimedia Technology Assisted English Grammar Teaching in Colleges","Scientific Programming","","","","https://www.hindawi.com/journals/sp/2022/4422754/","… deep learning is applied to English grammar error detection … In English syntax error detection, the error detection model … of iterations seriously affects the error detection effect, and the …","2022","2022-07-29 20:11:21","2022-08-10 19:14:05","","","","Query date: 2022-07-28 19:22:13","","","","","","","","","","","","","","","","","","Publisher: hindawi.com","","","http://dx.doi.org/10.1155/2022/4422754","Long short-term memory; Error detection; Multimedia systems; Efficiency; Teaching; Multilayers","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y7RTG6J3","journalArticle","2022","Wang, K","Machine Learning Enabled Design Framework for High-Performance, Energy-Efficient, Fault-Tolerant, and Secure On-Chip Communication","","","","","https://search.proquest.com/openview/d97ebdcd2a08e29dd68a3468402a34ec/1?pq-origsite=gscholar&cbl=18750&diss=y","… error detection and correction techniques. We propose a proactive NoC design to optimize fault-tolerance and performance with reinforcement learning … -router error detection/correction …","2022","2022-07-29 20:11:42","2022-08-10 20:37:59","","","","Query date: 2022-07-28 19:22:13","","","","","","","","","","","","","","","","","","Publisher: search.proquest.com","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KPU6HE8T","journalArticle","2021","Zheng, Changmeng; Wu, Zhiwei; Wang, Tao; Cai, Yi; Li, Qing","Object-Aware Multimodal Named Entity Recognition in Social Media Posts with Adversarial Learning","IEEE Transactions on Multimedia","","15209210","10.1109/TMM.2020.3013398","","Named Entity Recognition (NER) in social media posts is challenging since texts are usually short and contexts are lacking. Most recent works show that visual information can boost the NER performance since images can provide complementary contextual information for texts. However, the image-level features ignore the mapping relations between fine-grained visual objects and textual entities, which results in error detection in entities with different types. To better exploit visual and textual information in NER, we propose an adversarial gated bilinear attention neural network (AGBAN). The model jointly extracts entity-related features from both visual objects and texts, and leverages an adversarial training to map two different representations into a shared representation. As a result, domain information contained in an image can be transferred and applied for extracting named entities in the text associated with the image. Experimental results on Tweets dataset demonstrate that our model outperforms the state-of-the-art methods. Moreover, we systematically evaluate the effectiveness of the proposed gated bilinear attention network in capturing the interactions of mutimodal features visual objects and textual words. Our results indicate that the adversarial training can effectively exploit commonalities across heterogeneous data sources, which leads to improved performance in NER when compared to models purely exploiting text data or combining the image-level visual features.  1999-2012 IEEE.","2021","2022-08-10 17:41:34","2022-08-10 19:22:24","","2520-2532","","","23","","IEEE Transactions on Multimedia","","","","","","","","","","","","","","","Publisher: Institute of Electrical and Electronics Engineers Inc.","","","http://dx.doi.org/10.1109/TMM.2020.3013398","Natural language processing systems; Social networking (online); Image enhancement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CJ79GBRQ","thesis","2021","Nam, Somang; Penn, Gerald; McCahan, Susan","Towards an Automatic Caption Quality Assessment Model Reflecting the Subjective Views of Deaf, and Hard of Hearing Audiences","","","","","","","2021","2022-08-10 18:30:44","2022-08-10 18:30:44","","","","","","","","","","","","","University of Toronto (Canada)","","","","","","","","","ISBN: 9798496562485","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y8KHT6MC","thesis","2020","Fang, Zhou","Towards Intelligent Clinical Diagnosis and Surveillance with Medical Images and Videos Analysis","","","","","","","2020","2022-08-10 18:30:44","2022-08-10 18:30:44","","","","","","","","","","","","","Hong Kong University of Science and Technology (Hong Kong)","","","","","","","","","ISBN: 9798535514840","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WXD9QRD3","thesis","2022","Karimi, MohammadMahdi; Esterline, Albert; Osareh, Ali; Graves, Corey; Limbrick, Daniel; Bililign, Solomon","Developing Safe Automotive Deep Learning Systems for Image Classification","","","","","","","2022","2022-08-10 18:30:44","2022-08-10 18:30:44","","","","","","","","","","","","","North Carolina Agricultural and Technical State University","","","","","","","","","ISBN: 9798819371282","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y2HK2E2G","conferencePaper","2019","Zhang, Hao; Hong, Xianggong; Zhou, Shifen; Wang, Qingcai","Infrared Image Segmentation for Photovoltaic Panels Based on Res-UNet","Pattern Recognition and Computer Vision: Second Chinese Conference, PRCV 2019, Xi’an, China, November 8–11, 2019, Proceedings, Part I","978-3-030-31653-2","","","https://doi.org/10.1007/978-3-030-31654-9_52","","2019","2022-08-10 18:30:44","2022-08-10 18:30:44","","611–622","","","","","","","","","","","Springer-Verlag","Xi'an, China","","","","","","","","Type: 10.1007/978-3-030-31654-9_52","","","","U-Net, Semantic segmentation, Infrared image, Photovoltaic panels","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EX8IXKLN","journalArticle","2021","Hoyos, William; Aguilar, Jose; Toro, Mauricio","Dengue models based on machine learning techniques: A systematic literature review","Artif. Intell. Med.","","","","https://doi.org/10.1016/j.artmed.2021.102157","","2021","2022-08-10 18:30:44","2022-08-10 18:30:44","","16","","C","119","","","","","","","","","","","","","","","","","ISBN: 0933-3657 Publisher: Elsevier Science Publishers Ltd. Type: 10.1016/j.artmed.2021.102157","","","","Dengue, KNN, HI, WHO, MAE, PSO, APRI, LoR, VEGF, BTS, DSS, TNFα, Machine learning, RMSE, Diagnostic model, IL-1β, SARIMAX, CoI, CI, GBM, SE, LASSO, MSE, SD, ANN, SVM, LiR, MLP, SLR, IL-10, RF, BRT, GLM, SS, Epidemic model, GT, AI, PAF, BI, GAM, AUC, MCS, DT, DNA, CRF, DENV, PRISMA, FL, ALT, Intervention model, GWR, S1P, SOM, OR, CART, DBSI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z37RWXKD","bookSection","2021","Bi, Nifei; Chen, Xiansen; Xu, Chen; Zhou, Aoying","Beamer: An End-to-End Deep Learning Framework for Unifying Data Cleaning in DNN Model Training and Inference","30th ACM International Conference on Information and Knowledge Management, CIKM 2021, November 1, 2021  -  November 5, 2021","","","","","Deep learning has made extraordinary progress in the last few years, focusing on improving the accuracy and speed of standard deep learning benchmarks. Nevertheless, datasets in production environments are often messy, which makes data cleaning crucial for DNN model training and inference. Existing solutions that combine big data processing systems and deep learning systems to accomplish the data cleaning, DNN model training and inference are internally tied to one of Spark or Flink. However, Spark and Flink usually show different performance under batch and stream processing workloads. In order to employ Spark in batch training and Flink in streaming inference, existing solutions incur the burden of maintaining two data cleaning programs. In this demonstration, we showcase Beamer: an end-to-end deep learning framework for unifying the data cleaning program when employing Spark in training and Flink in inference, respectively.  2021 ACM.","2021","2022-06-10 02:09:03","2022-07-31 14:46:16","","4685-4689","","","","","","","International Conference on Information and Knowledge Management, Proceedings","","","","Association for Computing Machinery","Virtual, Online, Australia","","","","","","","","","","","http://dx.doi.org/10.1145/3459637.3481977","Batch data processing; Big data; Cleaning; Data handling; Deep learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A9SYXK2D","conferencePaper","2019","Li, Pei; Dai, Chaofan; Wang, Wenqian","Application of attribute correlation in unsupervised data cleaning","5th International Conference on e-Society, e-Learning and e-Technologies, ICSLT 2019, January 10, 2019  -  January 12, 2019","","","10.1145/3312714.3312717","","Referring to the supervised learning and unsupervised learning in machine learning, we divide the data cleaning processes into supervised and unsupervised two forms too, and then, we reclassify the data quality problems into canonicalization error, redundancy error, strong logic error and weak logic error according to the characteristics of unsupervised cleaning. For the weak logic errors, we propose a repair framework AC-Framework and an algorithm AC-Repair based on the attribute correlation. When repairing, we first establish a priority queue(PQ) for elements to be repaired according to the minimum cost idea and take the corresponding conflict-free data set() as a training set to learn the correlation among attributes. Then, we select the first element in PQ list as the candidate element to repair, and recompute the PQ list after one repair round to improve the efficiency. Finally, in order to prevent the algorithm from endless loops, we set a label flag to mark the repaired elements, in this way, every error element will be repaired at most once. In the experimental part, we compare the AC-Repair algorithm with the interpolation-based repair algorithm to verify its validity.  2019 Association for Computing Machinery.","2019","2022-06-10 02:09:05","2022-07-31 15:40:53","","45-51","","","","","","","ACM International Conference Proceeding Series","","","","Association for Computing Machinery","Vienna, Austria","","","","","","","","","","","http://dx.doi.org/10.1145/3312714.3312717","Cleaning; Machine learning; Learning systems; Computer circuits; E-learning; Errors; machine learning; weak logic errors, attribute correlation, Unsupervised data cleaning, minimum repair cost, machine learning; attribute correlation; minimum repair cost; Unsupervised data cleaning; weak logic errors; attribute correlation, machine learning, minimum repair cost, Unsupervised data cleaning, weak logic errors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2DJNNQT4","conferencePaper","2021","Schneider, Nicole R.; Samet, Hanan","Which portland is it?: A machine learning approach","5th ACM SIGSPATIAL International Workshop on Location-Based Recommendations, Geosocial Networks and Geoadvertising, LocalRec 2021, November 2, 2021","","","10.1145/3486183.3491066","","This paper reviews several approaches to the problem of toponym resolution for news articles referring to 'Portland.' We train several models to differentiate between Portland, Maine and Portland, Oregon, generating features using only the text of the articles. The data used is in the form of articles pulled from NewsStand. The labels, which are provided by NewsStand's interpretation of the articles, allow for a supervised learning approach. We apply Natural Language Processing (NLP) and data cleaning techniques to process the article data, perform feature reduction, and then feed the data to the models. We show that the logistic regression model performs the best of the four models that we test. We also demonstrate that this model learns a more robust representation of the two classes than the other three models do.  2021 ACM.","2021","2022-06-10 02:09:07","2022-07-31 03:34:49","","49-58","","","","","","","Proceedings of the 5th ACM SIGSPATIAL International Workshop on Location-Based Recommendations, Geosocial Networks and Geoadvertising, LocalRec 2021","","","","Association for Computing Machinery, Inc","Virtual, Online, China","","","","","","","","","","","http://dx.doi.org/10.1145/3486183.3491066","Cleaning; Machine learning; Learning algorithms; Open Data; Natural language processing systems; Logistic regression; Geographic information systems; experimental, machine learning, toponym resolution, spatio-textual, geotagging; toponym resolution, machine learning, experimental, spatio-textual, geotagging","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CPZUVM9N","conferencePaper","2021","Feng, Alice","Using electronic health records to accurately predict COVID-19 health outcomes through a novel machine learning pipeline","12th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics, BCB 2021, August 1, 2021  -  August 4, 2021","","","10.1145/3459930.3469490","","Current COVID-19 predictive models primarily focus on predicting the risk of mortality, and rely on COVID-19 specific medical data such as chest imaging after COVID-19 diagnosis. In this project, we developed an innovative supervised machine learning pipeline using longitudinal Electronic Health Records (EHR) to accurately predict COVID-19 related health outcomes including mortality, ventilation, days in hospital or ICU. In particular, we developed unique and effective data processing algorithms, including data cleaning, initial feature screening, vector representation, and feature normalization. Then we trained models using state-of-the-art machine learning strategies combined with different parameter settings and feature selection. Based on routinely collected EHR, our machine learning pipeline not only consistently outperformed those developed by other research groups using the same data set, but also achieved similar mortality prediction accuracy as those trained on medical data available only after COVID-19 diagnosis. In addition, we identified top COVID-19 risk factors, which are consistent with epidemiologic findings.  2021 Owner/Author.","2021","2022-06-10 02:09:10","2022-07-31 15:34:16","","ACM Special Interest Group on Biomedical Computing (SIGBIOM)","","","","","","","Proceedings of the 12th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics, BCB 2021","","","","Association for Computing Machinery, Inc","Virtual, Online, United states","","","","","","","","","","","http://dx.doi.org/10.1145/3459930.3469490","Cleaning; Pipelines; Learning systems; E-learning; Forecasting; Diagnosis; Predictive analytics; Records management; Bioinformatics; Medical imaging; Medical informatics; Supervised learning; machine learning; electronic health record; electronic health record, machine learning, predictive model; predictive model; predictive model, machine learning, electronic health record","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EUH6TJPF","conferencePaper","2016","Krishnan, Sanjay; Franklin, Michael J.; Goldberg, Ken; Wang, Jiannan; Wu, Eugene","ActiveClean: An interactive data cleaning framework for modern machine learning","2016 ACM SIGMOD International Conference on Management of Data, SIGMOD 2016, June 26, 2016  -  July 1, 2016","07308078","","10.1145/2882903.2899409","","Databases can be corrupted with various errors such as missing, incorrect, or inconsistent values. Increasingly, modern data analysis pipelines involve Machine Learning, and the effects of dirty data can be difficult to debug. Dirty data is often sparse, and naive sampling solutions are not suited for high-dimensional models. We propose ActiveClean, a progressive framework for training Machine Learning models with data cleaning. Our framework updates a model iteratively as the analyst cleans small batches of data, and includes numerous optimizations such as importance weighting and dirty data detection. We designed a visual interface to wrap around this framework and demonstrate ActiveClean for a video classification problem and a topic modeling problem.  2016 ACM.","2016","2022-06-10 02:09:39","2022-07-31 15:41:18","","2117-2120","","","26-June-2016","","","","Proceedings of the ACM SIGMOD International Conference on Management of Data","","","","Association for Computing Machinery","San Francisco, CA, United states","","","","","","","","","","","http://dx.doi.org/10.1145/2882903.2899409","Machine learning; machine learning, data cleaning; data cleaning, machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"875VWDES","conferencePaper","2021","Miao, Zhengjie; Li, Yuliang; Wang, Xiaolan","Rotom: A Meta-Learned Data Augmentation Framework for Entity Matching, Data Cleaning, Text Classification, and beyond","2021 International Conference on Management of Data, SIGMOD 2021, June 20, 2021  -  June 25, 2021","07308078","","","","Deep Learning revolutionizes almost all fields of computer science including data management. However, the demand for high-quality training data is slowing down deep neural nets' wider adoption. To this end, data augmentation (DA), which generates more labeled examples from existing ones, becomes a common technique. Meanwhile, the risk of creating noisy examples and the large space of hyper-parameters make DA less attractive in practice. We introduce Rotom, a multi-purpose data augmentation framework for a range of data management and mining tasks including entity matching, data cleaning, and text classification. Rotom features InvDA, a new DA operator that generates natural yet diverse augmented examples by formulating DA as a seq2seq task. The key technical novelty of Rotom is a meta-learning framework that automatically learns a policy for combining examples from different DA operators, whereby combinatorially reduces the hyper-parameters space. Our experimental results show that Rotom effectively improves a model's performance by combining multiple DA operators, even when applying them individually does not yield performance improvement. With this strength, Rotom outperforms the state-of-the-art entity matching and data cleaning systems in the low-resource settings as well as two recently proposed DA techniques for text classification.  2021 ACM.","2021","2022-06-10 02:09:40","2022-07-31 04:29:44","","1303-1316","","","","","","","Proceedings of the ACM SIGMOD International Conference on Management of Data","","","","Association for Computing Machinery","Virtual, Online, China","","","","","","","","","","","http://dx.doi.org/10.1145/3448016.3457258","Cleaning; Deep learning; Classification (of information); Deep neural networks; Information management; Text mining; entity matching, error detection, data augmentation, deep learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HNF2YNUT","journalArticle","2019","Hulsebos, Madelon; Hu, Kevin; Bakker, Michiel; Zgraggen, Emanuel; Satyanarayan, Arvind; Kraska, Tim; Demiralp, Caatay; Hidalgo, Cesar","Sherlock: A deep learning approach to semantic data type detection","","","","","","Correctly detecting the semantic type of data columns is crucial for data science tasks such as automated data cleaning, schema matching, and data discovery. Existing data preparation and analysis systems rely on dictionary lookups and regular expression matching to detect semantic types. However, these matching-based approaches often are not robust to dirty data and only detect a limited number of types.We introduce Sherlock, a multi-input deep neural network for detecting semantic types. We train Sherlock on 686, 765 data columns retrieved from the VizNet corpus by matching 78 semantic types from DBpedia to column headers. We characterize each matched column with 1, 588 features describing the statistical properties, character distributions, word embeddings, and paragraph vectors of column values. Sherlock achieves a support-weighted F1 score of 0.89, exceeding that of machine learning baselines, dictionary and regular expression benchmarks, and the consensus of crowdsourced annotations.  Copyright  2019, The Authors. All rights reserved.","2019","2022-06-10 02:09:41","2022-07-31 04:22:10","","","","","","","","","arXiv","","","","","","","","","","","","","","","","http://dx.doi.org/10.1145/3292500.3330993","Deep learning; Data Science; Deep neural networks; Data mining; Semantics; Computational linguistics; Pattern matching; deep learning; semantic types, tabular data, type detection, deep learning; semantic types; TABLES; Tabular data; type detection; deep learning, type detection, tabular data, semantic types","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ESAZ2WUQ","journalArticle","2022","Li, Gang; Baechler, Gilles; Tragut, Manuel; Li, Yang","Learning to denoise raw mobile UI layouts for improving datasets at scale","","","23318422","","","The layout of a mobile screen is a critical data source for UI design research and semantic understanding of the screen. However, UI layouts in existing datasets are often noisy, have mismatches with their visual representation, or consists of generic or app-specific types that are difficult to analyze and model. In this paper, we propose the CLAY pipeline that uses a deep learning approach for denoising UI layouts, allowing us to automatically improve existing mobile UI layout datasets at scale. Our pipeline takes both the screenshot and the raw UI layout, and annotates the raw layout by removing incorrect nodes and assigning a semantically meaningful type to each node. To experiment with our data-cleaning pipeline, we create the CLAY dataset of 59,555 human-annotated screen layouts, based on screenshots and raw layouts from Rico, a public mobile UI corpus. Our deep models achieve high accuracy with F1 scores of 82.7% for detecting layout objects that do not have a valid visual representation and 85.9% for recognizing object types, which significantly outperforms a heuristic baseline. Our work lays a foundation for creating large-scale high quality UI layout datasets for data-driven mobile UI research and reduces the need of manual labeling efforts that are prohibitively expensive. Copyright  2022, The Authors. All rights reserved.","2022","2022-06-10 02:10:19","2022-07-31 05:40:36","","","","","","","","","arXiv","","","","","","","","","","","","","Publisher: arXiv","","","http://dx.doi.org/10.1145/3491102.3502042","Deep learning; Pipelines; Large dataset; Semantics; Convolutional neural networks; Object detection; Graph neural networks; mobile UI layouts, Graph Neural Networks, Transformers, neural networks, Convolutional Neural Networks, Datasets","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"78EGLADL","conferencePaper","2020","Meduri, Vamsi; Popa, Lucian; Sen, Prithviraj; Sarwat, Mohamed","A Comprehensive Benchmark Framework for Active Learning Methods in Entity Matching","","","","","","Entity Matching (EM) is a core data cleaning task, aiming to identify different mentions of the same real-world entity. Active learning is one way to address the challenge of scarce labeled data in practice, by dynamically collecting the necessary examples to be labeled by an Oracle and refining the learned model (classifier) upon them. In this paper, we build a unified active learning benchmark framework for EM that allows users to easily combine different learning algorithms with applicable example selection algorithms. The goal of the framework is to enable concrete guidelines for practitioners as to what active learning combinations will work well for EM. Towards this, we perform comprehensive experiments on publicly available EM datasets from product and publication domains to evaluate active learning methods, using a variety of metrics including EM quality, #labels and example selection latencies. Our most surprising result finds that active learning with fewer labels can learn a classifier of comparable quality as supervised learning. In fact, for several of the datasets, we show that there is an active learning combination that beats the state-of-the-art supervised learning result. Our framework also includes novel optimizations that improve the quality of the learned model by roughly 9% in terms of F1-score and reduce example selection latencies by up to 10 without affecting the quality of the model. Copyright  2020, The Authors. All rights reserved.","2020","2022-06-10 02:10:20","2022-07-31 15:42:50","","","","","","","","","arXiv","","","","arXiv","","","","","","","","","","","","http://dx.doi.org/10.1145/3318464.3380597","Learning algorithms; Learning systems; Supervised learning; ensembles, query by committee, unified active learning, neural networks, random forests, learner-agnostic selectors, perfect and noisy oracles, margin, learner-aware selectors, entity matching, SVM, example selectors, blocking dimensions, rule-based models; RULES; example selectors, blocking dimensions, entity matching, learner-aware selectors, learner-agnostic selectors, SVM, neural networks, query by committee, margin, ensembles, unified active learning, rule-based models, perfect and noisy oracles, random forests","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T74RD868","journalArticle","2022","Thirumuruganathan, Saravanan; Kunjir, Mayuresh; Ouzzani, Mourad; Chawla, Sanjay","Automated Annotations for AI Data and Model Transparency","Journal of Data and Information Quality","","19361955","10.1145/3460000","","The data and Artificial Intelligence revolution has had a massive impact on enterprises, governments, and society alike. It is fueled by two key factors. First, data have become increasingly abundant and are often available openly. Enterprises have more data than they can process. Governments are spearheading open data initiatives by setting up data portals such as data.gov and releasing large amounts of data to the public. Second, AI engineering development is becoming increasingly democratized. Open source frameworks have enabled even an individual developer to engineer sophisticated AI systems. But with such ease of use comes the potential for irresponsible use of data.Ensuring that AI systems adhere to a set of ethical principles is one of the major problems of our age. We believe that data and model transparency has a key role to play in mitigating the deleterious effects of AI systems. In this article, we describe a framework to synthesize ideas from various domains such as data transparency, data quality, data governance among others to tackle this problem. Specifically, we advocate an approach based on automated annotations (of both data and the AI model), which has a number of appealing properties. The annotations could be used by enterprises to get visibility of potential issues, prepare data transparency reports, create and ensure policy compliance, and evaluate the readiness of data for diverse downstream AI applications. We propose a model architecture and enumerate its key components that could achieve these requirements. Finally, we describe a number of interesting challenges and opportunities.  2021 Association for Computing Machinery.","2022","2022-06-10 02:10:20","2022-07-31 14:53:42","","","","1","14","","Journal of Data and Information Quality","","","","","","","","","","","","","","","Publisher: Association for Computing Machinery","","","http://dx.doi.org/10.1145/3460000","Machine learning; Open Data; Ethical technology; Transparency; machine learning; data cleaning; Data transparency, machine learning, data cleaning; Data transparency; Data transparency, data cleaning, machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KRDIWS9S","journalArticle","2020","Lin, Yiming; Jiang, Daokun; Yus, Roberto; Bouloukakis, Georgios; Chio, Andrew; Mehrotra, Sharad; Venkatasubramanian, Nalini","LOCATER: Cleaning WiFi Connectivity Datasets for Semantic Localization","","","23318422","","","This paper explores the data cleaning challenges that arise in using WiFi connectivity data to locate users to semantic indoor locations such as buildings, regions, rooms. WiFi connectivity data consists of sporadic connections between devices and nearby WiFi access points (APs), each of which may cover a relatively large area within a building. Our system, entitled semantic LOCATion cleanER (LOCATER), postulates semantic localization as a series of data cleaning tasks - first, it treats the problem of determining the AP to which a device is connected between any two of its connection events as a missing value detection and repair problem. It then associates the device with the semantic subregion (e.g., a conference room in the region) by postulating it as a location disambiguation problem. LOCATER uses a bootstrapping semi-supervised learning method for coarse localization and a probabilistic method to achieve finer localization. The paper shows that LOCATER can achieve significantly high accuracy at both the coarse and fine levels. Copyright  2020, The Authors. All rights reserved.","2020","2022-06-10 02:10:21","2022-07-31 05:36:38","","","","","","","","","arXiv","","","","","","","","","","","","","Publisher: arXiv","","","http://dx.doi.org/10.14778/3430915.3430923","Cleaning; Learning systems; Semantics; Supervised learning; Semi-supervised learning; Wireless local area networks (WLAN); Location; IMPUTATION; INDOOR LOCALIZATION; SCHEME","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XV5NPECK","journalArticle","2018","Rezig, El Kindi; Cao, Lei; Stonebraker, Michael; Simonini, Giovanni; Tao, Wenbo; Madden, Samuel; Ouzzani, Mourad; Tang, Nan; Elmagarmid, Ahmed K.","Data civilizer 2.0: A holistic framework for data preparation and analytics","45th International Conference on Very Large Data Bases, VLDB 2019, August 26, 2017  -  August 30, 2017","","","10.14778/3352063.3352108","","Data scientists spend over 80% of their time (1) parameter-tuning machine learning models and (2) iterating between data cleaning and machine learning model execution. While there are existing efforts to support the first requirement, there is currently no integrated workflow system that couples data cleaning and machine learning development. The previous version of Data Civilizer was geared towards data cleaning and discovery using a set of pre-defined tools. In this paper, we introduce Data Civilizer 2.0, an end-to-end workflow system satisfying both requirements. In addition, this system also supports a sophisticated data debugger and a workflow visualization system. In this demo, we will show how we used Data Civilizer 2.0 to help scientists at the Massachusetts General Hospital build their cleaning and machine learning pipeline on their 30TB brain activity dataset.  2019 VLDB Endowment.","2018","2022-06-10 02:10:21","2022-07-31 03:01:00","","1954-1957","","12","12","","","","Proceedings of the VLDB Endowment","","","","","","","","","","","","","","","","http://dx.doi.org/10.14778/3352063.3352108","Brain; Cleaning; Machine learning; Data visualization; Program debugging","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"23GCE7VX","journalArticle","2020","Karla, Bojan; Li, Peng; Wu, Renzhi; Gurel, Nezihe Merve; Chu, Xu; Wu, Wentao; Zhang, Ce","Nearest neighbor classifiers over incomplete information: From certain answers to certain predictions","","","23318422","","","Machine learning (ML) applications have been thriving recently, largely attributed to the increasing availability of data. However, inconsistency and incomplete information are ubiquitous in real-world datasets, and their impact on ML applications remains elusive. In this paper, we present a formal study of this impact by extending the notion of Certain Answers for Codd tables, which has been explored by the database research community for decades, into the field of machine learning. Specifically, we focus on classification problems and propose the notion of ""Certain Predictions"" (CP) - a test data example can be certainly predicted (CP'ed) if all possible classifiers trained on top of all possible worlds induced by the incompleteness of data would yield the same prediction. We study two fundamental CP queries: (Q1) checking query that determines whether a data example can be CP'ed; and (Q2) counting query that computes the number of classifiers that support a particular prediction (i.e., label). Given that general solutions to CP queries are, not surprisingly, hard without assumption over the type of classifier, we further present a case study in the context of nearest neighbor (NN) classifiers, where efficient solutions to CP queries can be developed - we show that it is possible to answer both queries in linear or polynomial time over exponentially many possible worlds. We demonstrate one example use case of CP in the important application of ""data cleaning for machine learning (DC for ML)."" We show that our proposed CPClean approach built based on CP can often significantly outperform existing techniques in terms of classification accuracy with mild manual cleaning effort. Copyright  2020, The Authors. All rights reserved.","2020","2022-06-10 02:10:22","2022-07-31 05:11:28","","","","","","","","","arXiv","","","","","","","","","","","","","Publisher: arXiv","","","http://dx.doi.org/10.14778/3430915.3430917","Cleaning; Machine learning; Classification (of information); Forecasting; Query processing; Nearest neighbor search; Polynomial approximation; MULTIPLE IMPUTATION; MISSING DATA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J8KC4IP3","conferencePaper","2021","Haruna, Charles Roland; Yang, Jian; Hou, Meng Shu; Gou, Lei; Fan, Shu Huan; Eghan-Yartel, Barbie","Incorporating Knowledge Bases and Databases to an Effective Repair of Data Errors","5th International Conference on Compute and Data Analysis, ICCDA 2021, February 2, 2021  -  February 4, 2021","","","10.1145/3456529.3456536","","In data warehousing and integration, data error repairs are very important. Some existing techniques tend to fix data errors using machine learning, statistics, integrity constraints, while others use multiple iterations to find data errors and a long time to repair them. Researches have shown the data cleaning accuracy is not efficient using those techniques. Thus to improve the accuracy, some works provided mechanisms employing knowledge bases (kbs) and crowdsourcing platforms, but using only single tables to achieve that. In this work a data error repair mechanism is proposed, which involves the use of a knowledge base on an entire database system having common attributes among its tables. Thorough experiments showed the effectiveness of the mechanism, with results showing the proposed technique is more efficient and effective using the whole database as compared to data repairs done on single tables.  2021 ACM.","2021","2022-06-10 02:10:24","2022-07-31 05:56:00","","36-45","","","","","","","ACM International Conference Proceeding Series","","","","Association for Computing Machinery","Sanya, China","","","","","","","","","","","http://dx.doi.org/10.1145/3456529.3456536","Data handling; Errors; Knowledge based systems; Information analysis; Data warehouses; Data quality, Database., Knowledge Base, Data Error Repair; Database., Knowledge Base, Data quality, Data Error Repair","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GAUCSV7K","journalArticle","2022","Sun, Zhensu; Li, Li; Liu, Yan; Du, Xiaoning; Li, Li","On the importance of building high-quality training datasets for neural code search","","","23318422","","","The performance of neural code search is significantly influenced by the quality of the training data from which the neural models are derived. A large corpus of high-quality query and code pairs is demanded to establish a precise mapping from the natural language to the programming language. Due to the limited availability, most widely-used code search datasets are established with compromise, such as using code comments as a replacement of queries. Our empirical study on a famous code search dataset reveals that over one-third of its queries contain noises that make them deviate from natural user queries. Models trained through noisy data are faced with severe performance degradation when applied in real-world scenarios. To improve the dataset quality and make the queries of its samples semantically identical to real user queries is critical for the practical usability of neural code search. In this paper, we propose a data cleaning framework consisting of two subsequent filters: a rule-based syntactic filter and a model-based semantic filter. This is the first framework that applies semantic query cleaning to code search datasets. Experimentally, we evaluated the effectiveness of our framework on two widely-used code search models and three manually-annotated code retrieval benchmarks. Training the popular DeepCS model with the filtered dataset from our framework improves its performance by 19.2% MRR and 21.3% Answer@1, on average with the three validation benchmarks.  2022, CC BY.","2022","2022-06-10 02:10:27","2022-07-31 05:05:14","","","","","","","","","arXiv","","","","","","","","","","","","","Publisher: arXiv","","","http://dx.doi.org/10.1145/3510003.3510160","Cleaning; Deep learning; Benchmarking; Natural language processing systems; Semantics; data cleaning; deep learning; Training; Computational modeling; Data models; Benchmark testing; Training data; dataset; code search, dataset, data cleaning, deep learning; Code search; Codes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W7PLIH9S","journalArticle","2016","Chu, Xu; Ilyas, Ihab F.; Krishnan, Sanjay; Wang, Jiannan","Data cleaning: Overview and emerging challenges","2016 ACM SIGMOD International Conference on Management of Data, SIGMOD 2016, June 26, 2016  -  July 1, 2016","","","10.1145/2882903.2912574","","Detecting and repairing dirty data is one of the perennial challenges in data analytics, and failure to do so can result in inaccurate analytics and unreliable decisions. Over the past few years, there has been a surge of interest from both industry and academia on data cleaning problems including new abstractions, interfaces, approaches for scalability, and statistical techniques. To better understand the new advances in the field, we will first present a taxonomy of the data cleaning literature in which we highlight the recent interest in techniques that use constraints, rules, or patterns to detect errors, which we call qualitative data cleaning. We will describe the state-of-theart techniques and also highlight their limitations with a series of illustrative examples. While traditionally such approaches are distinct from quantitative approaches such as outlier detection, we also discuss recent work that casts such approaches into a statistical estimation framework including: using Machine Learning to improve the efficiency and accuracy of data cleaning and considering the effects of data cleaning on statistical analysis.  2016 ACM.","2016","2022-06-10 02:10:28","2022-07-31 14:32:38","","2201-2206","","","26-June-2016","","","","Proceedings of the ACM SIGMOD International Conference on Management of Data","","","","","","","","","","","","","","","","http://dx.doi.org/10.1145/2882903.2912574","Cleaning; Data Analytics; data quality, statistical cleaning, integrity constraints, data cleaning, sampling; QUERY; VIOLATIONS; statistical cleaning, sampling, data cleaning, integrity constraints, data quality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z445ZWRH","journalArticle","2017","Katevas, Kleomenis; Leontiadis, Ilias; Pielot, Martin; Serra, Joan","Practical processing of mobile sensor data for continual deep learning predictions","1st International Workshop on Deep Learning for Mobile Systems and Applications, EMDL 2017, June 23, 2017","","","10.1145/3089801.3089802","","We present a practical approach for processing mobile sensor time series data for continual deep learning predictions. The approach comprises data cleaning, normalization, capping, time-based compression, and finally classification with a recurrent neural network. We demonstrate the effectiveness of the approach in a case study with 279 participants. On the basis of sparse sensor events, the network continually predicts whether the participants would attend to a notification within 10 minutes. Compared to a random baseline, the classifier achieves a 40% performance increase (AUC of 0.702) on a withheld test set. This approach allows to forgo resource-intensive, domain-specific, error-prone feature engineering, which may drastically increase the applicability of machine learning to mobile phone sensor data.  2017 ACM.","2017","2022-06-10 02:10:28","2022-07-31 04:46:52","","19-24","","","","","","","EMDL 2017 - Proceedings of the 1st International Workshop on Deep Learning for Mobile Systems and Applications, co-located with MobiSys 2017","","","","","","","","","","","","","","","","http://dx.doi.org/10.1145/3089801.3089802","Data handling; Classification (of information); Learning systems; Recurrent neural networks; mobile sensing, push notifications, sensor data processing, recurrent neural networks; push notifications, mobile sensing, sensor data processing, recurrent neural networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"32DVJ9HZ","conferencePaper","2019","Berti-Equille, Laure","Learn2Clean: Optimizing the sequence of tasks for web data preparation","2019 World Wide Web Conference, WWW 2019, May 13, 2019  -  May 17, 2019","","","10.1145/3308558.3313602","","Data cleaning and preparation has been a long-standing challenge in data science to avoid incorrect results and misleading conclusions obtained from dirty data. For a given dataset and a given machine learning-based task, a plethora of data preprocessing techniques and alternative data curation strategies may lead to dramatically different outputs with unequal quality performance. Most current work on data cleaning and automated machine learning, however, focus on developing either cleaning algorithms or user-guided systems or argue to rely on a principled method to select the sequence of data preprocessing steps that can lead to the optimal quality performance of. In this paper, we propose Learn2Clean, a method based on Q-Learning, a model-free reinforcement learning technique that selects, for a given dataset, a ML model, and a quality performance metric, the optimal sequence of tasks for preprocessing the data such that the quality of the ML model result is maximized. As a preliminary validation of our approach in the context of Web data analytics, we present some promising results on data preparation for clustering, regression, and classification on real-world data.  2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License.","2019","2022-06-10 02:10:29","2022-07-31 05:42:30","","2580-2586","","","","","","","The Web Conference 2019 - Proceedings of the World Wide Web Conference, WWW 2019","","","","Association for Computing Machinery","San Francisco, CA, United states","","","","","","","","","","","http://dx.doi.org/10.1145/3308558.3313602","Cleaning; Data curation; Data Science; Learning systems; Reinforcement learning; Data Analytics; World Wide Web; Data cleaning; Data cleaning, Q-Learning, Principled data preprocessing, Reinforcement learning; Principled data preprocessing; Q-Learning; Data cleaning, Reinforcement learning, Q-Learning, Principled data preprocessing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AWDXX2JL","conferencePaper","2021","Tan, Wang-Chiew","Deep Data Integration","2021 International Conference on Management of Data, SIGMOD 2021, June 20, 2021  -  June 25, 2021","07308078","","","","We are witnessing the widespread adoption of deep learning techniques as avant-garde solutions to different computational problems in recent years. In data integration, the use of deep learning techniques has helped establish several state-of-the-art results in long standing problems, including information extraction, entity matching, data cleaning, and table understanding. In this talk, I will reflect on the strengths of deep learning and how that has helped move the needle in data integration. I will also discuss a few challenges associated with solutions based on deep learning techniques and describe some opportunities for the data management community.  2021 Owner/Author.","2021","2022-06-10 02:10:30","2022-07-31 03:18:46","","2","","","","","","","Proceedings of the ACM SIGMOD International Conference on Management of Data","","","","Association for Computing Machinery","Virtual, Online, China","","","","","","","","","","","http://dx.doi.org/10.1145/3448016.3460534","Deep learning; Learning systems; Data integration; Information management; data integration; data cleaning; deep learning; information extraction; entity matching; table understanding; data integration, entity matching, data cleaning, table understanding, deep learning, information extraction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"89S882I8","journalArticle","2017","Li, Li-Hua; Lin, Chi-Tien; Chen, Shin-Fu","Micro-lending default awareness using artificial neural network","2nd International Conference on Multimedia Systems and Signal Processing, ICMSSP 2017, August 13, 2017  -  August 16, 2017","","","10.1145/3145511.3145515","","Lending ways plays as a key sector in banking business. In recent years, small amount lending, so-called micro-lending, has become the popular trend due to the prosperous development of internet financial service. The high profit has driven banks to bear the so-called credit risk that the borrower may default or delay the repayment of the loan. To prevent from or to predict the credit risk, there are many methodologies widely applied, such as the credit scoring system with credit score-card, the Logistic Regression (LR) for assessing repayment ability or linear scoring function like Bayesian Decision Rules for credit risk of lending. These traditional methods need substantial information to do the analysis of customer lending. However, for general public, the applicant's information of micro-lending is usually less complete, not to mention to fill out the information of score-card. If we applied the above traditional methods for credit risk measurement, the accuracy of predicting the default usually is not as expected due to the incompleteness of information. It is, therefore, studies on the credit-risk measurement of micro-lending have become crucial. In this paper, we proposed a new approach for credit-risk measurement of micro-lending. To learn the pattern of bad credit, the methodology of data cleaning and Back-Propagation Neural Network (BPN) are adopted. The dataset of loan information from a Brazilian commercial bank is used to run the process of credit default awareness. Based on the experiment outcomes, we proved that the Artificial Neural Network can significantly improve the accuracy of the perception while reducing the chance of misjudgment of the lending.  2017 Association for Computing Machinery.","2017","2022-06-10 02:10:30","2022-07-31 05:21:53","","56-60","","","","","","","ACM International Conference Proceeding Series","","","","","","","","","","","","","","","","http://dx.doi.org/10.1145/3145511.3145515","Backpropagation; Neural networks; Logistic regression; Risk assessment; Banking; Multimedia signal processing; Multimedia systems; Torsional stress; Default, Back-Propagation Neural Network, Credit Risk, Micro-lending; Micro-lending, Back-Propagation Neural Network, Credit Risk, Default","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LQ23GLTA","journalArticle","2020","Zhang, Dan; Suhara, Yoshihiko; Li, Jinfeng; Hulsebos, Madelon; Demiralp, Caatay; Tan, Wang Chiew","Sato: Contextual semantic type detection in tables","Proceedings of the VLDB Endowment","","21508097","10.14778/3407790.3407793","","Detecting the semantic types of data columns in relational tables is important for various data preparation and information retrieval tasks such as data cleaning, schema matching, data discovery, and semantic search. However, existing detection approaches either perform poorly with dirty data, support only a limited number of semantic types, fail to incorporate the table context of columns or rely on large sample sizes for training data. We introduce Sato, a hybrid machine learning model to automatically detect the semantic types of columns in tables, exploiting the signals from the table context as well as the column values. Sato combines a deep learning model trained on a large-scale table corpus with topic modeling and structured prediction to achieve support-weighted and macro average F1 scores of 0.925 and 0.735, respectively, exceeding the state-of-theart performance by a significant margin. We extensively analyze the overall and per-type performance of Sato, discussing how individual modeling components, as well as feature categories, contribute to its performance.  2020, VLDB Endowment.","2020","2022-06-10 02:10:32","2022-07-31 04:28:08","","1835-1848","","11","13","","Proceedings of the VLDB Endowment","","","","","","","","","","","","","","","Publisher: VLDB Endowment","","","http://dx.doi.org/10.14778/3407790.3407793","Deep learning; Learning systems; Semantics; Scales (weighing instruments); WEB","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BCZFPPEB","conferencePaper","2019","Tae, Ki Hyun; Roh, Yuji; Oh, Young Hun; Kim, Hyunsu; Whang, Steven Euijong","Data cleaning for accurate, fair, and robust models: A big data - AI integration approach","3rd Workshop on Data Management for End-To-End Machine Learning, DEEM 2019 - In conjunction with the 2019 ACM SIGMOD/PODS Conference, June 30, 2019","07308078","","10.1145/3329486.3329493","","The wide use of machine learning is fundamentally changing the software development paradigm (a.k.a. Software 2.0) where data becomes a first-class citizen, on par with code. As machine learning is used in sensitive applications, it becomes imperative that the trained model is accurate, fair, and robust to attacks. While many techniques have been proposed to improve the model training process (in-processing approach) or the trained model itself (post-processing), we argue that the most effective method is to clean the root cause of error: the data the model is trained on (pre-processing). Historically, there are at least three research communities that have been separately studying this problem: data management, machine learning (model fairness), and security. Although a significant amount of research has been done by each community, ultimately the same datasets must be preprocessed, and there is little understanding how the techniques relate to each other and can possibly be integrated. We contend that it is time to extend the notion of data cleaning for modern machine learning needs. We identify dependencies among the data preprocessing techniques and propose MLClean, a unified data cleaning framework that integrates the techniques and helps train accurate and fair models. This work is part of a broader trend of Big data - Artificial Intelligence (AI) integration.  2019 ACM.","2019","2022-06-10 02:10:33","2022-07-31 14:33:17","","ACM Special Interest Group on Management of Data (SIGMOD)","","","","","","","Proceedings of the ACM SIGMOD International Conference on Management of Data","","","","Association for Computing Machinery","Amsterdam, Netherlands","","","","","","","","","","","http://dx.doi.org/10.1145/3329486.3329493","Big data; Cleaning; Machine learning; Software design; Data integration; Information management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GICUNXAJ","conferencePaper","2022","Pu, Jiashu; Lin, Jianshi; Mao, Xiaoxi; Tao, Jianrong; Shen, Xudong; Shang, Yue; Wu, Runze","Unsupervised Representation Learning of Player Behavioral Data with Confidence Guided Masking","31st ACM World Wide Web Conference, WWW 2022, April 25, 2022  -  April 29, 2022","","","10.1145/3485447.3512275","","Players of online games generate rich behavioral data during gaming. Based on these data, game developers can build a range of data science applications, such as bot detection and social recommendation, to improve the gaming experience. However, the development of such applications requires data cleansing, training sample labeling, feature engineering, and model development, which makes the use of such applications in small and medium-sized game studios still uncommon. While acquiring supervised learning data is costly, unlabeled behavioral logs are often continuously and automatically generated in games. Thus we resort to unsupervised representation learning of player behavioral data to optimize intelligent services in games. Behavioral data has many unique properties, including semantic complexity, excessive length, etc. A worth noting property within raw player behavioral data is that a lot of it is task-irrelevant. For these data characteristics, we introduce a BPE-enhanced compression method and propose a novel adaptive masking strategy called Masking by Token Confidence (MTC) for the Masked Language Modeling (MLM) pre-training task. MTC is designed to increase the masking probabilities of task-relevant tokens. Experiments on four downstream tasks and successful deployment in a world-renowned Massively Multiplayer Online Role-Playing Game (MMORPG) prove the effectiveness of the MTC strategy1.  2022 ACM.","2022","2022-06-10 02:10:33","2022-07-31 03:43:52","","3396-3406","","","","","","","WWW 2022 - Proceedings of the ACM Web Conference 2022","","","","Association for Computing Machinery, Inc","Virtual, Online, France","","","","","","","","","","","http://dx.doi.org/10.1145/3485447.3512275","Learning systems; Social networking (online); Semantics; Signal encoding; Computational linguistics; Modeling languages; unsupervised Pre-trained, Masked Language Modeling, Online Games, sequence compression, Transformer Encoder, User Modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F86VP2SI","journalArticle","2018","Kunft, Andreas; Katsifodimos, Asterios; Schelter, Sebastian; Brec, Sebastian; Rabl, Tilmann; Markl, Volker","An intermediate representation for optimizing machine learning pipelines","45th International Conference on Very Large Data Bases, VLDB 2019, August 26, 2017  -  August 30, 2017","","","10.14778/3342263.3342633","","Machine learning (ML) pipelines for model training and validation typically include preprocessing, such as data cleaning and feature engineering, prior to training an ML model. Preprocessing combines relational algebra and user-defined functions (UDFs), while model training uses iterations and linear algebra. Current systems are tailored to either of the two. As a consequence, preprocessing and ML steps are optimized in isolation. To enable holistic optimization of ML training pipelines, we present Lara, a declarative domainspecific language for collections and matrices. Lara's intermediate representation (IR) re ects on the complete program, i.e., UDFs, control ow, and both data types. Two views on the IR enable diverse optimizations. Monads enable operator pushdown and fusion across type and loop boundaries. Combinators provide the semantics of domainspecific operators and optimize data access and cross-validation of ML algorithms. Our experiments on preprocessing pipelines and selected ML algorithms show the effects of our proposed optimizations on dense and sparse data, which achieve speedups of up to an order of magnitude.  2019, is held by the owner/author(s).","2018","2022-06-10 02:10:41","2022-07-31 02:23:33","","1553-1567","","11","12","","","","Proceedings of the VLDB Endowment","","","","","","","","","","","","","","","","http://dx.doi.org/10.14778/3342263.3342633","Machine learning; Pipelines; Semantics; Linear algebra; SYSTEMS; PLANS; SCALABLE LINEAR ALGEBRA","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ILM8L5UL","conferencePaper","2019","Lu, Jiaheng; Wang, Jin; Lin, Chunbin; Li, Chen","Synergy of database techniques and machine learning models for string similarity search and join","28th ACM International Conference on Information and Knowledge Management, CIKM 2019, November 3, 2019  -  November 7, 2019","","","10.1145/3357384.3360319","","String data is ubiquitous and string similarity search and join are critical to the applications of information retrieval, data integration, data cleaning, and also big data analytics. To support these operations, many techniques in the database and machine learning areas have been proposed independently. More precisely, in the database research area, there are techniques based on the filtering- and-verification framework that can not only achieve a high performance, but also provide guaranteed quality of results for given similarity functions. In the machine learning research area, string similarity processing is modeled as a problem of identifying similar text records; Specifically, the deep learning approaches use embedding techniques that map text to a low-dimensional continuous vector space. In this tutorial, we review a number of studies of string similarity search and join in these two research areas. We divide the studies in each area into different categories. For each category, we provide a comprehensive review of the relevant works, and present the details of these solutions. We conclude this tutorial by pinpointing promising directions for future work to combine techniques in these two areas.  2019 Association for Computing Machinery.","2019","2022-06-10 02:10:42","2022-07-31 04:10:01","","2975-2976","","","","","","","International Conference on Information and Knowledge Management, Proceedings","","","","Association for Computing Machinery","Beijing, China","","","","","","","","","","","http://dx.doi.org/10.1145/3357384.3360319","Deep learning; Learning systems; Data integration; Advanced Analytics; Data Analytics; Database systems; Knowledge management; Vector spaces; data integration; machine learning; string similarity search, string similarity join, machine learning, databases, data integration; databases; string similarity join; string similarity search; string similarity search, data integration, machine learning, databases, string similarity join","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YJ25ZUXN","conferencePaper","2021","Phani, Arnab; Rath, Benjamin; Boehm, Matthias","LIMA: Fine-grained Lineage Tracing and Reuse in Machine Learning Systems","2021 International Conference on Management of Data, SIGMOD 2021, June 20, 2021  -  June 25, 2021","07308078","","","","Machine learning (ML) and data science workflows are inherently exploratory. Data scientists pose hypotheses, integrate the necessary data, and run ML pipelines of data cleaning, feature engineering, model selection and hyper-parameter tuning. The repetitive nature of these workflows, and their hierarchical composition from building blocks exhibits high computational redundancy. Existing work addresses this redundancy with coarse-grained lineage tracing and reuse for ML pipelines. This approach allows using existing ML systems, but views entire algorithms as black boxes, and thus, fails to eliminate fine-grained redundancy and to handle internal non-determinism. In this paper, we introduce LIMA, a practical framework for efficient, fine-grained lineage tracing and reuse inside ML systems. Lineage tracing of individual operations creates new challenges and opportunities. We address the large size of lineage traces with multi-level lineage tracing and reuse, as well as lineage deduplication for loops and functions; exploit full and partial reuse opportunities across the program hierarchy; and integrate this framework with task parallelism and operator fusion. The resulting framework performs fine-grained lineage tracing with low overhead, provides versioning and reproducibility, and is able to eliminate fine-grained redundancy. Our experiments on a variety of ML pipelines show performance improvements up to 12.4x.  2021 ACM.","2021","2022-06-10 02:10:44","2022-07-31 05:38:17","","1426-1439","","","","","","","Proceedings of the ACM SIGMOD International Conference on Management of Data","","","","Association for Computing Machinery","Virtual, Online, China","","","","","","","","","","","http://dx.doi.org/10.1145/3448016.3452788","Machine learning; Pipelines; Data Science; Printing machinery; Computer software reusability; Redundancy; OPTIMIZATION; QUERIES; MANAGEMENT; DATA PROVENANCE; EFFICIENT; reuse of intermediates, lineage tracing, lineage-based reuse, ml systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"33ZSHNV9","conferencePaper","2019","Neutatz, Felix; Mahdavi, Mohammad; Abedjan, Ziawasch","Ed2: A case for active learning in error detection","28th ACM International Conference on Information and Knowledge Management, CIKM 2019, November 3, 2019  -  November 7, 2019","","","10.1145/3357384.3358129","","State-of-the-art approaches formulate error detection as a semi-supervised classification problem. Recent research suggests that active learning is insufficiently effective for error detection and proposes the usage of neural networks and data augmentation to reduce the number of these user-provided labels. However, we can show that using the appropriate active learning strategy, it is possible to outperform the more complex models that rely on data augmentation. To this end, we propose a multi-classifier approach with two-stage sampling for active learning. This intuitive and neat sampling method chooses the most promising cells across rows and columns for labeling. On three datasets, ED2 achieves state-of-the-art detection accuracy while for large datasets, the required number of user labels is lower by one order of magnitude compared to the state of the art.  2019 Association for Computing Machinery.","2019","2022-06-10 02:10:45","2022-07-31 14:04:53","","2249-2252","","","","","","","International Conference on Information and Knowledge Management, Proceedings","","","","Association for Computing Machinery","Beijing, China","","","","","","","","","","","http://dx.doi.org/10.1145/3357384.3358129","Learning systems; Error detection; Large dataset; Supervised learning; Knowledge management; active learning, data quality, error detection, example-driven error detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PV6JZYZB","conferencePaper","2021","Shedage, Seema; Farmer, Jake; Demirel, Doga; Halic, Tansel; Kockara, Sinan; Arikatla, Venkata; Sexton, Kevin; Ahmadi, Shahryar","Development of Virtual Skill Trainers and Their Validation Study Analysis Using Machine Learning","5th International Conference on Information System and Data Mining, ICISDM 2021, May 27, 2021  -  May 29, 2021","","","10.1145/3471287.3471296","","Minimally invasive skills assessment is important in developing competent surgical simulators and executing reliable skills evaluation [9]. Arthroscopy and Laparoscopy surgeries are considered Minimally Invasive Surgeries (MIS). In MIS, the surgeon operates through small incisions with specialized narrow instruments, fiberoptic lights, and a monitor. Arthroscopy surgery is used to diagnose and treat joints problems, and Laparoscopic procedures are performed on the abdominal cavity. Due to non-natural hand-eye coordination, narrow field-of-view, and limited instrument control, MIS training is challenging to master. We are analyzing two simulators' data, Virtual Arthroscopic Tear Diagnosis and Evaluation Platform (VATDEP) and Gentleness Simulator. Both simulators went through the validation studies with human subjects. We recorded simulation data during the validation studies, such as tool motion, position, and task time. Recorded data went through the data preprocessing; after the data cleaning, we extracted the recoded data features and normalized them. Normalized features were used to input various machine learning algorithms, including K-nearest neighbor (KNN), Support vector machine (SVM), and Logistic regression (LR). The average accuracy was evaluated through k-fold cross-validation. The proposed methods validated using 10 subjects (5 experts, 5 novices) for the VATDEP simulator. 23 subjects (4 experts and 19 novices) for the Gentleness Simulator. The result shows a significant difference between the expert and novice population with the p  0.05 using the Mann-Whitney U-test. The VATDEP simulator's classification algorithms' average accuracy is 74% and 80% for the Gentleness Simulator. The results show that the normalized features and with KNN, SVM, and LR classifiers can provide accurate classification of experts and novices. The evaluation technique proposed in this study can develop surgical training by providing appropriate feedback to trainees to evaluate proficiency.  2021 ACM.","2021","2022-06-10 02:10:48","2022-07-31 14:10:06","","128-137","","","","","","","ACM International Conference Proceeding Series","","","","Association for Computing Machinery","Virtual, Online, United states","","","","","","","","","","","http://dx.doi.org/10.1145/3471287.3471296","Learning algorithms; Support vector machines; E-learning; Nearest neighbor search; Laparoscopy; Simulators; Virtual reality; Machine Learning; Validation Study; Virtual Reality Simulator","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D57F7BCN","conferencePaper","2019","Mohammad, Nurul Izzati; Ismail, Saiful Adli; Kama, Mohd Nazri; Yusop, Othman Mohd; Azmi, Azri","Customer Churn Prediction in Telecommunication Industry Using Machine Learning Classifiers","3rd International Conference on Vision, Image and Signal Processing, ICVISP 2019, August 26, 2019  -  August 28, 2019","","","10.1145/3387168.3387219","","Customer churn is one of the main problems in telecommunication industry. This study aims to identify the factors that influence customer churn and develop an effective churn prediction model as well as provide best analysis of data visualization results. The dataset has been collected from Kaggle open data website. The proposed methodology for analysis of churn prediction covers several phases: data pre-processing, analysis, implementing machine learning algorithms, evaluation of the classifiers and choose the best one for prediction. Data preprocessing process involved three major action, which are data cleaning, data transformation and feature selection. Machine learning classifiers was chosen are Logistic Regression, Artificial Neural Network and Random Forest. Then, classifiers were evaluated by using performance measurement which are accuracy, precision, recall and error rate in order to find the best classifier. Based on this study, the output shows that logistic regression outperform compared to artificial neural network and random forest.  2019 ACM.","2019","2022-06-10 02:10:49","2022-07-31 02:54:34","","","","","","","","","ACM International Conference Proceeding Series","","","","Association for Computing Machinery","Vancouver, BC, Canada","","","","","","","","","","","http://dx.doi.org/10.1145/3387168.3387219","Machine learning; Neural networks; Decision trees; Forecasting; Predictive analytics; Open Data; Telecommunication industry; Logistic regression; Random forests; Data visualization; Metadata; Sales; Machine Learning; Prediction; Image processing; Customer Churn; Telecommunication Industry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EHAFFV84","conferencePaper","2020","Dakuo Wang; Ram, P.; Weidele, D.K.I.; Liu, S.; Muller, M.; Weisz, J.D.; Valente, A.; Chaudhary, A.; Torres, D.; Samulowitz, H.; Amini, L.","AutoAI: automating the end-to-end AI lifecycle with humans-in-the-loop","IUI '20: 25th International Conference on Intelligent User Interfaces, 17-20 March 2020","","","10.1145/3379336.3381474","","Automated Artificial Intelligence and Machine Learning (AutoAI / AutoML) can now automate every step of the end-to-end AI Lifecycle, from data cleaning, to algorithm selection, and to model deployment and monitoring in the machine learning workflow. AutoAI technologies, initially aimed to save data scientists from the low level coding tasks, also has great potential to serve non-technical users such as domain experts and business users to build and deploy machine learning models. Researchers coined it as ""democratizing AI"", where non-technical users are empowered by AutoAI technologies to create and adopt AI models. To realize such promise, AutoAI needs to translate and incorporate the real-world business logic and requirements into the automation. In this Demo, we present a first of its kinds experimental system, IBM AutoAI Playground, that enables non-technical users to define and customize their business goals (e.g., Prediction Time) as constraints. AutoAI then builds models to satisfy those constraints while optimizing for the model performance (e.g., ROC AUC score). This Demo also showcases AutoAIViz, a Conditional Parallel Coordinates visualization feature, and a TrustedAI feature from two accepted IUI'20 papers.","2020-03-17","2022-06-10 02:11:06","2022-07-31 15:38:59","","77-8","","","","","","","IUI '20: Proceedings of the 25th International Conference on Intelligent User Interfaces Companion","","","","ACM","New York, NY, USA","","","","","","","","","","","http://dx.doi.org/10.1145/3379336.3381474","Machine learning; Automation; learning (artificial intelligence); Life cycle; user interfaces; data visualisation; knowledge based systems; AutoML; human-AI collaboration, AutoML, parallel coordinates, business constraints, democratizing AI, stakeholder constraints, AutoAI; Constrained optimization; User interfaces; AutoAI; business constraints; democratizing AI; human-AI collaboration; parallel coordinates; stakeholder constraints; stakeholder constraints, AutoAI, AutoML, business constraints, democratizing AI, human-AI collaboration, parallel coordinates","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K58YAPV7","conferencePaper","2019","Ahmed, U.Z.; Sindhgatta, R.; Srivastava, N.; Karkare, A.","Targeted Example Generation for Compilation Errors","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE), 11-15 Nov. 2019","","","10.1109/ASE.2019.00039","","We present TEGCER, an automated feedback tool for novice programmers. TEGCER uses supervised classification to match compilation errors in new code submissions with relevant pre-existing errors, submitted by other students before. The dense neural network used to perform this classification task is trained on 15000+ error-repair code examples. The proposed model yields a test set classification Pred@3 accuracy of 97.7% across 212 error category labels. Using this model as its base, TEGCER presents students with the closest relevant examples of solutions for their specific error on demand. A large scale (N230) usability study shows that students who use TEGCER are able to resolve errors more than 25% faster on average than students being assisted by human tutors.","2019","2022-06-10 02:11:11","2022-07-31 04:07:27","","327-38","","","","","","","2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). Proceedings","","","","IEEE Computer Society","Los Alamitos, CA, USA","","","","","","","","","","","http://dx.doi.org/10.1109/ASE.2019.00039","Classification (of information); Automation; neural nets; Neural networks; Errors; pattern classification; program compilers; Software engineering; Computer aided instruction; Students; Program processors; intelligent tutoring systems; Training; Programming; Tools; Maintenance engineering; Compilation Error; Example Generation; Intelligent Tutoring Systems; Introductory Programming; Neural Networks; Particle separators; computer science education; compilation error, neural networks, intelligent tutoring systems, introductory programming, example generation; neural networks, example generation, intelligent tutoring systems, compilation error, introductory programming","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5C3QPL37","conferencePaper","2021","Runjin Chen; Yanyan Shen; Dongxiang Zhang","GNEM: a generic one-to-set neural entity matching framework","WWW '21: Web Conference 2021, 19-23 April 2021","","","10.1145/3442381.3450119","","Entity Matching is a classic research problem in any data analytics pipeline, aiming to identify records referring to the same real-world entity. It plays an important role in data cleansing and integration. Advanced entity matching techniques focus on extracting syntactic or semantic features from record pairs via complex neural architectures or pre-trained language models. However, the performances always suffer from noisy or missing attribute values in the records. We observe that comparing one record with several relevant records in a collective manner allows each pairwise matching decision to be made by borrowing valuable insights from other pairs, which is beneficial to the overall matching performance. In this paper, we propose a generic one-to-set neural framework named GNEM for entity matching. GNEM predicts matching labels between one record and a set of relevant records simultaneously. It constructs a record pair graph with weighted edges and adopts the graph neural network to propagate information among pairs. We further show that GNEM can be interpreted as an extension and generalization of the existing pairwise matching techniques. Extensive experiments on real-world data sets demonstrate that GNEM consistently outperforms the existing pairwise entity matching techniques and achieves up to 8.4% improvement on F1-Score compared with the state-of-the-art neural methods.","2021-04-19","2022-06-10 02:11:11","2022-07-31 13:37:45","","1686-94","","","","","","","WWW '21: Proceedings of the Web Conference 2021","","","","ACM","New York, NY, USA","","","","","","","","","","","http://dx.doi.org/10.1145/3442381.3450119","Deep learning; neural nets; data analysis; Data Analytics; Semantics; World Wide Web; feature extraction; pattern matching; data integration; graph theory; Deep learning, Graph neural network, Entity matching; Graph structures; RULE-BASED METHOD; Entity matching; Graph neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BLFFLAG3","journalArticle","2022","Ayman, Afiya; Sivagnanam, Amutheezan; Wilbur, Michael; Pugliese, Philip; Dubey, Abhishek; Laszka, Aron","Data-Driven Prediction and Optimization of Energy Use for Transit Fleets of Electric and ICE Vehicles","10.1145/3428150","","15335399","10.1145/3433992","","Due to the high upfront cost of electric vehicles, many public transit agencies can afford only mixed fleets of internal combustion and electric vehicles. Optimizing the operation of such mixed fleets is challenging because it requires accurate trip-level predictions of electricity and fuel use as well as efficient algorithms for assigning vehicles to transit routes. We present a novel framework for the data-driven prediction of trip-level energy use for mixed-vehicle transit fleets and for the optimization of vehicle assignments, which we evaluate using data collected from the bus fleet of CARTA, the public transit agency of Chattanooga, TN. We first introduce a data collection, storage, and processing framework for system-level and high-frequency vehicle-level transit data, including domain-specific data cleansing methods. We train and evaluate machine learning models for energy prediction, demonstrating that deep neural networks attain the highest accuracy. Based on these predictions, we formulate the problem of minimizing energy use through assigning vehicles to fixed-route transit trips. We propose an optimal integer program as well as efficient heuristic and meta-heuristic algorithms, demonstrating the scalability and performance of these algorithms numerically using the transit network of CARTA.  2021 Copyright held by the owner/author(s). Publication rights licensed to ACM.","2022","2022-06-10 02:11:14","2022-07-31 14:25:25","","","","1","22","","ACM Transactions on Internet Technology","","","","","","","","","","","","","","","Publisher: Association for Computing Machinery","","","http://dx.doi.org/10.1145/3433992","Forecasting; Genetic algorithms; Deep neural networks; Digital storage; Data mining; Vehicles; Heuristic algorithms; Environmental impact; Urban transportation; Combinatorial optimization; Fleet operations; Integer programming; machine learning; deep learning; genetic algorithm; public transportation, deep learning, combinatorial optimization, electric vehicle, integer program, machine learning, energy use, environmental impact, genetic algorithm; electric vehicle; MODEL; combinatorial optimization; energy use; environmental impact; integer program; MAP-MATCHING ALGORITHM; public transportation; genetic algorithm, deep learning, environmental impact, energy use, combinatorial optimization, electric vehicle, integer program, public transportation, machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LJ8JK8J6","journalArticle","2021","Sun, Danfeng; Wu, Jia; Yang, Jian; Wu, Huifeng","Intelligent data collaboration in heterogeneous-device IoT platforms","ACM Transactions on Sensor Networks","","15504859","10.1145/3427912","","The merging boundaries between edge computing and deep learning are forging a new blueprint for the Internet of Things (IoT). However, the low-quality of data in many IoT platforms, especially those composed of heterogeneous devices, is hindering the development of high-quality applications for those platforms. The solution presented in this article is intelligent data collaboration, i.e., the concept of deep learning providing IoT with the ability to adaptively collaborate to accomplish a task. Here, we outline the concept of intelligent data collaboration in detail and present a mathematical model in general form. To demonstrate one possible case where intelligent data collaboration would be useful, we prepared an implementation called adaptive data cleaning (ADC), designed to filter noisy data out of temperature readings in an IoT base station network. ADC primarily consists of a denoising autoencoder LSTM for predictions and a four-level data processing mechanism to perform the filtering. Comparisons between ADC and a maximum slop method show ADC with the lowest false error and the best filtering rates.  2021 Association for Computing Machinery.","2021","2022-06-10 02:11:15","2022-07-31 05:51:29","","","","3","17","","ACM Transactions on Sensor Networks","","","","","","","","","","","","","","","Publisher: Association for Computing Machinery","","","http://dx.doi.org/10.1145/3427912","Long short-term memory; Data handling; Internet of things; Edge computing; edge computing; Internet of Things (IoT); Internet of Things (IoT), Data collaboration, edge computing; BIG DATA; SYSTEM; ANALYTICS; THINGS; Data collaboration; DENOISING AUTOENCODER; INTERNET","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CZRYGKSM","conferencePaper","2021","Bansal, Chahat; Ahlawat, Hari Om; Jain, Mayank; Prakash, Om; Mehta, Shivani A; Singh, Deepanshu; Baheti, Harshavardhansushil; Singh, Suyash; Seth, Aaditeshwar","IndiaSat: A Pixel-Level Dataset for Land-Cover Classification on Three Satellite Systems - Landsat-7, Landsat-8, and Sentinel-2","4th ACM SIGCAS Conference on Computing and Sustainable Societies, COMPASS 2021, June 28, 2021  -  July 2, 2021","","","10.1145/3460112.3471953","","Land-cover (LC) classification is required for land management and planning models, and is increasingly done through remote sensing data. Supervised machine learning methods applied to satellite imagery can help with high-resolution LC classification but demand a labeled dataset for training and evaluation of the models. The availability of such datasets is limited though, especially for developing regions like in India. We describe a large pixel-level dataset, IndiaSat, that we have curated and provided for open use, consisting of 180,414 pixels labeled into four LC classes: greenery, water bodies, barren land, and built-up area. Initial labels are obtained through the crowd-sourced mapping platform Open Street Maps (OSM), and then manually curated and corrected. We describe our data cleaning methodology and ensure spatial diversity across different geographic regions in the country. We show that the IndiaSat dataset can be used to train simple classifiers deployed on commodity platforms like Google Earth Engine (GEE) for three popular and openly accessible satellite systems: Landsat-7, Landsat-8, and Sentinel-2, with high accuracy, and to additionally build LC change detection models to determine pixel-level changes over a sequence of several years.  2021 ACM.","2021","2022-06-10 02:11:17","2022-07-31 05:55:39","","147-155","","","","","","","Proceedings of 2021 4th ACM SIGCAS Conference on Computing and Sustainable Societies, COMPASS 2021","","","","Association for Computing Machinery, Inc","Virtual, Online, Australia","","","","","","","","","","","http://dx.doi.org/10.1145/3460112.3471953","Classification (of information); Large dataset; Supervised learning; Mapping; Remote sensing; Pixels; Satellite imagery; Open Street Maps, Satellite Imagery, LULC Mapping; Satellite Imagery, LULC Mapping, Open Street Maps","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DJKK2UUV","conferencePaper","2021","Kowshik, M. Ashikuzzaman; Pritom, Yeasin Arafat; Rahman, Md.Sohanur; Akbar, Ali; Ahad, Md Atiqur Rahman","Nurse Care Activity Recognition from Accelerometer Sensor Data Using Fourier-and Wavelet-based Features","2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the 2021 ACM International Symposium on Wearable Computers, UbiComp/ISWC 2021, September 21, 2021  -  September 25, 2021","","","10.1145/3460418.3479387","","Nurse care activity recognition is an emerging segment in healthcare automation systems based on physical movement recognition applying machine learning techniques using various sensor-based datasets. In this paper, different machine learning models have been used to recognize the activities. However, before that, our user dataset has been preprocessed using data cleaning, resampling, data labeling, windowing, and filtering techniques in order to handle the ununiform data. Various analytical features have been extracted using Fast Fourier Transformation, Power Spectral Density, and Discrete Wavelet Transformation. After that, the best combinational features have been selected from the extracted features, and class imbalance has been mitigated before applying the conventional machine learning models. After applying all methodology, 87.00% accuracy has been obtained using the Light Gradient Boosting Machine Classifier.  2021 ACM.","2021","2022-06-10 02:11:18","2022-07-31 05:06:48","","434-439","","","","","","","UbiComp/ISWC 2021 - Adjunct Proceedings of the 2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2021 ACM International Symposium on Wearable Computers","","","","Association for Computing Machinery, Inc","Virtual, Online, United states","","","","","","","","","","","http://dx.doi.org/10.1145/3460418.3479387","Machine learning; Automation; Pattern recognition; Biomedical signal processing; Video signal processing; Discrete wavelet transforms; Motion estimation; Nursing; Power spectral density; Signal reconstruction; Discrete Wavelet Transformation (DWT); Fast Fourier Transformation (FFT); Human Activity Recognition; Light Gradient Boosting Machine Classifier; Nurse Care Activity Recognition; Power Spectral Density (PSD)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DJQPKPR9","journalArticle","2020","Schmeicer, Stephan; Schiele, Gregor","CoSense: The Collaborative Sensing Middleware for the Internet-of-Things","ACM/IMS Transactions on Data Science","","26911922","10.1145/3395233","","We present coSense-the collaborative, fault-tolerant, and adaptive sensing middleware for the Internet-of-Things (IoT). By actively harnessing the greatest asset of the IoT, the sheer number of devices, coSense is able to provide easy data acquisition with quality-of-service-based data cleaning by combining unsupervised learning and information fusion. It can also greatly improve sensor accuracy and fault tolerance to produce measurements specifically tailored for modern data-driven IoT empowered applications. In this article, we focus on the general concepts behind coSense and evaluate the accuracy gain based on a real-world dataset.  2020 ACM.","2020","2022-06-10 02:11:18","2022-07-31 02:50:16","","","","4","1","","ACM/IMS Transactions on Data Science","","","","","","","","","","","","","","","Publisher: Association for Computing Machinery","","","http://dx.doi.org/10.1145/3395233","Internet of things; Data acquisition; Fault tolerance; Quality of service; Middleware; clustering, IoT, sensor fusion; sensor fusion, clustering, IoT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LNIBFD6X","conferencePaper","2021","Zhu, Chenguang; Yang, Ziyi; Gmyr, Robert; Zeng, Michael; Huang, Xuedong","Leveraging Lead Bias for Zero-shot Abstractive News Summarization","44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2021, July 11, 2021  -  July 15, 2021","","","10.1145/3404835.3462846","","A typical journalistic convention in news articles is to deliver the most salient information in the beginning, also known as the lead bias. While this phenomenon can be exploited in generating a summary, it has a detrimental effect on teaching a model to discriminate and extract important information in general. We propose that this lead bias can be leveraged in our favor in a simple and effective way to pre-train abstractive news summarization models on large-scale unlabeled news corpora: predicting the leading sentences using the rest of an article. We collect a massive news corpus and conduct data cleaning and filtering via statistical analysis. We then apply self-supervised pre-training on this dataset to existing generation models BART and T5 for domain adaptation. Via extensive experiments on six benchmark datasets, we show that this approach can dramatically improve the summarization quality and achieve state-of-the-art results for zero-shot news summarization without any fine-tuning. For example, in the DUC2003 dataset, the ROUGE-1 score of BART increases 13.7% after the lead-bias pre-training. We deploy the model in Microsoft News and provide public APIs as well as a demo website for multi-lingual news summarization.  2021 ACM.","2021","2022-06-10 02:11:19","2022-07-31 05:38:56","","1462-1471","","","","","","","SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval","","","","Association for Computing Machinery, Inc","Virtual, Online, Canada","","","","","","","","","","","http://dx.doi.org/10.1145/3404835.3462846","Benchmarking; Information retrieval; domain adaptation; lead bias, zero-shot summarization, domain adaptation, pre-training; lead bias; pre-training; zero-shot summarization; lead bias, domain adaptation, zero-shot summarization, pre-training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"59SS676R","bookSection","2019","","Machine learning and probabilistic data cleaning","Data Cleaning","978-1-4503-7152-0","","","https://doi.org/10.1145/3310205.3310213","","2019","2022-06-10 02:42:54","2022-07-31 05:32:38","","","","","","","","","","","","","Association for Computing Machinery","","","","","","","","","Type: 10.1145/3310205.3310213","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YKP3HGNR","book","2019","Ilyas, Ihab F.; Chu, Xu","Data Cleaning","","978-1-4503-7152-0","","","","","2019","2022-06-10 02:42:54","2022-08-10 19:16:51","","","","","","","","","","","","","Association for Computing Machinery","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XGZ4H8LD","conferencePaper","2020","Picado, Jose; Davis, John; Termehchy, Arash; Lee, Ga Young","Learning Over Dirty Data Without Cleaning","Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data","978-1-4503-6735-6","","","https://doi.org/10.1145/3318464.3389708","","2020","2022-06-10 02:42:54","2022-07-31 05:59:44","","1301–1316","","","","","","","","","","","Association for Computing Machinery","Portland, OR, USA","","","","","","","","Type: 10.1145/3318464.3389708","","","","machine learning, relational learning, data cleaning, data integration; data integration, data cleaning, relational learning, machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JD8JCXAK","conferencePaper","2021","Kumar, Arun","Automation of Data Prep, ML, and Data Science: New Cure or Snake Oil?","Proceedings of the 2021 International Conference on Management of Data","978-1-4503-8343-1","","","https://doi.org/10.1145/3448016.3457537","","2021","2022-06-10 02:42:54","2022-07-31 14:48:15","","2878–2880","","","","","","","","","","","Association for Computing Machinery","","","","","","","","","Type: 10.1145/3448016.3457537","","","","machine learning, benchmark datasets, data cleaning, data preparation, automl","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KZV2Y4TI","journalArticle","2019","Mahdavi, Mohammad; Abedjan, Ziawasch; Fernandez, Raul Castro; Madden, Samuel; Ouzzani, Mourad; Stonebraker, Michael; Tang, Nan","Raha: A Configuration-Free Error Detection System","Proceedings of the 2019 International Conference on Management of Data","","","","https://doi.org/10.1145/3299869.3324956","","2019","2022-06-10 02:42:54","2022-07-31 15:36:40","","865–882","","","","","","","","","","","","","","","","","","","","Type: 10.1145/3299869.3324956","","","","error detection, semi-supervised learning, clustering, label propagation, classification, historical data, data cleaning, machine learning; historical data, classification, label propagation, clustering, semi-supervised learning, error detection, machine learning, data cleaning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WDVS8ZVM","journalArticle","2019","Berti-Equille, Laure","ML-Based Knowledge Graph Curation: Current Solutions and Challenges","Companion Proceedings of The 2019 World Wide Web Conference","","","","https://doi.org/10.1145/3308560.3316522","","2019","2022-06-10 02:42:54","2022-07-31 05:20:35","","938–939","","","","","","","","","","","","","","","","","","","","Type: 10.1145/3308560.3316522","","","","Knowledge base curation, knowledge graph completion, entity disambiguation; entity disambiguation; Knowledge base curation; knowledge graph completion; knowledge graph completion, Knowledge base curation, entity disambiguation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5D2SIW22","journalArticle","2021","Bowman, Anthony D.; Jololian, Leon","A conceptual framework for an introductory machine learning course","J. Comput. Sci. Coll.","","","","","","2021","2022-06-10 02:43:07","2022-07-30 22:19:10","","78–83","","1","37","","","","","","","","","","","","","","","","","ISBN: 1937-4771 Publisher: Consortium for Computing Sciences in Colleges","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BQWZA968","conferencePaper","2016","Agrawal, Divy; Ba, Lamine; Berti-Equille, Laure; Chawla, Sanjay; Elmagarmid, Ahmed; Hammady, Hossam; Idris, Yasser; Kaoudi, Zoi; Khayyat, Zuhair; Kruse, Sebastian; Ouzzani, Mourad; Papotti, Paolo; Quiane-Ruiz, Jorge-Arnulfo; Tang, Nan; Zaki, Mohammed J.","Rheem: Enabling Multi-Platform Task Execution","Proceedings of the 2016 International Conference on Management of Data","978-1-4503-3531-7","","","https://doi.org/10.1145/2882903.2899414","","2016","2022-06-10 02:43:07","2022-07-31 04:33:11","","2069–2072","","","","","","","","","","","Association for Computing Machinery","San Francisco, California, USA","","","","","","","","Type: 10.1145/2882903.2899414","","","","big data, data analytics, cross-platform execution; cross-platform execution, big data, data analytics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7DNV9KJ4","conferencePaper","2016","Li, Jianshu; Zhao, Jian; Zhao, Fang; Liu, Hao; Li, Jing; Shen, Shengmei; Feng, Jiashi; Sim, Terence","Robust Face Recognition with Deep Multi-View Representation Learning","Proceedings of the 24th ACM international conference on Multimedia","978-1-4503-3603-1","","","https://doi.org/10.1145/2964284.2984061","","2016","2022-06-10 02:43:07","2022-07-31 04:30:50","","1068–1072","","","","","","","","","","","Association for Computing Machinery","Amsterdam, The Netherlands","","","","","","","","Type: 10.1145/2964284.2984061","","","","model ensemble, face recognition, deep learning, multi-view feature representation; face recognition, deep learning, multi-view feature representation, model ensemble","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G2MGIX6H","conferencePaper","2018","Ré, Christopher","Software 2.0 and Snorkel: Beyond Hand-Labeled Data","Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining","978-1-4503-5552-0","","","https://doi.org/10.1145/3219819.3219937","","2018","2022-06-10 02:43:07","2022-07-31 14:56:27","","2876","","","","","","","","","","","Association for Computing Machinery","London, United Kingdom","","","","","","","","Type: 10.1145/3219819.3219937","","","","hand-labeled data, data labeling, deep learning, software 2.0, label synthesis; label synthesis, hand-labeled data, data labeling, software 2.0, deep learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CXCBJ5PB","conferencePaper","2018","Dolby, Julian; Shinnar, Avraham; Allain, Allison; Reinen, Jenna","Ariadne: analysis for machine learning programs","Proceedings of the 2nd ACM SIGPLAN International Workshop on Machine Learning and Programming Languages","978-1-4503-5834-7","","","https://doi.org/10.1145/3211346.3211349","","2018","2022-06-10 02:43:07","2022-07-31 15:39:46","","1–10","","","","","","","","","","","Association for Computing Machinery","Philadelphia, PA, USA","","","","","","","","Type: 10.1145/3211346.3211349","","","","program analysis, machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DVLIUGBC","conferencePaper","2018","He, Ran; Yang, Sen; Yang, Jingyuan; Cao, Jin","Automated Mining of Approximate Periodicity on Numeric Data: A Statistical Approach","Proceedings of the 2nd International Conference on Compute and Data Analysis","978-1-4503-6359-4","","","https://doi.org/10.1145/3193077.3194509","","2018","2022-06-10 02:43:07","2022-07-31 14:52:24","","20–27","","","","","","","","","","","Association for Computing Machinery","DeKalb, IL, USA","","","","","","","","Type: 10.1145/3193077.3194509","","","","Automated Machine Learning, Periodicity Detection, Numeric Sequence; Periodicity Detection, Automated Machine Learning, Numeric Sequence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QBFAVQDL","conferencePaper","2018","Krasanakis, Emmanouil; Spyromitros-Xioufis, Eleftherios; Papadopoulos, Symeon; Kompatsiaris, Yiannis","Adaptive Sensitive Reweighting to Mitigate Bias in Fairness-aware Classification","Proceedings of the 2018 World Wide Web Conference","978-1-4503-5639-8","","","https://doi.org/10.1145/3178876.3186133","","2018","2022-06-10 02:43:07","2022-07-31 02:10:00","","853–862","","","","","","","","","","","International World Wide Web Conferences Steering Committee","Lyon, France","","","","","","","","Type: 10.1145/3178876.3186133","","","","algorithm bias, reweighting, classification fairness; DISCRIMINATION; reweighting, classification fairness, algorithm bias","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8GS4DCV9","conferencePaper","2019","Sun, Siyu; Gai, Yingjie; Zhou, Yingying; Xu, Aiting","Research on User Comments of Douban Animation Made in China Based on Text Mining Technology","Proceedings of the 2019 7th International Conference on Information Technology: IoT and Smart City","978-1-4503-7663-1","","","https://doi.org/10.1145/3377170.3377232","","2019","2022-06-10 02:43:07","2022-07-31 04:37:43","","89–93","","","","","","","","","","","Association for Computing Machinery","Shanghai, China","","","","","","","","Type: 10.1145/3377170.3377232","","","","Domestic animation, Machine learning, LDA theme analysis, Emotion analysis, NLP; Emotion analysis, NLP, Machine learning, Domestic animation, LDA theme analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V86KRR63","journalArticle","2018","Kestor, Gokcen; Mutlu, Burcu Ozcelik; Manzano, Joseph; Subasi, Omer; Unsal, Osman; Krishnamoorthy, Sriram","Comparative analysis of soft-error detection strategies: a case study with iterative methods","Proceedings of the 15th ACM International Conference on Computing Frontiers","","","","https://doi.org/10.1145/3203217.3203240","","2018","2022-06-10 02:43:07","2022-07-31 15:37:51","","173–182","","","","","","","","","","","","","","","","","","","","Type: 10.1145/3203217.3203240","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"US5NTG8Z","conferencePaper","2021","SAHLAOUI, Hayat; ALAOUI, El Arbi ABDELLAOUI; Agoujil, Said","A framework towards more accurate and explanatory student performance model","Proceedings of the 4th International Conference on Networking, Information Systems &amp; Security","978-1-4503-8871-9","","","https://doi.org/10.1145/3454127.3457634","","2021","2022-06-10 02:43:19","2022-07-30 22:30:01","","Article 58","","","","","","","","","","","Association for Computing Machinery","KENITRA, AA, Morocco","","","","","","","","Type: 10.1145/3454127.3457634","","","http://dx.doi.org/10.1145/3454127.3457634","Students’ performance, Interpretability., Model performance, Machine learning algorithms; Model performance, Students’ performance, Interpretability., Machine learning algorithms","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I6L9GML2","conferencePaper","2017","Fayyad, Usama M.; Candel, Arno; Rubia, Eduardo Ariño de la; Pafka, Szilárd; Chong, Anthony; Lee, Jeong-Yoon","Benchmarks and Process Management in Data Science: Will We Ever Get Over the Mess?","Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","978-1-4503-4887-4","","","https://doi.org/10.1145/3097983.3120998","","2017","2022-06-10 02:43:19","2022-07-31 14:45:38","","31–32","","","","","","","","","","","Association for Computing Machinery","Halifax, NS, Canada","","","","","","","","Type: 10.1145/3097983.3120998","","","","accuracy; data benchmarks, software implementations, training speed, accuracy, model deployment and monitoring, performance benchmarks, memory footprint, model management; Data benchmarks; memory footprint; model deployment and monitoring; model management; Performance benchmarks; software implementations; training speed; training speed, model deployment and monitoring, accuracy, software implementations, data benchmarks, model management, memory footprint, performance benchmarks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y4YAATIU","journalArticle","2016","Christen, Peter; Gayler, Ross W.; Tran, Khoi-Nguyen; Fisher, Jeffrey; Vatsalan, Dinusha","Automatic Discovery of Abnormal Values in Large Textual Databases","J. Data and Information Quality","","","","https://doi.org/10.1145/2889311","","2016","2022-06-10 02:43:19","2022-07-31 14:50:42","","Article 7","","1–2","7","","","","","","","","","","","","","","","","","ISBN: 1936-1955 Publisher: Association for Computing Machinery Type: 10.1145/2889311","","","","probabilistic language model, data quality, out-of-vocabulary, support vector machine, one-class classifier, word features, String databases, outlier detection; String databases, word features, one-class classifier, outlier detection, support vector machine, data quality, out-of-vocabulary, probabilistic language model","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XLYQ4LKR","conferencePaper","2017","Ng, Raymond","Text analytics, health analytics","1st Europe Summer School: Data Science","978-1-4503-7315-9","","","https://doi.org/10.1145/3168836.3168845","","2017","2022-06-10 02:43:19","2022-07-31 04:05:21","","Article 9","","","","","","","","","","","Association for Computing Machinery","Athens, Greece","","","","","","","","Type: 10.1145/3168836.3168845","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R3PWTVA9","conferencePaper","2018","Lv, Yirong; Sun, Bin; Luo, Qinyi; Wang, Jing; Yu, Zhibin; Qian, Xuehai","CounterMiner: mining big performance data from hardware counters","Proceedings of the 51st Annual IEEE/ACM International Symposium on Microarchitecture","978-1-5386-6240-3","","","https://doi.org/10.1109/MICRO.2018.00056","","2018","2022-06-10 02:43:19","2022-07-31 02:50:51","","613–626","","","","","","","","","","","IEEE Press","Fukuoka, Japan","","","","","","","","Type: 10.1109/MICRO.2018.00056","","","","data mining; big data; performance; computer architecture; performance counters; performance counters, data mining, computer architecture, big data; computer architecture, big data, data mining, performance counters","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HTLXS2B5","conferencePaper","2021","Chen, Jiayi; Hu, Zhiguang; Bai, Mei","AutoEncoder Network-based Pipeline for Abnormal Enterprise Data Mining","2021 4th International Conference on Computing and Big Data","978-1-4503-8719-4","","","https://doi.org/10.1145/3507524.3507528","","2021","2022-06-10 02:43:19","2022-07-31 15:38:52","","8–14","","","","","","","","","","","Association for Computing Machinery","Wuhan, China","","","","","","","","Type: 10.1145/3507524.3507528","","","http://dx.doi.org/10.1145/3507524.3507528","Pipelines; Learning systems; Inference engines; Data mining; Crime; Electric power utilization; feature engining, neural network, Additional Key Words and Phrases: data mining; neural network, Additional Key Words and Phrases: data mining, feature engining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5SZNH5HU","conferencePaper","2022","Parulian, Nikolaus Nova; Ludascher, Bertram","DCM Explorer: A Tool to Support Transparent Data Cleaning through Provenance Exploration","14th International Workshop on the Theory and Practice of Provenance, TaPP 2022, held in conjunction with SIGMOD 2022, June 17, 2022","","","10.1145/3530800.3534539","","Data cleaning and preparation are essential phases of data science and machine learning (ML) workflows. Unfortunately, data cleaning processes are rarely well documented, despite the fact that they are error-prone and often involve hundreds of individual transformation steps. We have developed DCM (Data Cleaning Model) which captures provenance information for data cleaning. In this paper, we present DCM Explorer, a companion tool for DCM to explore and use data cleaning provenance. With DCM Explorer, a user can query and visualize the data cleaning workflows that are ""hidden""in recorded provenance information, show different states of the data (as it underwent cleaning), explore an individual cell's history, etc. Through query-driven provenance reports, DCM Explorer adds valuable process documentation, making data cleaning more transparent, self-explanatory, and reusable.  2022 ACM.","2022","2022-07-27 17:24:54","2022-07-31 14:24:56","","56-61","","","","","","","Proceedings of 14th International Workshop on the Theory and Practice of Provenance, TaPP 2022","","","","Association for Computing Machinery, Inc","Philadelphia, PA, United states","","","","","","","","","","","http://dx.doi.org/10.1145/3530800.3534539","Cleaning; Metadata; scientific workflows, data provenance, transparency, data cleaning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X8C6K9G7","conferencePaper","2022","Flokas, Lampros; Wu, Weiyuan; Liu, Yejia; Wang, Jiannan; Verma, Nakul; Wu, Eugene","Complaint-Driven Training Data Debugging at Interactive Speeds","2022 ACM SIGMOD International Conference on the Management of Data, SIGMOD 2022, June 12, 2022  -  June 17, 2022","07308078","","10.1145/3514221.3517849","","Modern databases support queries that perform model inference (inference queries). Although powerful and widely used, inference queries are susceptible to incorrect results if the model is biased due to training data errors. Recently, prior work Rain proposed complaint-driven data debugging which uses user-specified errors in the output of inference queries (Complaints) to rank erroneous training examples that most likely caused the complaint. This can help users better interpret results and debug training sets. Rain combined influence analysis from the ML literature with relaxed query provenance polynomials from the DB literature to approximate the derivative of complaints w.r.t. training examples. Although effective, the runtime is O(|T|d), where T and d are the training set and model sizes, due to its reliance on the model's second order derivatives (the Hessian). On a Wide Resnet Network (WRN) model with 1.5 million parameters, it takes 1 minute to debug a complaint. We observe that most complaint debugging costs are independent of the complaint, and that modern models are overparameterized. In response, Rain++ uses precomputation techniques, based on non-trivial insights unique to data debugging, to reduce debugging latencies to a constant factor independent of model size. We also develop optimizations when the queried database is known apriori, and for standing queries over streaming databases. Combining these optimizations in Rain++ ensures interactive debugging latencies (1ms) on models with millions of parameters.  2022 ACM.","2022","2022-07-27 17:25:01","2022-07-31 02:43:30","","369-383","","","","","","","Proceedings of the ACM SIGMOD International Conference on Management of Data","","","","Association for Computing Machinery","Virtual, Online, United states","","","","","","","","","","","http://dx.doi.org/10.1145/3514221.3517849","Machine learning; Query languages; Query processing; Rain; machine learning debugging, data cleaning, data provenance","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G6EZ7KSP","conferencePaper","2019","Rahman, Musfiqur; Rigby, Peter C.; Palani, Dharani; Nguyen, Tien","Cleaning StackOverflow for machine translation","Proceedings of the 16th International Conference on Mining Software Repositories","","","","https://doi.org/10.1109/MSR.2019.00021","","2019","2022-07-27 18:07:09","2022-07-27 18:07:09","","79–83","","","","","","","","","","","IEEE Press","Montreal, Quebec, Canada","","","","","","","","Type: 10.1109/MSR.2019.00021","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KZIMFH47","journalArticle","2022","Ilyas, Ihab F.; Rekatsinas, Theodoros","Machine Learning and Data Cleaning: Which Serves the Other?","J. Data and Information Quality","","","","https://doi.org/10.1145/3506712","","2022","2022-07-27 18:07:35","2022-07-27 18:07:35","","Article 13","","3","14","","","","","","","","","","","","","","","","","ISBN: 1936-1955 Publisher: Association for Computing Machinery Type: 10.1145/3506712","","","","Machine learning, data cleaning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3B2EN9RI","journalArticle","2020","Atkinson, Gentry; Metsis, Vangelis","Identifying label noise in time-series datasets","Adjunct Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers","","","","https://doi.org/10.1145/3410530.3414366","","2020","2022-07-27 18:07:35","2022-07-31 13:27:54","","238–243","","","","","","","","","","","","","","","","","","","","Type: 10.1145/3410530.3414366","","","","human activity recognition, label noise, accelerometer, CNN, label cleaning, time-series data, neural networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KUJR4UJV","conferencePaper","2022","Dolby, Julian; Tsay, Jason; Hirzel, Martin","Automatically debugging AutoML pipelines using maro: ML automated remediation oracle","Proceedings of the 6th ACM SIGPLAN International Symposium on Machine Programming","978-1-4503-9273-0","","","https://doi.org/10.1145/3520312.3534868","","2022","2022-07-27 18:07:35","2022-07-27 18:07:35","","60–69","","","","","","","","","","","Association for Computing Machinery","San Diego, CA, USA","","","","","","","","Type: 10.1145/3520312.3534868","","","","Automated Remediation, AI Debugging, Automated Debugging, AutoML","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
