"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"HUZ7BM2N","journalArticle","2021","Jiang, JiChu; Simsek, Murat; Kantarci, Burak; Khan, Shahzad","TabCellNet: Deep learning-based tabular cell structure detection","Neurocomputing","","09252312","10.1016/j.neucom.2021.01.103","","There is an increasing demand for automated document processing techniques as the volume of electronic component documents increase. This is most prevalent in the supply chain optimization sector where vast amount of documents need to be processed and is time consuming and prone to error. Detection of tables and table structures serves as a crucial step to automate document processing. While table detection is a well investigated problem, tabular structure detection is more complex, and requires further improvements. To address this, this study proposes a deep learning model that focuses on high precision tabular cell structure detection. The proposed model creates a benchmark for the ICDAR2013 dataset cell structure with comparison to the previous state of the art table detection models as well as proposing alternative models. Our methodology approaches improving table structure detection through the detection of cells instead of row and columns for better generalization capabilities for heterogeneous table structures. Our proposed model advances prior models by improving major parts of the detection pipeline, mainly the two-stage detector, backbone, backbone architecture, and non-maximum-suppression (NMS). TabCellNet consists of Hybrid Task Cascade (HTC) with Combinational Backbone Network (CBNet), dual ResNeXt101 and Soft-NMS to achieve a precision of 89.2% and recall of 98.7% on the hand annotated ICDAR2013 cell structure dataset.  2021 Elsevier B.V.","2021","2022-06-10 02:10:41","2022-08-10 20:39:06","","12-23","","","440","","Neurocomputing","","","","","","","","","","","","","","","Publisher: Elsevier B.V.","","","http://dx.doi.org/10.1016/j.neucom.2021.01.103","Deep learning; Convolutional neural networks; Cells; Cytology; Supply chains; Image processing; Document processing; Page object detection; Structure detection; Table detection; Tabular data extraction; NETWORKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EQPRUMQE","journalArticle","2018","Madi, N; Al-Khalifa, HS","A proposed Arabic grammatical error detection tool based on deep learning","Procedia computer science","","","","https://www.sciencedirect.com/science/article/pii/S1877050918321860","… Developing a system for automating error detection in Arabic writing could help produce … tool that performs Arabic Grammatical error detection by employing a deep learning model. …","2018","2022-07-29 20:04:51","2022-08-10 19:13:09","","","","Query date: 2022-07-28 22:11:05","","","","","","","","","","","","","","","","","","Publisher: Elsevier","","","http://dx.doi.org/10.1016/j.procs.2018.10.482","Deep learning; Recurrent neural networks; Error detection; Deep neural networks; Natural language processing systems; Computational linguistics; Deep Learning; Arabic Natural Language Processing; Grammatical Error Detection; Recurrent Neural Networks","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LN5U8GFU","journalArticle","2019","Huang, S; Luo, X; Huang, J; Guo, Y; Gu, S","An unsupervised approach for learning a Chinese IS-A taxonomy from an unstructured corpus","Knowledge-Based Systems","","","","https://www.sciencedirect.com/science/article/pii/S0950705119303363","… Error detection A key challenge in error detection is that two concepts from the above … To overcome this problem, we propose a co-occurrence-coordination-based error detection …","2019","2022-07-29 20:06:26","2022-08-10 19:14:01","","","","Query date: 2022-07-28 21:07:20","","","","","","","","","","","","","","","","","","Publisher: Elsevier","","","http://dx.doi.org/10.1016/j.knosys.2019.07.032","Iterative methods; Error detection; Natural language processing systems; Semantics; Unsupervised learning; C (programming language); Text processing; Taxonomies; Chinese taxonomy learning; Relation inference; Taxonomic semantic clique","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UVWZ6CAG","journalArticle","2020","Rong, D; Wang, H; Xie, L; Ying, Y; Zhang, Y","Impurity detection of juglans using deep learning and machine vision","Computers and Electronics in …","","","","https://www.sciencedirect.com/science/article/pii/S0168169920318391","… The proposed deep-learning method is simpler and more … the white transmission belt to avoid error detection in the real factory … Future work will focus on deep learning using multi-wave …","2020","2022-07-29 20:07:35","2022-08-10 19:20:38","","","","Query date: 2022-07-28 20:03:59","","","","","","","","","","","","","","","","","","Publisher: Elsevier","","","http://dx.doi.org/10.1016/j.compag.2020.105764","Deep learning; Learning systems; Convolutional neural networks; Convolution; Computer vision; Damage detection; Image segmentation; Belt conveyors; Food safety; Impurity detection; Juglans; Machine vision","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9KDTSRMZ","journalArticle","2021","Zhang, X; Dai, G; Zhong, R; Zhou, L; Xiao, Q; Wang, X; ...","Radiomics analysis of EPID measurements for patient positioning error detection in thyroid associated ophthalmopathy radiotherapy","Physica Medica","","","","https://www.sciencedirect.com/science/article/pii/S1120179721002970","… toward machine learning-based positioning error detection … Combined radiomics and machine learning approaches are … toward machine learning-based positioning error detection …","2021","2022-07-29 20:08:58","2022-08-10 19:22:50","","","","Query date: 2022-07-28 18:03:11","","","","","","","","","","","","","","","","","","Publisher: Elsevier","","","","Machine learning; EPID dosimetry; Multifactorial error sources; Positioning error detection; Radiomics analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A2BBJ9GV","journalArticle","2021","Eshky, A; Cleland, J; Ribeiro, MS; Sugden, E; ...","Automatic audiovisual synchronisation for ultrasound tongue imaging","Speech …","","","","https://www.sciencedirect.com/science/article/pii/S0167639321000583","… in order to find the thresholds for error detection. We use these … by a self-supervised neural network, exploiting the correlation … Our approach used a self-supervised neural network which …","2021","2022-07-29 20:09:13","2022-08-10 19:14:47","","","","Query date: 2022-07-28 18:03:11","","","","","","","","","","","","","","","","","","Publisher: Elsevier","","","","Automatic audiovisual synchronisation; Synchronisation error tolerance; Ultrasound tongue imaging; Automatic audiovisual synchronisation, Synchronisation error tolerance, Ultrasound tongue imaging","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JISMXVFT","journalArticle","2022","Bedford, JL; Hanson, IM","A recurrent neural network for rapid detection of delivery errors during real-time portal dosimetry","Physics and Imaging in Radiation Oncology","","","","https://www.sciencedirect.com/science/article/pii/S2405631622000288","… When using the neural network, the median segment index for error detection was 66 out of 180, with no false positives. The neural network reduced the rate of false negative results …","2022","2022-07-29 20:11:17","2022-08-10 19:13:14","","","","Query date: 2022-07-28 19:22:13","","","","","","","","","","","","","","","","","","Publisher: Elsevier","","","","Artificial neural network; Electronic portal imaging device; In vivo dosimetry; Volumetric modulated arc therapy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QAWKLWL2","journalArticle","2022","Korzekwa, D; Lorenzo-Trueba, J; Drugman, T; ...","Computer-assisted pronunciation training—Speech synthesis is almost all you need","Speech …","","","","https://www.sciencedirect.com/science/article/pii/S0167639322000863","… We propose a reformulation of the problem of pronunciation error detection as a task of … error detection models. In the present work, we are training separate machine learning models …","2022","2022-07-29 20:11:18","2022-08-10 19:16:46","","","","Query date: 2022-07-28 19:22:13","","","","","","","","","","","","","","","","","","Publisher: Elsevier","","","http://dx.doi.org/10.1016/j.specom.2022.06.003","Deep learning; Learning systems; Error detection; Bayesian networks; Speech recognition; Computer aided instruction; Speech synthesis; Automated lexical stress error detection; Automated pronunciation error detection; Computer-assisted pronunciation training; Voice conversion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2IALBN8S","journalArticle","2022","Zhao, J; Yan, J; Xue, T; Wang, S; Qiu, X; Yao, X; ...","A deep learning method for oriented and small wheat spike detection (OSWSDet) in UAV images","… and Electronics in …","","","","https://www.sciencedirect.com/science/article/pii/S0168169922004045","… Along with various technological developments, deep-learning-based methods have … cause error detection and miss detection problems. This paper proposes a deep learning method …","2022","2022-07-29 20:11:18","2022-08-10 19:12:35","","","","Query date: 2022-07-28 19:22:13","","","","","","","","","","","","","","","","","","Publisher: Elsevier","","","http://dx.doi.org/10.1016/j.compag.2022.107087","Deep learning; Error detection; Aircraft detection; Unmanned aerial vehicles (UAV); Antennas; YOLOv5; Orientation feature; Unmanned aerial vehicle (UAV); Wheat spike detection; YOLOv5, Orientation feature, Unmanned aerial vehicle (UAV), Wheat spike detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2MJEXLNG","journalArticle","2022","Yang, B; Chen, X; Li, J; Zhu, J; Men, K; Dai, J","A feasible method to evaluate deformable image registration with deep learning–based segmentation","Physica Medica","","","","https://www.sciencedirect.com/science/article/pii/S1120179722014077","… The QA method achieved promising image registration error detection, with the following metrics for the nine ROIs: balanced accuracy, 0.946 ± 0.029; sensitivity, 0.959 ± 0.021; and …","2022","2022-07-29 20:11:19","2022-08-10 19:12:41","","","","Query date: 2022-07-28 19:22:13","","","","","","","","","","","","","","","","","","Publisher: Elsevier","","","","Deep learning; Imaging registration; Quantitative evaluation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P7MY7383","journalArticle","2022","Brion, DAJ; Shen, M; Pattinson, SW","Automated recognition and correction of warp deformation in extrusion additive manufacturing","Additive Manufacturing","","","","https://www.sciencedirect.com/science/article/pii/S2214860422002378","… deep learning, computer vision, and expert heuristics to correct or prevent warp. We train a deep convolutional neural network … in the area of AM error detection. Douglas Brion and …","2022","2022-07-29 20:11:26","2022-08-10 19:14:43","","","","Query date: 2022-07-28 19:22:13","","","","","","","","","","","","","","","","","","Publisher: Elsevier","","","http://dx.doi.org/10.1016/j.addma.2022.102838","Machine learning; Errors; Deep neural networks; Convolutional neural networks; Computer vision; Additives; 3D printers; Deformation; Extrusion; Error detection and correction; Extrusion 3D printing; Warp deformation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6ZD4A6K3","journalArticle","2022","Bauer, Markus; Augenstein, Christoph; Schafer, Martin; Theile, Oliver","Artificial Intelligence in Laser Powder Bed Fusion Procedures - Neural Networks for Live-Detection and Forecasting of Printing Failures","55th CIRP Conference on Manufacturing Systems, CIRP CMS 2022, June 29, 2022  -  July 1, 2022","","","10.1016/j.procir.2022.05.159","","Recently, many disruptive technologies like additive manufacturing were developed and have grown to production grade solutions. While such technologies can reduce the required time and amount of material, they require new methods to address long printing times and error identification in complex process structures. Such systems can be created using artificial intelligence (AI), such that operators can focus on supervising monitoring systems rather than the printing process and can decide upon preprocessed information. For the laser powder bed fusion process (LPBF), a main challenge lies in error detection per layer and in predicting the necessity of near-future operator interaction, to meet quality standards. Yet, only few works aim to automate the task of characterizing build layers. We propose an AI-driven approach to identify and forecast printing errors in LPBF using convolutional neural networks (CNNs) and the Cox proportional hazards (CPH) approach. For training and validation, layer wise greyscale images of 27 print jobs have been recorded. All print jobs' results were qualitatively rated afterwards by experts. We then perform an autoencoder-based clustering and compare print jobs of high and low quality to create pseudo-labels. We finally train a CNN in a supervised fashion to classify layers as succeeded or faulty, as well as a CPH model to estimate remaining build time without errors. We achieve an overall accuracy of 94.9% for the CNN and statistically significant forecasts (p  0.005) of the imposed hazard per layer using the CPH model. Our work demonstrates a novel approach of automated build part characterization, that reduces human operator effort and can be used for automated quality assurance and process monitoring.  2022 The Authors. Published by Elsevier B.V.","2022","2022-08-10 17:40:52","2022-08-10 19:14:21","","1367-1372","","","107","","","","Procedia CIRP","","","","","","","","","","","","","","","","http://dx.doi.org/10.1016/j.procir.2022.05.159","Neural Networks; Artificial Intelligence; Additive Manufacturing; Cox Proportional Hazards; Digital TWIN; Laser Powder Bed Fusion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JZ2FPZYN","journalArticle","2019","Ye, Jay J.","Construction and Utilization of a Neural Network Model to Predict Current Procedural Terminology Codes from Pathology Report Texts","Journal of Pathology Informatics","","2153-3539","10.4103/jpi.jpi_3_19","https://www.sciencedirect.com/science/article/pii/S2153353922003765","Background: At our department, each specimen was assigned a tentative current procedural terminology (CPT) code at accessioning. The codes were subject to subsequent changes by pathologist assistants and pathologists. After the cases had been finalized, their CPT codes went through a final verification step by coding staff, with the aid of a keyword-based CPT code-checking web application. Greater than 97% of the initial assignments were correct. This article describes the construction of a CPT code-predicting neural network model and its incorporation into the CPT code-checking application. Materials and Methods: R programming language was used. Pathology report texts and CPT codes for the cases finalized during January 1-November 30, 2018, were retrieved from the database. The order of the specimens was randomized before the data were partitioned into training and validation set. R Keras package was used for both model training and prediction. The chosen neural network had a three-layer architecture consisting of a word-embedding layer, a bidirectional long short-term memory (LSTM) layer, and a densely connected layer. It used concatenated header-diagnosis texts as the input. Results: The model predicted CPT codes in both the validation data set and the test data set with an accuracy of 97.5% and 97.6%, respectively. Closer examination of the test data set (cases from December 1 to 27, 2018) revealed two interesting observations. First, among the specimens that had incorrect initial CPT code assignments, the model disagreed with the initial assignments in 73.6% (117/159) and agreed in 26.4% (42/159). Second, the model identified nine additional specimens with incorrect CPT codes that had evaded all steps of checking. Conclusions: A neural network model using report texts to predict CPT codes can achieve high accuracy in prediction and moderate sensitivity in error detection. Neural networks may play increasing roles in CPT coding in surgical pathology.","2019-01-01","2022-08-10 18:22:58","2022-08-10 18:22:58","","13","","1","10","","Journal of Pathology Informatics","","","","","","","","","","","","","","","","","","","deep learning; neural network; Current procedural terminology codes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4PWTDHHT","journalArticle","2018","Feng, Jianyuan; Hajizadeh, Iman; Yu, Xia; Rashid, Mudassir; Turksoy, Kamuran; Samadi, Sediqeh; Sevil, Mert; Hobbs, Nicole; Brandt, Rachel; Lazaro, Caterina; Maloney, Zacharie; Littlejohn, Elizabeth; Philipson, Louis H.; Cinar, Ali","Multi-level supervision and modification of artificial pancreas control system","Computers & Chemical Engineering","","0098-1354","10.1016/j.compchemeng.2018.02.002","https://www.sciencedirect.com/science/article/pii/S0098135418300619","Artificial pancreas (AP) systems provide automated regulation of blood glucose concentration (BGC) for people with type 1 diabetes (T1D). An AP includes three components: a continuous glucose monitoring (CGM) sensor, a controller calculating insulin infusion rate based on the CGM signal, and a pump delivering the insulin amount calculated by the controller to the patient. The performance of the AP system depends on successful operation of these three components. Many APs use model predictive controllers that rely on models to predict BGC and to calculate the optimal insulin infusion rate. The performance of model-based controllers depends on the accuracy of the models that is affected by large dynamic changes in glucose-insulin metabolism or equipment performance that may move the operating conditions away from those used in developing the models and designing the control system. Sensor errors and missing signals will cause calculation of erroneous insulin infusion rates. And the performance of the controller may vary at each sampling step and each period (meal, exercise, and sleep), and from day to day. Here we describe a multi-level supervision and controller modification (ML-SCM) module is developed to supervise the performance of the AP system and retune the controller. It supervises AP performance in 3 time windows: sample level, period level, and day level. At sample level, an online controller performance assessment sub-module will generate controller performance indexes to evaluate various components of the AP system and conservatively modify the controller. A sensor error detection and signal reconciliation module will detect sensor error and reconcile the CGM sensor signal at each sample. At period level, the controller performance is evaluated with information collected during a certain time period and the controller is tuned more aggressively. At the day level, the daily CGM ranges are further analyzed to determine the adjustable range of controller parameters used for sample level and period level. Thirty subjects in the UVa/Padova metabolic simulator were used to evaluate the performance of the ML-SCM module and one clinical experiment is used to illustrate its performance in a clinical environment. The results indicate that the AP system with an ML-SCM module has a safer range of glucose concentration distribution and more appropriate insulin infusion rate suggestions than an AP system without the ML-SCM module.","2018-04-06","2022-08-10 18:23:12","2022-08-10 19:21:57","","57-69","","","112","","Computers & Chemical Engineering","","","","","","","","","","","","","","","","","","","Artificial pancreas; Controller performance assessment; Controller retuning; Sensor error detection; Type 1 diabetes","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7V645QPY","journalArticle","2022","Zhang, Zhichao; Yang, Zhoujun; Gao, Yuan; Zha, Xianqian; Jin, Ziyang; Luo, Qiang; Zheng, Wei; Zhao, Qing; Wang, Nengchao; Gao, Li; Pan, Yuan","Realization of automatic data cleaning and feedback conditioning for J-TEXT ECEI signals based on machine learning","Fusion Engineering and Design","","09203796","10.1016/j.fusengdes.2022.113065","","In recent years, Electron Cyclotron Emission Imaging (ECEI) diagnostics and many other imaging diagnostics have become increasingly important in magnetic confinement fusion research. When the image quality becomes worse due to bad pixels, it becomes an important issue for imaging diagnostics. To automatically identify and classify abnormal ECEI signals, a classification algorithm for ECEI signals based on machine learning was developed for the J-TEXT ECEI diagnostic. Incorporated with the digital control function of J-TEXT ECEI, the channels of low-attenuation saturated signals and weak signals can be corrected by adjusting the attenuation levels. At present, the automatic data cleaning and feedback conditioning unit has been set up and applied to the J-TEXT ECEI. The accuracy rate of the classification algorithm on the external test dataset reaches 93.8%. Feedback conditioning can be completed between two discharge shots. This unit can preprocess the diagnostic data for physical analysis and improve the quality of ECEI signals.  2022","2022","2022-06-10 02:09:04","2022-07-31 15:13:08","","","","","177","","Fusion Engineering and Design","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.fusengdes.2022.113065","Cleaning; Machine learning; Classification (of information); Quality control; Feedback; Cyclotrons; Statistical tests; machine learning; data cleaning; Digital control systems; ECEI signals; Electron Cyclotron Emission Imaging (ECEI) diagnostics; feedback conditioning; diagnostics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RMPMJNLK","journalArticle","2021","Hu, Xiaobin; Li, Guoqiang; Niu, Peifeng; Wang, Jianmei; Zha, Linlin","A generative adversarial neural network model for industrial boiler data repair","Applied Soft Computing","","15684946","10.1016/j.asoc.2021.107214","","Many achievements have been made in using neural networks to predict complex nonlinear industrial activities. The assumption that these prediction models established is that the various data collected by the sensors are available and accurate. However, accidents always happen beyond assumptions. The interference and damage of sensors are common phenomena in actual industrial production. In this case, the data collected by the sensors is incorrect and unavailable and cannot be fed into the prediction model for work. Incorrect data leads to inaccurate predictions, and the predictions lead to incorrect actions, which ultimately affect the activities of the entire industrial assembly line. How is this kind of problem data dealt with? This is the first time that generative adversarial networks (GAN) technology has been used to repair missing boiler data. Although GAN technology was originally used for image processing, we took the lead in transferring this technology to the issue of boiler data repair. Furthermore, we proposed a novel model structure that is more suitable for boiler data repair. Our method has rigorous theoretical feasibility and has passed the experimental test.  2021 Elsevier B.V.","2021","2022-06-10 02:09:05","2022-07-30 22:30:31","","","","","104","","Applied Soft Computing","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.asoc.2021.107214","Generative adversarial networks; Neural networks; Forecasting; Predictive analytics; Boilers; Data missing; Data repair; Industrial boiler; Image processing; Industrial boiler, Data repair, Data missing, Generative adversarial networks, 99-00, Neural networks, 00-01; OPTIMIZATION; PREDICTION; SYSTEMS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y4483VGQ","journalArticle","2022","Asakawa, Eiichi; Kaneko, Naoshi; Hasegawa, Dai; Shirakawa, Shinichi","Evaluation of text-to-gesture generation model using convolutional neural network","Neural Networks","","08936080","10.1016/j.neunet.2022.03.041","","Conversational gestures have a crucial role in realizing natural interactions with virtual agents and robots. Data-driven approaches, such as deep learning and machine learning, are promising in constructing the gesture generation model, which automatically provides the gesture motion for speech or spoken texts. This study experimentally analyzes a deep learning-based gesture generation model from spoken text using a convolutional neural network. The proposed model takes a sequence of spoken words as the input and outputs a sequence of 2D joint coordinates representing the conversational gesture motion. We prepare a dataset consisting of gesture motions and spoken texts by adding text information to an existing dataset and train the models using specific speaker's data. The quality of the generated gestures is compared with those from an existing speech-to-gesture generation model through a user perceptual study. The subjective evaluation shows that the model performance is comparable or superior to those by the existing speech-to-gesture generation model. In addition, we investigate the importance of data cleansing and loss function selection in the text-to-gesture generation model. We further examine the model transferability between speakers. The experimental results demonstrate successful model transferability of the proposed model. Finally, we show that the text-to-gesture generation model can produce good quality gestures even when using a transformer architecture.  2022 The Author(s)","2022","2022-06-10 02:09:06","2022-07-31 13:53:44","","365-375","","","151","","Neural Networks","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.neunet.2022.03.041","Deep learning; Network architecture; Convolutional neural networks; Convolution; Transfer learning; Convolutional neural network; Gesture generation; Spoken text; Transformer architecture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GGKT5CBL","journalArticle","2020","Lattar, Hafsa; Salem, Aicha Ben; Ghezala, Henda Hajjami Ben","Does data cleaning improve heart disease prediction?","24th KES International Conference on Knowledge-Based and Intelligent Information and Engineering Systems, KES 2020, September 16, 2020  -  September 18, 2020","","","10.1016/j.procs.2020.09.109","","Data quality has become an important issue. This issue becomes more and more important in medicine area, where the need for effective decision making is high. In this context, the need for data cleaning to improve data quality is becoming crucial. Duplicate records elimination is a challenging data cleansing task. In this paper, we present a duplicate records elimination approach to improve the quality of data. We propose a deep learning-based approach for duplicate records detection using a sentence embeddings model. Also, we propose an algorithm for duplicated records correction. Then, we apply the proposed duplicate records elimination approach to analyse the effect of data cleaning on the quality of decisions. We evaluate our proposal on heart disease problem using Cleveland heart disease dataset. Experiments show that the classification performance improves upon the application of the duplicate records elimination approach on datasets compared to that of datasets with duplicate records.  2020 The Authors. Published by Elsevier B.V.","2020","2022-06-10 02:09:07","2022-07-31 03:15:32","","1131-1140","","","176","","","","Procedia Computer Science","","","","","","","","","","","","","","","","http://dx.doi.org/10.1016/j.procs.2020.09.109","Cleaning; Deep learning; Classification (of information); Cardiology; Decision making; Diseases; Knowledge based systems; data cleaning; Data quality; decisions quality; deep leaning; sentence embeddings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DCGX2I3A","journalArticle","2021","Stoger, Karl; Schneeberger, David; Kieseberg, Peter; Holzinger, Andreas","Legal aspects of data cleansing in medical AI","Computer Law and Security Review","","02673649","10.1016/j.clsr.2021.105587","","Data quality is of paramount importance for the smooth functioning of modern data-driven AI applications with machine learning as a core technology. This is also true for medical AI, where malfunctions due to ""dirty data"" can have particularly dramatic harmful implications. Consequently, data cleansing is an important part in improving the usability of (Big) Data for medical AI systems. However, it should not be overlooked that data cleansing can also have negative effects on data quality if not performed carefully. This paper takes an interdisciplinary look at some of the technical and legal challenges of data cleansing against the background of European medical device law, with the key message that technical and legal aspects must always be considered together in such a sensitive context.  2021 Karl Stoger","2021","2022-06-10 02:09:07","2022-07-31 05:39:21","","","","","42","","Computer Law and Security Review","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.clsr.2021.105587","Computer networks; Security systems; Data cleansing; Data quality; Medical AI; Medical devices","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FG3N83JG","journalArticle","2018","Ma, Xiaojun; Sha, Jinglan; Wang, Dehua; Yu, Yuanbo; Yang, Qian; Niu, Xueqi","Study on a prediction of P2P network loan default based on the machine learning LightGBM and XGboost algorithms according to different high dimensional data cleaning","Electronic Commerce Research and Applications","","15674223","10.1016/j.elerap.2018.08.002","","Big data and the Internet financial sector tremendously developed in the 21st century. The national emphasis on this field has also gradually improved. Peer-to-peer (P2P) is an innovative mode of borrowing that is a powerful complement to the traditional financial industry. The projected default rate on credit is an absolute prerequisite for guaranteeing the proper operation of related financial projects or platforms. In this paper, we use multi-observation and multi-dimensional data cleaning method and apply the modern machine learning algorithms LightGBM in Asia at the end of 2016 and XGboost, which are based on real P2P transaction data from Lending club. The default risk of loans in the platform is strongly and innovatively predicted. And the results of different methods are compared. Furthermore, we observe that the LightGBM algorithm based on multiple observational data set classification prediction results is the best. The average performance rate of the historical transaction data of the Lending Club platform rose by 1.28 percentage points, which reduced loan defaults by approximately $117 million. Finally, with respect to the influencing factors of the default rate, suggested developments for the Lending club and other P2P platforms are provided as is the suggested direction of other countries development in this field.  2018 Elsevier B.V.","2018","2022-06-10 02:09:07","2022-07-31 04:13:17","","24-39","","","31","","Electronic Commerce Research and Applications","","","","","","","","","","","","","","","Publisher: Elsevier B.V.","","","http://dx.doi.org/10.1016/j.elerap.2018.08.002","Cleaning; Machine learning; Classification (of information); Learning algorithms; Clustering algorithms; Finance; Peer to peer networks; Predictive analytics; Data cleaning; Default rate; LightGBM algorithm; P2P; XGboost algorithm","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IZE74BM8","journalArticle","2022","TU, Ya; LIN, Yun; ZHA, Haoran; ZHANG, Ju; WANG, Yu; GUI, Guan; MAO, Shiwen","Large-scale real-world radio signal recognition with deep learning","","","10009361","10.1016/j.cja.2021.08.016","","In the past ten years, many high-quality datasets have been released to support the rapid development of deep learning in the fields of computer vision, voice, and natural language processing. Nowadays, deep learning has become a key research component of the Sixth-Generation wireless systems (6G) with numerous regulatory and defense applications. In order to facilitate the application of deep learning in radio signal recognition, in this work, a large-scale real-world radio signal dataset is created based on a special aeronautical monitoring system - Automatic Dependent Surveillance-Broadcast (ADS-B). This paper makes two main contributions. First, an automatic data collection and labeling system is designed to capture over-the-air ADS-B signals in the open and real-world scenario without human participation. Through data cleaning and sorting, a high-quality dataset of ADS-B signals is created for radio signal recognition. Second, we conduct an in-depth study on the performance of deep learning models using the new dataset, as well as comparison with a recognition benchmark using machine learning and deep learning methods. Finally, we conclude this paper with a discussion of open problems in this area.  2021 Chinese Society of Aeronautics and Astronautics","2022","2022-06-10 02:09:08","2022-07-31 05:43:43","","","","","","","","","Chinese Journal of Aeronautics","","","","","","","","","","","","","Publisher: Elsevier B.V.","","","http://dx.doi.org/10.1016/j.cja.2021.08.016","Deep learning; Learning algorithms; Signal processing; Large dataset; Benchmarking; Natural language processing systems; Radio broadcasting; Automatic Dependent Surveillance-Broadcast (ADS-B); Radio signal dataset; Recognition benchmark; Signal recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LZUHSJI8","journalArticle","2020","Braiek, Houssem Ben; Khomh, Foutse","On testing machine learning programs","Journal of Systems and Software","","01641212","10.1016/j.jss.2020.110542","","Nowadays, we are witnessing a wide adoption of Machine learning (ML) models in many software systems. They are even being tested in safety-critical systems, thanks to recent breakthroughs in deep learning and reinforcement learning. Many people are now interacting with systems based on ML every day, e.g., voice recognition systems used by virtual personal assistants like Amazon Alexa or Google Home. As the field of ML continues to grow, we are likely to witness transformative advances in a wide range of areas, from finance, energy, to health and transportation. Given this growing importance of ML-based systems in our daily life, it is becoming utterly important to ensure their reliability. Recently, software researchers have started adapting concepts from the software testing domain (e.g., code coverage, mutation testing, or property-based testing) to help ML engineers detect and correct faults in ML programs. This paper reviews current existing testing practices for ML programs. First, we identify and explain challenges that should be addressed when testing ML programs. Next, we report existing solutions found in the literature for testing ML programs. Finally, we identify gaps in the literature related to the testing of ML programs and make recommendations of future research directions for the scientific community. We hope that this comprehensive review of software testing practices will help ML engineers identify the right approach to improve the reliability of their ML-based systems. We also hope that the research community will act on our proposed research directions to advance the state of the art of testing for ML programs.  2020","2020","2022-06-10 02:09:09","2022-07-31 05:05:25","","","","","164","","Journal of Systems and Software","","","","","","","","","","","","","","","Publisher: Elsevier Inc.","","","http://dx.doi.org/10.1016/j.jss.2020.110542","Deep learning; Machine learning; Learning systems; Reinforcement learning; Safety engineering; Software reliability; Software testing; Data cleaning; Feature engineering testing; Implementation testing; Model testing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GZ58WHJB","journalArticle","2020","Bandekar, Shraddha Ramdas; Vijayalakshmi, C.","Design and analysis of machine learning algorithms for the reduction of crime rates in India","9th World Engineering Education Forum, WEEF 2019, November 13, 2019  -  November 16, 2019","","","10.1016/j.procs.2020.05.018","","A country's economic growth is adversely affected with the ever-increasing crimes every day. It is one of the most severe issues in our society and reducing the crime rates have become an extremely important task. Hence, it is very important to identify different factors, occurrence relations of crimes and thus determining optimized way to reduce crimes rates. For this a database must be maintained which keeps record of different crimes with details related to place, time and nature so on for future reference. This research work focuses on how machine learning algorithms can be designed and analyzed to reduce crime rates in India. By the means of machine learning techniques, determining the pattern relations among huge set of data has become easier. This research mainly depends on providing a prediction on crime type that might occur based on the location where it has already taken place. Machine learning has been used to develop a model by the use of training data set that have gone through the process of data cleaning and transformation. Analysis of data set along with its characteristics can be implemented with the aid of data visualization. The various factors are being identified and captured. Risk factors are being identified and predictive measures are designed which help in keeping society safe. Various clustering algorithms, optimization algorithms and statistical analysis has been done in this work.  2020 The Authors. Published by Elsevier B.V.","2020","2022-06-10 02:09:36","2022-07-31 14:16:12","","122-127","","","172","","","","Procedia Computer Science","","","","","","","","","","","","","","","","http://dx.doi.org/10.1016/j.procs.2020.05.018","Machine learning; Learning algorithms; Clustering algorithms; Data visualization; Crime; Economics; Engineering education; Engineering research; Metadata; Risk assessment; Optimization; Support Vector Machine; Bayesian Neural Network; Classifier Regression; K Means Clustering; K-Nearest Neighbor; Levenberg Algorithm; National Crime Records Bureau","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CHU9J5WT","journalArticle","2019","Lan, Ting; Liu, Jian; Qin, Hong; Xu, Lin Li","Time-domain global similarity method for automatic data cleaning for multi-channel measurement systems in magnetic confinement fusion devices","Computer Physics Communications","","00104655","10.1016/j.cpc.2018.07.014","","To guarantee the availability and reliability of data source in Magnetic Confinement Fusion (MCF) devices, incorrect diagnostic data, which cannot reflect real physical properties of measured objects, should be sorted out before further analysis and study. Traditional data sorting cannot meet the growing demand of MCF research because of the low-efficiency, time-delay, and lack of objective criteria. In this paper, a Time-Domain Global Similarity (TDGS) method based on machine learning technologies is proposed for the automatic data cleaning of MCF devices. The aim of traditional data sorting is to classify original diagnostic data sequences. The lengths and evolution properties of the data sequences vary shot by shot. Hence the classification criteria are affected by many discharge parameters and are different in various discharges. The focus of the TDGS method is turned to the physical similarity between data sequences from different channels, which are more independent of discharge parameters. The complexity arisen from real discharge parameters during data cleaning is avoided in the TDGS method by transforming the general data sorting problem into a binary classification problem about the physical similarity between data sequences. As a demonstration of its application to multi-channel measurement systems, the TDGS method is applied to the EAST POlarimeterINTerferometer (POINT) system. The optimal performance of the method evaluated by 24-fold cross-validation has reached 0.9871  0.0385.  2018","2019","2022-06-10 02:09:37","2022-07-31 03:14:52","","159-166","","","234","","Computer Physics Communications","","","","","","","","","","","","","","","Publisher: Elsevier B.V.","","","http://dx.doi.org/10.1016/j.cpc.2018.07.014","Cleaning; Machine learning; Classification (of information); Sorting; Metadata; Fusion reactors; Magnetism; Reliability analysis; Time domain analysis; Automatic data cleaning; Machine learning technique; Magnetic confinement fusion device; MUlti-channel measurement system; Time-domain global similarity; NEURAL-NETWORKS; INTERFEROMETER SYSTEM; LARGE HELICAL DEVICE; POLARIMETER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EZFLAUX7","journalArticle","2021","Wang, Shuai; Li, Bin; Li, Guanzheng; Yao, Bin; Wu, Jianzhong","Short-term wind power prediction based on multidimensional data cleaning and feature reconfiguration","Applied Energy","","03062619","10.1016/j.apenergy.2021.116851","","Wind power prediction decreases the uncertainty of the entire energy system, which is essential for balancing energy supply and demand. In order to improve the prediction accuracy, a short-term wind power prediction method based on data cleaning and feature reconfiguration is proposed. A large number of historical samples consisting of wind direction, wind speed, and wind power are mapped into a multidimensional sample space, and the distribution of wind data in different dimensions are analyzed in depth. By calculating the local density of each sample, outliers are effectively detected. The features of wind are reconfigured into a global information map combined with the time series information, which reflects the variation of the wind process in the short term. The features of the original data are greatly enriched, providing a high-quality training set for the prediction model. A redesigned convolutional neural network was used to predict short-term wind power, and the proposed methods were trained and tested based on a dataset of a real wind farm in China. Data cleaning and feature reconfiguration reduce the average single-point error by 1.38% and 2.56%, respectively, while the combined method reduced it by 6.24%. Plenty of experimental results show that the proposed methods achieve good performance and effectively improve the accuracy of short-term wind power prediction.  2021","2021","2022-06-10 02:09:37","2022-07-31 04:20:22","","","","","292","","Applied Energy","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.apenergy.2021.116851","Cleaning; Neural networks; Wind; Wind power; Convolution; Economics; Weather forecasting; Data cleaning; Convolutional neural network; Feature reconfiguration; Local density; Short-term wind power prediction; ALGORITHM; CONVOLUTIONAL NEURAL-NETWORK; DECOMPOSITION; ELECTRICITY; SIMULATION; SPEED PREDICTION; TURBINES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JYBPPGQV","conferencePaper","2021","Cruz, Saulo; Gilabert, Eduardo; Arnaiz, Aitor","Welding process quality improvement with machine learning techniques","17th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2021, June 7, 2021  -  June 9, 2021","","","10.1016/j.ifacol.2021.08.039","","This paper presents a methodology for selecting design parameters with influence in quality product, using data analysis and machine learning techniques applied to a manufacturing problem where execution results can provide data for design improvement. Techniques are developed and used to extract the maximum information from existing process and quality data, and therefore to get feedback at design stages regarding how parameters variations affect the product performance when certain quality tests are applied. An algorithm is developed to sample multidimensional points in order to get the most representative subset, and various techniques are applied for data cleaning and outliers detection, such as Mahalanobis distance, Cook distance and HDOutliers method. Finally, inductive learning techniques, such as decision trees and association rules, are implemented to get conclusions about the relationships of the different variables. This paper finally shows this methodology in an automotive welding scenario.  2021 The Authors. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0)","2021","2022-06-10 02:09:38","2022-07-31 03:03:14","","343-348","","","54","","","","IFAC-PapersOnLine","","","","","","","","","","","","","Issue: 1","","","http://dx.doi.org/10.1016/j.ifacol.2021.08.039","Machine learning; Learning algorithms; Decision trees; Forestry; Association rules; Product design; Welding; Quality optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TYRXCM3P","journalArticle","2021","Xu, Rui; Deng, Xiaoling; Wan, Hang; Cai, Yanpeng; Pan, Xipeng","A deep learning method to repair atmospheric environmental quality data based on Gaussian diffusion","Journal of Cleaner Production","","09596526","10.1016/j.jclepro.2021.127446","","Online monitoring data of atmospheric environmental quality often deviate or are missing, causing a great impact on regional atmospheric quality analysis. In this study, a deep learning method to repair atmospheric environmental quality data based on Gaussian diffusion and gate recurrent unit (GD-GRU) was developed to improve repair accuracy. A multi-source Gaussian diffusion model was developed to estimate PM2.5 based on the pollutant diffusion law and the data of 61 stations in Guilin. The root mean square error (RMSE) of the estimated and observed value was extracted as the error sequence. The error value was regarded as output of gate recurrent unit (GRU) with the inputs of weather and pollutant parameters. Missing data were calculated by Gaussian diffusion estimated value and the error predicted by GRU. The established GD-GRU model was applied to repair the long-sequence missing data. The analytical results indicated that the GD-GRU model had higher prediction accuracy of extreme values than Gaussian diffusion model and GRU model, because GD-GRU based on Gaussian diffusion can calculate the extreme value by simulating the diffusion and transmission mechanism. The established model predicted PM2.5 concentration in the next hours with an RMSE of 12.561, which was approximately 21.02% better, on average, than methods like autoregressive integrated moving average model (ARIMA), support vector regression (SVR), recurrent neural network (RNN), long short-term memory model (LSTM), and GRU. The established GD-GRU model demonstrated good performance on extreme values prediction and air quality data repair, thus providing a new method for air quality long-sequence missing data repair.  2021 Elsevier Ltd","2021","2022-06-10 02:09:41","2022-07-30 22:21:44","","","","","308","","Journal of Cleaner Production","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.jclepro.2021.127446","Long short-term memory; Repair; Deep learning; Errors; Air quality; Mean square error; Gaussian distribution; Diffusion; Data repair; PM2.5; PM; Gaussian diffusion; PREDICTION; MODEL; NEURAL-NETWORKS; OZONE; POLLUTANTS; POLLUTION; SUPPORT VECTOR MACHINE; TRANSFORMATION; TRANSPORT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PZLJ5JTE","journalArticle","2018","Domingues, Remi; Filippone, Maurizio; Michiardi, Pietro; Zouaoui, Jihane","A comparative evaluation of outlier detection algorithms: Experiments and analyses","Pattern Recognition","","00313203","10.1016/j.patcog.2017.09.037","","We survey unsupervised machine learning algorithms in the context of outlier detection. This task challenges state-of-the-art methods from a variety of research fields to applications including fraud detection, intrusion detection, medical diagnoses and data cleaning. The selected methods are benchmarked on publicly available datasets and novel industrial datasets. Each method is then submitted to extensive scalability, memory consumption and robustness tests in order to build a full overview of the algorithms characteristics.  2017 Elsevier Ltd","2018","2022-06-10 02:10:18","2022-07-30 21:37:06","","406-421","","","74","","Pattern Recognition","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.patcog.2017.09.037","Anomaly detection; Machine learning; Learning algorithms; Diagnosis; Statistics; Crime; Intrusion detection; Signal detection; Outlier detection; Fraud detection; Isolation forest; Novelty detection; Variational inference; isolation forest","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F6EAANP5","journalArticle","2018","Bischof, Stefan; Harth, Andreas; Kampgen, Benedikt; Polleres, Axel; Schneider, Patrik","Enriching integrated statistical open city data by combining equational knowledge and missing value imputation","Journal of Web Semantics","","15708268","10.1016/j.websem.2017.09.003","","Several institutions collect statistical data about cities, regions, and countries for various purposes. Yet, while access to high quality and recent such data is both crucial for decision makers and a means for achieving transparency to the public, all too often such collections of data remain isolated and not re-useable, let alone comparable or properly integrated. In this paper we present the Open City Data Pipeline, a focused attempt to collect, integrate, and enrich statistical data collected at city level worldwide, and re-publish the resulting dataset in a re-useable manner as Linked Data. The main features of the Open City Data Pipeline are: (i) we integrate and cleanse data from several sources in a modular and extensible, always up-to-date fashion; (ii) we use both Machine Learning techniques and reasoning over equational background knowledge to enrich the data by imputing missing values, (iii) we assess the estimated accuracy of such imputations per indicator. Additionally, (iv) we make the integrated and enriched data, including links to external data sources, such as DBpedia, available both in a web browser interface and as machine-readable Linked Data, using standard vocabularies such as QB and PROV. Apart from providing a contribution to the growing collection of data available as Linked Data, our enrichment process for missing values also contributes a novel methodology for combining rule-based inference about equational knowledge with inferences obtained from statistical Machine Learning approaches. While most existing works about inference in Linked Data have focused on ontological reasoning in RDFS and OWL, we believe that these complementary methods and particularly their combination could be fruitfully applied also in many other domains for integrating Statistical Linked Data, independent from our concrete use case of integrating city data.  2017 Elsevier B.V.","2018","2022-06-10 02:10:19","2022-07-31 13:58:30","","22-47","","","48","","Journal of Web Semantics","","","","","","","","","","","","","","","Publisher: Elsevier B.V.","","","http://dx.doi.org/10.1016/j.websem.2017.09.003","Machine learning; Pipelines; Data integration; Decision making; Knowledge based systems; Open Data; Statistics; Data acquisition; Linked data; Data cleaning; Linked Data; Open data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EEH2W5TZ","journalArticle","2022","Shende, Mayur Kishor; Feijoo-Lorenzo, Andres E.; Bokde, Neeraj Dhanraj","cleanTS: Automated (AutoML) tool to clean univariate time series at microscales","Neurocomputing","","09252312","10.1016/j.neucom.2022.05.057","","Data cleaning is one of the most important tasks in data analysis processes. One of the perennial challenges in data analytics is the detection and handling of non-valid data. Failing to do so can result in creating imbalanced observations that can cause bias and influence estimates, and in extreme cases, can even lead to inaccurate analytics and unreliable decisions. Usually, the process of data cleaning is time-consuming due to its growing volume, velocity, and variety. Further, the complexity and difficulty of the cleaning process increase with the amount of data to be analyzed. It is rarely the case that any real-world data is clean and error-free. Thus, pre-processing the data before using it for analysis has become standard practice. This paper is intended to provide an easy-to-use and reliable system which automates the cleaning process for univariate time series data. Also, automating the process reduces the time required for cleaning it. Another issue that the proposed system aims to solve is making the visualization of a large amount of data more effective. To tackle these issues, an R package, cleanTS is proposed. The proposed system provides a way to analyze data on different scales and resolutions. Also, it provides users with tools and a benchmark system for comparing various techniques used in data cleaning.  2022 The Author(s)","2022","2022-06-10 02:10:20","2022-07-31 14:36:02","","155-176","","","500","","Neurocomputing","","","","","","","","","","","","","","","Publisher: Elsevier B.V.","","","http://dx.doi.org/10.1016/j.neucom.2022.05.057","Cleaning; Data handling; Machine learning; Data Analytics; Time series analysis; Data visualization; Bleaching; Harmonic analysis; Data cleaning; AutoML; Time series cleaning; BIG DATA; ANALYTICS; BUSINESS INTELLIGENCE; MISSING VALUE IMPUTATION; R PACKAGE; STATE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AXMSTKF8","journalArticle","2022","Chen, Peng; Du, Xin; Lu, Zhihui; Wu, Jie; Hung, Patrick C.K.","EVFL: An explainable vertical federated learning for data-oriented Artificial Intelligence systems","Journal of Systems Architecture","","13837621","10.1016/j.sysarc.2022.102474","","Vertical federated learning (VFL), as one of the latest advances of security in the data-oriented Artificial Intelligence (AI) systems, facilitates better keeping the AI systems converge faster with higher performance and security. Since a large amount of data from these systems is often of low quality, the training data needs to be interpreted and evaluated. While there have been some research efforts, they still have significant shortcomings, such as high computational complexity and impracticality. Considering the characteristics of the data, the interpretation of machine learning models allows for data cleansing, which can improve data quality and help regulators understand the decision-making process. In this paper, we propose an explainable vertical federated learning (EVFL) framework, including the credibility assessment strategy, the federated counterfactual explanation and the importance rate (IR) metric. Furthermore, we initialize the knowledge-based counterfactual instance based on prior knowledge and retrain the federated counterfactual method for feasible counterfactual features. We report experimental results obtained on the Lending Club and Zhongyuan datasets for implementing our framework to show that our approach is significantly effective. Notably, on the Lending Club dataset, our method can have a +4.9% improvement over other selections.  2022 Elsevier B.V.","2022","2022-06-10 02:10:24","2022-07-31 13:52:54","","","","","126","","Journal of Systems Architecture","","","","","","","","","","","","","","","Publisher: Elsevier B.V.","","","http://dx.doi.org/10.1016/j.sysarc.2022.102474","Learning systems; Decision making; Knowledge based systems; Data cleansing; Data-oriented AI; Feature importance; Federated counterfactual explanation; Vertical federated learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4TLDHUZY","journalArticle","2018","Wang, Zhengyi; Liang, Man; Delahaye, Daniel","A hybrid machine learning model for short-term estimated time of arrival prediction in terminal manoeuvring area","Transportation Research Part C: Emerging Technologies","","0968090X","10.1016/j.trc.2018.07.019","","4D trajectory prediction is the core element of future air transportation system, which is intended to improve the operational ability and the predictability of air traffic. In this paper, we introduce a novel hybrid model to address the short-term trajectory prediction problem in Terminal Manoeuvring Area (TMA) by application of machine learning methods. The proposed model consists of two parts: clustering-based preprocessing and Multi-Cells Neural Network (MCNN)-based prediction. Firstly, in the preprocessing part, after data cleaning, filtering and data re-sampling, we applied principal Component Analysis (PCA) to reduce the dimension of trajectory vector variable. Then, the trajectories are clustered into several patterns by clustering algorithm. Using nested cross validation, MCNN model is trained to find out the appropriate prediction model of Estimated Time of Arrival (ETA) for each individual cluster cell. Finally, the predicted ETA for each new flight is generated in different cluster cells classified by decision trees. To assess the performance of MCNN model, the Multiple Linear Regression (MLR) model is proposed as the comparison learning model, and K-means++ and DBSCAN are proposed as two comparison clustering models in preprocessing part. With real 4D trajectory data in Beijing TMA, experimental results demonstrate that our proposed model MCNN with DBSCAN in preprocessing is the most effective and robust hybrid machine learning model, both in trajectory clustering and short-term 4D trajectory prediction. In addition, it can make an accurate trajectory prediction in terms of Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) with regards to comparison models.  2018 Elsevier Ltd","2018","2022-06-10 02:10:27","2022-07-30 22:34:19","","280-294","","","95","","Transportation Research Part C: Emerging Technologies","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.trc.2018.07.019","Machine learning; Learning systems; Neural networks; Decision trees; Forecasting; Predictive analytics; Information management; Data mining; Air traffic control; Mean square error; Linear regression; Air transportation; Cells; Cytology; K-means clustering; Time of arrival; Trajectories; Clustering; 4D trajectory prediction; Air traffic management; Multi-cells neural network; TRAJECTORY PREDICTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UHAV22EX","journalArticle","2020","Gangavarapu, Tushaar; Jayasimha, Aditya; Krishnan, Gokul S.; Sowmya Kamath, S.","Predicting ICD-9 code groups with fuzzy similarity based supervised multi-label classification of unstructured clinical nursing notes","Knowledge-Based Systems","","09507051","10.1016/j.knosys.2019.105321","","In hospitals, caregivers are trained to chronicle the subtle changes in the clinical conditions of a patient at regular intervals, for enabling decision-making. Caregivers text-based clinical notes are a significant source of rich patient-specific data, that can facilitate effective clinical decision support, despite which, this treasure-trove of data remains largely unexplored for supporting the prediction of clinical outcomes. The application of sophisticated data modeling and prediction algorithms with greater computational capacity have made disease prediction from raw clinical notes a relevant problem. In this paper, we propose an approach based on vector space and topic modeling, to structure the raw clinical data by capturing the semantic information in the nursing notes. Fuzzy similarity based data cleansing approach was used to merge anomalous and redundant patient data. Furthermore, we utilize eight supervised multi-label classification models to facilitate disease (ICD-9 code group) prediction. We present an exhaustive comparative study to evaluate the performance of the proposed approaches using standard evaluation metrics. Experimental validation on MIMIC-III, an open database, underscored the superior performance of the proposed Term weighting of unstructured notes AGgregated using fuzzy Similarity (TAGS) model, which consistently outperformed the state-of-the-art structured data based approach by 7.79% in AUPRC and 1.24% in AUROC.  2019 Elsevier B.V.","2020","2022-06-10 02:10:29","2022-07-31 04:44:40","","","","","190","","Knowledge-Based Systems","","","","","","","","","","","","","","","Publisher: Elsevier B.V.","","","http://dx.doi.org/10.1016/j.knosys.2019.105321","Machine learning; Classification (of information); Learning systems; Forecasting; Decision making; Predictive analytics; Codes (symbols); Natural language processing systems; Semantics; Decision support systems; Fuzzy logic; Vector spaces; Nursing; Natural language processing; Hospital data processing; Healthcare analytics, Disease prediction, Machine learning, Natural language processing, ICD-9 code group prediction, Clinical decision support systems; Clinical decision support systems; Disease prediction; Healthcare analytics; ICD-9 code group prediction; NEURAL-NETWORKS; ACUTE PHYSIOLOGY; APACHE; CHRONIC HEALTH EVALUATION; HOSPITAL MORTALITY; INTENSIVE-CARE-UNIT; MODELS; LEARNING APPROACH; MORTALITY PREDICTION; STAY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y7LXDBP2","journalArticle","2021","Sun, Xian; Wang, Peijin; Yan, Zhiyuan; Wang, Cheng; Diao, Wenhui; Chen, Jin; Li, Jihao; Feng, Yingchao; Xu, Tao; Weinmann, Martin; Hinz, Stefan; Fu, Kun","FAIR1M: A benchmark dataset for fine-grained object recognition in high-resolution remote sensing imagery","","","23318422","","","With the rapid development of deep learning, many deep learning based approaches have made great achievements in object detection task. It is generally known that deep learning is a data-driven method. Data directly impact the performance of object detectors to some extent. Although existing datasets have included common objects in remote sensing images, they still have some limitations in terms of scale, categories, and images. Therefore, there is a strong requirement for establishing a large-scale benchmark on object detection in high-resolution remote sensing images. In this paper, we propose a novel benchmark dataset with more than 1 million instances and more than 15,000 images for Fine-grAined object recognItion in high-Resolution remote sensing imagery which is named as FAIR1M. We collected remote sensing images with a resolution of 0.3m to 0.8m from different platforms, which are spread across many countries and regions. All objects in the FAIR1M dataset are annotated with respect to 5 categories and 37 sub-categories by oriented bounding boxes. Compared with existing detection datasets dedicated to object detection, the FAIR1M dataset has 4 particular characteristics: (1) it is much larger than other existing object detection datasets both in terms of the quantity of instances and the quantity of images, (2) it provides more rich fine-grained category information for objects in remote sensing images, (3) it contains geographic information such as latitude, longitude and resolution, (4) it provides better image quality owing to a careful data cleaning procedure. To establish a baseline for fine-grained object recognition, we propose a novel evaluation method and benchmark fine-grained object detection tasks and a visual classification task using several State-Of-The-Art (SOTA) deep learning based models on our FAIR1M dataset. Experimental results strongly indicate that the FAIR1M dataset is closer to practical application and it is considerably more challenging than existing datasets. Researchers can better investigate fine-grained object detection algorithms with the help of the FAIR1M dataset. Copyright  2021, The Authors. All rights reserved.","2021","2022-06-10 02:10:30","2022-07-31 13:46:18","","","","","","","","","arXiv","","","","","","","","","","","","","Publisher: arXiv","","","http://dx.doi.org/10.1016/j.isprsjprs.2021.12.004","Deep learning; Classification (of information); Large dataset; Convolutional neural networks; Object detection; Object recognition; Remote sensing; Transfer learning; Image enhancement; Convolutional neural network (CNN); Benchmark dataset; Fine-grained object detection and recognition; Remote sensing images; CONVOLUTIONAL NEURAL-NETWORK; TARGET DETECTION; VEHICLE DETECTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9R6CEY66","journalArticle","2017","Bahmani, Zeinab; Bertossi, Leopoldo; Vasiloglou, Nikolaos","ERBlox: Combining matching dependencies with machine learning for entity resolution","International Journal of Approximate Reasoning","","0888613X","10.1016/j.ijar.2017.01.003","","Entity resolution (ER), an important and common data cleaning problem, is about detecting data duplicate representations for the same external entities, and merging them into single representations. Relatively recently, declarative rules called matching dependencies (MDs) have been proposed for specifying similarity conditions under which attribute values in database records are merged. In this work we show the process and the benefits of integrating four components of ER: (a) Building a classifier for duplicate/non-duplicate record pairs built using machine learning (ML) techniques; (b) Use of MDs for supporting the blocking phase of ML; (c) Record merging on the basis of the classifier results; and (d) The use of the declarative language LogiQLan extended form of Datalog supported by the LogicBlox platformfor all activities related to data processing, and the specification and enforcement of MDs.  2017 Elsevier Inc.","2017","2022-06-10 02:10:30","2022-07-31 13:57:37","","118-141","","","83","","International Journal of Approximate Reasoning","","","","","","","","","","","","","","","Publisher: Elsevier Inc.","","","http://dx.doi.org/10.1016/j.ijar.2017.01.003","Classification (of information); Learning systems; Support vector machines; C (programming language); Merging; Classification; Datalog; Entity resolution; Matching dependencies; Support-vector machines; LINKAGE; BLOCKING TECHNIQUES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XFZRAIXL","journalArticle","2016","Gottapu, Ram Deepak; Dagli, Cihan; Ali, Bharami","Entity Resolution Using Convolutional Neural Network","Complex Adaptive Systems, 2016, November 2, 2016  -  November 4, 2016","","","10.1016/j.procs.2016.09.306","","Entity resolution is an important application in field of data cleaning. Standard approaches like deterministic methods and probabilistic methods are generally used for this purpose. Many new approaches using single layer perceptron, crowdsourcing etc. are developed to improve the efficiency and also to reduce the time of entity resolution. The approaches used for this purpose also depend on the type of dataset, labeled or unlabeled. This paper presents a new method for labeled data which uses single layered convolutional neural network to perform entity resolution. It also describes how crowdsourcing can be used with the output of the convolutional neural network to further improve the accuracy of the approach while minimizing the cost of crowdsourcing. The paper also discusses the data pre-processing steps used for training the convolutional neural network. Finally it describes the airplane sensor dataset which is used for demonstration of this approach and then shows the experimental results achieved using convolutional neural network.  2016 The Authors.","2016","2022-06-10 02:10:31","2022-07-31 13:57:51","","153-158","","","95","","","","Procedia Computer Science","","","","","","","","","","","","","","","","http://dx.doi.org/10.1016/j.procs.2016.09.306","Data handling; Convolutional neural networks; Convolution; Crowdsourcing; Multilayer neural networks; Network layers; Complex networks; Adaptive systems; crowdsourcing; convolutional neural network; hybrid machine-human model; word embedding; word stemming; stemming","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6L8X5BHR","journalArticle","2021","Yin, Qishuai; Yang, Jin; Tyagi, Mayank; Zhou, Xu; Hou, Xinxin; Cao, Bohan","Field data analysis and risk assessment of gas kick during industrial deepwater drilling process based on supervised learning algorithm","Process Safety and Environmental Protection","","09575820","10.1016/j.psep.2020.08.012","","During industrial offshore deep-water drilling process, gas kick event occurs frequently due to extremely narrow Mud Weight (MW) window (minimum 0.01sg) and negligible safety margins for the well control purposes. Further, traditional gas kick detection methods in such environments have significant time-lag and can often lead to severe well control issues, and occasionally to well blowouts or borehole abandonment. In this study, firstly, the raw field data is processed through data collection, data cleaning, feature scaling, outlier detection, data labeling and dataset splitting. Additionally, a novel data labeling criterion for gas kick risks is proposed where five kick risks (Indicated by different colors in this study) are defined based on three key indicators: differential flow out (DFO), kick gain volume (Vol), and kick duration time (Time). Kick risk status represents one of the following cases: Case 0 - No indicators are activated (Green), Case 1 - Multi-drilling parameters deviation or DFO is activated (Orange), Case 2 - DFO and Vol are simultaneously activated (Light Red), Case 3 - DFO and Time are simultaneously activated (Light Red), Case 4 - DFO, Vol and Time alarms are simultaneously activated (Dark Red). Then, a novel data mining method using Long Short-Term Memory (LSTM) Recurrent Neural Network (RNN) is presented for early detection of gas kick events by analyzing time series data from field drilling process. The network parameters such as number of hidden layers and number of neurons are initialized to build the LSTM network. The learned LSTM model is evaluated using the testing set, and the best LSTM model (six (6)-layers eighty (80)-nodes (6 L*80 N)) is optimally selected and deployed. The accuracy of deployed LSTM model is 87 % in the testing dataset, which is reliable enough to identify the kick fault during the deep-water drilling field operation. Lastly, the LSTM model detected the gas kick events earlier than the ""Tank Volume"" detection method in several representative case studies to conclude that the application of LSTM model can potentially improve well control safety in the deep-water wells with narrow MW windows.  2020","2021","2022-06-10 02:10:40","2022-07-31 13:42:43","","312-328","","","146","","Process Safety and Environmental Protection","","","","","","","","","","","","","","","Publisher: Institution of Chemical Engineers","","","http://dx.doi.org/10.1016/j.psep.2020.08.012","Long short-term memory; Data handling; Learning algorithms; Statistical tests; Data mining; Data acquisition; Supervised learning; Risk assessment; Infill drilling; Gases; Deepwater drilling; Chemical detection; Offshore oil well production; Abandoned wells; Accident prevention; Offshore gas wells; Risk analysis; Water wells; Early gas; Field data analysis; Gas kick; Industrial deep-water drilling; Kick detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"998U7MJW","journalArticle","2021","Ouyang, Boya; Song, Yu; Li, Yuhai; Sant, Gaurav; Bauchy, Mathieu","EBOD: An ensemble-based outlier detection algorithm for noisy datasets","Knowledge-Based Systems","","09507051","10.1016/j.knosys.2021.107400","","Real-world datasets often comprise outliers (e.g., due to operational error, intrinsic variability of the measurements, recording mistakes, etc.) and, hence, require cleansing as a prerequisite to any meaningful machine learning analysis. However, data cleansing is often a laborious task that requires intuition or expert knowledge. In particular, selecting an outlier detection algorithm is challenging as this choice is dataset-specific and depends on the nature of the considered dataset. These difficulties have prevented the development of a ""one-fits-all"" approach for the cleansing of real-world, noisy datasets. Here, we present an unsupervised, ensemble-based outlier detection (EBOD) approach that considers the union of different outlier detection algorithms, wherein each of the selected detectors is only responsible for identifying a small number of outliers that are the most obvious from their respective standpoints. The use of an ensemble of weak detectors reduces the risk of bias during outlier detection as compared to using a single detector. The optimal combination of detectors is determined by forwardbackward search. By taking the example of a noisy dataset of concrete strength measurements as well as a broad collection of benchmark datasets, we demonstrate that our EBOD method systematically outperforms all alternative detectors, when used individually or in combination. Based on this new outlier detection method, we explore how data cleansing affects the complexity, training, and accuracy of an artificial neural network.  2021 The Authors","2021","2022-06-10 02:10:40","2022-07-31 03:21:41","","","","","231","","Knowledge-Based Systems","","","","","","","","","","","","","","","Publisher: Elsevier B.V.","","","http://dx.doi.org/10.1016/j.knosys.2021.107400","Anomaly detection; Data handling; Machine learning; Neural networks; Statistics; Signal detection; Concretes; Concrete strength; Data cleansing; Outlier detection; Concrete strength, Machine learning, Outlier detection, Data cleansing; CONCRETE; MACHINE; NETWORKS; RATIO; STRENGTH; SUPPORT","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B96MJW72","journalArticle","2019","Tran, Anh; Furlan, John M.; Pagalthivarthi, Krishnan V.; Visintainer, Robert J.; Wildey, Tim; Wang, Yan","WearGP: A computationally efficient machine learning framework for local erosive wear predictions via nodal Gaussian processes","Wear","","00431648","10.1016/j.wear.2018.12.081","","Computational fluid dynamics (CFD)-based wear predictions are computationally expensive to evaluate, even with a high-performance computing infrastructure. Thus, it is difficult to provide accurate local wear predictions in a timely manner. Data-driven approaches provide a more computationally efficient way to approximate the CFD wear predictions without running the actual CFD wear models. In this paper, a machine learning (ML) approach, termed WearGP, is presented to approximate the 3D local wear predictions, using numerical wear predictions from steady-state CFD simulations as training and testing datasets. The proposed framework is built on Gaussian process (GP) and utilized to predict wear in a much shorter time. The WearGP framework can be segmented into three stages. At the first stage, the training dataset is built by using a number of CFD simulations in the order of O(102). At the second stage, the data cleansing and data mining processes are performed, where the nodal wear solutions are extracted from the solution database to build a training dataset. At the third stage, the wear predictions are made, using trained GP models. Two CFD case studies including 3D slurry pump impeller and casing are used to demonstrate the WearGP framework, in which 144 training and 40 testing data points are used to train and test the proposed method, respectively. The numerical accuracy, computational efficiency and effectiveness between the WearGP framework and CFD wear model for both slurry pump impellers and casings are compared. It is shown that the WearGP framework can achieve highly accurate results that are comparable with the CFD results, with a relatively small size training dataset, with a computational time reduction on the order of 105 to 106.  2018 Elsevier B.V.","2019","2022-06-10 02:10:41","2022-07-31 03:36:59","","9-26","","","422-423","","Wear","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.wear.2018.12.081","Machine learning; Learning systems; Forecasting; Predictive analytics; Data mining; Computational efficiency; Gaussian distribution; Gaussian noise (electronic); Computational fluid dynamics; Impellers; Pumps; Slurry pipelines; Wear of materials; Gaussian process; Multiphase computational fluid dynamics; Slurry pump; Wear; MODEL; PARTICLE EROSION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CHV8SSAW","journalArticle","2019","Maitre, Julien; Bouchard, Kevin; Bedard, L. Paul","Mineral grains recognition using computer vision and machine learning","Computers and Geosciences","","00983004","10.1016/j.cageo.2019.05.009","","Identifying and counting individual mineral grains composing sand is an important component of many studies in environment, engineering, mineral exploration, ore processing and the foundation of geometallurgy. Typically, silt (32128m) and sand (1281000m) sized grains will be characterized under an optical microscope or a scanning electron microscope. In both cases, it is a tedious and costly process. Therefore, in this paper, we introduce an original computational approach in order to automate mineral grains recognition from numerical images obtained with a simple optical microscope. To the best of our knowledge, it is the first time that the current computer vision based on machine learning algorithms is tested for the automated recognition of such mineral grains. In more details, this work uses the simple linear iterative clustering segmentation to generate superpixels and many of them allow isolating sand grains, which is not possible with classical segmentation methods. Also, the approach has been tested using convolutional neural networks (CNNs). However, CNNs did not give as good results as the superpixels method. The superpixels are also exploited to extract features related to a sand grain. These image characteristics form the raw dataset. Prior to proceed with the classification, a data cleaning stage is necessary to get a usable dataset for machine learning algorithms. In addition, we present a comparison of performances of several algorithms. The overall obtained results are approximately 90% and demonstrate the concept of mineral recognition from a sample of sand grains provided by a numerical image.  2019 The Authors","2019","2022-06-10 02:10:41","2022-07-31 03:08:49","","84-93","","","130","","Computers and Geosciences","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.cageo.2019.05.009","Machine learning; Classification (of information); Learning algorithms; Learning systems; Iterative methods; Convolutional neural networks; Computer vision; Classification; Image segmentation; Image processing; Microscopes; Mineral exploration; Optical data processing; Ores; Sand; Scanning electron microscopy; Superpixels; Sand grain, Features, Machine learning, Recognition, Classification, Segmentation, Image processing, Ore; Features; Ore; Recognition; Sand grain; Segmentation; ELECTRON-MICROSCOPY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HUZ7BM2N","journalArticle","2021","Jiang, JiChu; Simsek, Murat; Kantarci, Burak; Khan, Shahzad","TabCellNet: Deep learning-based tabular cell structure detection","Neurocomputing","","09252312","10.1016/j.neucom.2021.01.103","","There is an increasing demand for automated document processing techniques as the volume of electronic component documents increase. This is most prevalent in the supply chain optimization sector where vast amount of documents need to be processed and is time consuming and prone to error. Detection of tables and table structures serves as a crucial step to automate document processing. While table detection is a well investigated problem, tabular structure detection is more complex, and requires further improvements. To address this, this study proposes a deep learning model that focuses on high precision tabular cell structure detection. The proposed model creates a benchmark for the ICDAR2013 dataset cell structure with comparison to the previous state of the art table detection models as well as proposing alternative models. Our methodology approaches improving table structure detection through the detection of cells instead of row and columns for better generalization capabilities for heterogeneous table structures. Our proposed model advances prior models by improving major parts of the detection pipeline, mainly the two-stage detector, backbone, backbone architecture, and non-maximum-suppression (NMS). TabCellNet consists of Hybrid Task Cascade (HTC) with Combinational Backbone Network (CBNet), dual ResNeXt101 and Soft-NMS to achieve a precision of 89.2% and recall of 98.7% on the hand annotated ICDAR2013 cell structure dataset.  2021 Elsevier B.V.","2021","2022-06-10 02:10:41","2022-08-10 20:39:06","","12-23","","","440","","Neurocomputing","","","","","","","","","","","","","","","Publisher: Elsevier B.V.","","","http://dx.doi.org/10.1016/j.neucom.2021.01.103","Deep learning; Convolutional neural networks; Cells; Cytology; Supply chains; Image processing; Document processing; Page object detection; Structure detection; Table detection; Tabular data extraction; NETWORKS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MDJCYGRU","journalArticle","2021","Olabanjo, Olusola A.; Aribisala, Benjamin S.; Mazzara, Manuel; Wusu, Ashiribo S.","An ensemble machine learning model for the prediction of danger zones: Towards a global counter-terrorism","Soft Computing Letters","","26662221","10.1016/j.socl.2021.100020","","Terrorism can be described as the use of violence against persons or properties to intimidate or coerce a government or its citizens to some certain political or social objectives. It is a global problem which has led to loss of lives and properties and known to have negative impacts on tourism and global economy. Terrorism has also been associated with high level of insecurity and most nations of the world are interested in any research efforts that can reduce its menace. Most of the research efforts on terrorism have focused on measures to fight terrorism or how to reduce the activities of terrorists but there are limited efforts on terrorism prediction. The aim of this work is to develop an ensemble machine learning model which combines Support Vector Machine and K-Nearest Neighbor for prediction of continents susceptible to terrorism. Data was obtained from Global Terrorism Database and data preprocessing included data cleaning and dimensionality reduction. Two feature selection techniques, Chi-squared, Information Gain and a hybrid of both were applied to the dataset before modeling. Ensemble machine learning models were then constructed and applied on the selected features. Chi-squared, Information Gain and the hybrid-based features produced an accuracy of 94.17%, 97.34% and 97.81% respectively at predicting danger zones with respective sensitivity scores of 82.3%, 88.7% and 92.2% and specificity scores of 98%, 90.5% and 99.67% respectively. These imply that the hybrid-based selected features produced the best results among the feature selection techniques at predicting terrorism locations. Our results show that ensemble machine learning model can accurately predict terrorism locations.  2021 The Author(s)","2021","2022-06-10 02:10:42","2022-07-31 02:21:06","","","","","3","","Soft Computing Letters","","","","","","","","","","","","","","","Publisher: Elsevier B.V.","","","http://dx.doi.org/10.1016/j.socl.2021.100020","Support vector machines; Forecasting; Feature extraction; Nearest neighbor search; Terrorism; Danger zones; Ensemble machine learning; Support vector machine","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WST5GQRC","journalArticle","2020","Huyghues-Beaufond, Nathalie; Tindemans, Simon; Falugi, Paola; Sun, Mingyang; Strbac, Goran","Robust and automatic data cleansing method for short-term load forecasting of distribution feeders","Applied Energy","","03062619","10.1016/j.apenergy.2019.114405","","Distribution networks are undergoing fundamental changes at medium voltage level. To support growing planning and control decision-making, the need for large numbers of short-term load forecasts has emerged. Data-driven modelling of medium voltage feeders can be affected by (1) data quality issues, namely, large gross errors and missing observations (2) the presence of structural breaks in the data due to occasional network reconfiguration and load transfers. The present work investigates and reports on the effects of advanced data cleansing techniques on forecast accuracy. A hybrid framework to detect and remove outliers in large datasets is proposed; this automatic procedure combines the Tukey labelling rule and the binary segmentation algorithm to cleanse data more efficiently, it is fast and easy to implement. Various approaches for missing value imputation are investigated, including unconditional mean, Hot Deck via k-nearest neighbour and Kalman smoothing. A combination of the automatic detection/removal of outliers and the imputation methods mentioned above are implemented to cleanse time series of 342 medium-voltage feeders. A nested rolling-origin-validation technique is used to evaluate the feed-forward deep neural network models. The proposed data cleansing framework efficiently removes outliers from the data, and the accuracy of forecasts is improved. It is found that Hot Deck (k-NN) imputation performs best in balancing the bias-variance trade-off for short-term forecasting.  2019","2020","2022-06-10 02:10:43","2022-07-31 04:32:16","","","","","261","","Applied Energy","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.apenergy.2019.114405","Anomaly detection; Forecasting; Decision making; Deep neural networks; Large dataset; Statistics; Nearest neighbor search; Economic and social effects; Electric power plant loads; Feeding; Outlier detection; Binary segmentation; Distribution systems; Kalman smoothing; Multi-step forecasts; PERFORMANCE; TIME-SERIES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NMY7LTWY","journalArticle","2020","Ataeyan, Mahdieh; Daneshpour, Negin","A novel data repairing approach based on constraints and ensemble learning","Expert Systems with Applications","","09574174","10.1016/j.eswa.2020.113511","","Data repairing is an important task in data mining. This paper proposes a novel data repairing approach based on a combination of constraints and ensemble learning. At first, functional dependencies (FDs) are used as constraints to identify inconsistent records. For each FD, all repeated values in the correct records are discovered. After that, noisy attributes in erroneous records are detected using correct records and the repeated values. To correct the detected noises, a supervised ensemble learning model is constructed for each attribute. The ensemble model consists of a Bayes classifier, a decision tree, and a MultiLayer Perceptron (MLP). A majority of votes is used as the combination strategy in the ensemble learning model. The proposed approach automatically repairs data without any user interaction. Moreover, the proposed method can detect more than one noise in a record. Experimental results show that our approach outperforms similar repairing algorithms (HoloClean and KATARA) in both terms of precision and recall.  2020 Elsevier Ltd","2020","2022-06-10 02:10:46","2022-07-30 22:48:26","","","","","159","","Expert Systems with Applications","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.eswa.2020.113511","Learning systems; Decision trees; Data mining; Multilayer neural networks; Ensemble learning; Data repairing; Functional dependency; Noise detection","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WJNMXL8D","journalArticle","2020","Liu, Yu; Pang, Zhibo; Karlsson, Magnus; Gong, Shaofang","Anomaly detection based on machine learning in IoT-based vertical plant wall for indoor climate control","Building and Environment","","03601323","10.1016/j.buildenv.2020.107212","","Indoor climate is closely related to human health, comfort and productivity. Vertical plant wall systems, embedded with sensors and actuators, have become a promising application for indoor climate control. In this study, we explore the possibility of applying machine learning based anomaly detection methods to vertical plant wall systems so as to enhance the automation and improve the intelligence to realize predictive maintenance of the indoor climate. Two categories of anomalies, namely point anomalies and contextual anomalies are researched. Prediction-based and pattern recognition-based methods are investigated and applied to indoor climate anomaly detection. The results show that neural network-based models, specifically the autoencoder (AE) and the long short-term memory encoder decoder (LSTM-ED) model surpass the others in terms of detecting point anomalies and contextual anomalies, respectively, therefore can be deployed into vertical plant walls systems in industrial practice. Based on the results, a new data cleaning method is proposed and a prediction-based method is deployed to the cloud in practice as a proof-of-concept. This study showcases the advancements in machine learning and Internet of things can be fully utilized by researches on building environment to accelerate the solution development.  2020 The Authors","2020","2022-06-10 02:10:49","2022-07-31 02:32:38","","","","","183","","Building and Environment","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.buildenv.2020.107212","Anomaly detection; Long short-term memory; Machine learning; Neural networks; Pattern recognition; Internet of things; Climate control; Embedded systems; Walls (structural partitions); Internet of Things; Indoor climate control; Vertical plant wall; PREDICTION; PERFORMANCE; SYSTEM; AIR; ENVIRONMENTAL-QUALITY; HUMIDITY; LIVING WALL; TEMPERATURE; THERMAL-BEHAVIOR","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I24GAPUM","journalArticle","2022","Zhang, Limao; Pan, Yue","Information fusion for automated post-disaster building damage evaluation using deep neural network","Sustainable Cities and Society","","22106707","10.1016/j.scs.2021.103574","","This paper develops a hybrid neural network architecture named multi-class factorization machine with deep neural network (multi-FMDNN) to fuse multi-source information for the automatic post-earthquake building damage evaluation. The novel algorithm is a combination of the factorization machine (FM) and the deep neural network (DNN), which adopts the one-vs-all strategy to fuse results from multiple base classifiers. 39,352 buildings affected by the 2015 Nepal earthquake are taken as a case study to validate the effectiveness of the proposed multi-FMDNN. Experimental results confirm that the proposed model outperforms over many other popular machine learning methods due to the powerful feature learning ability, ultimately reaching an overall accuracy, macro F1-score, and weighted F1-score in the value of 0.703, 0.737, and 0.702, respectively. Features associated with building structural characteristics are found to contribute more to classifying damage grades precisely. Besides, data preprocessing for data cleaning, encoding, and transformation is a necessary step to bring additional performance enhancement. For significance in the knowledge aspect, a novel multi-FMDNN algorithm is developed, which is superior in extracting both low- and high-order feature representation automatically from large volumes of destroyed buildings-related data and learning the optimal feature interactions simultaneously to pursue more accurate classification. For significance in the application aspect, the predicted results provide deep insights into a better understanding of the building vulnerability in seismic areas and inform data-driven decisions in disaster relief efforts. A promising future scope is to make full use of the available pre-event data along with some post-event data, which is possible to return fairly promising predictions and reduce the burden in earthquake field investigations for rapid responses. In future work, advanced techniques associated with data augment, hyperparameter optimization, and others will be implemented to constantly improve the overall accuracy and generalizability of the prediction model.  2021 Elsevier Ltd","2022","2022-06-10 02:10:49","2022-07-31 05:53:50","","","","","77","","Sustainable Cities and Society","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.scs.2021.103574","Factorization; Decision making; Deep neural networks; Network security; Network architecture; Metadata; Buildings; Disasters; Disaster prevention; Earthquakes; Automated evaluation; Deep neural network; Earthquake-induced building damage; Factorization machine; EARTHQUAKE RESILIENCE; EXPERT-SYSTEM; LOGIC","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z2PFPAUD","journalArticle","2021","Li, Shuangqi; Zhao, Pengfei","Big data driven vehicle battery management method: A novel cyber-physical system perspective","Journal of Energy Storage","","2352152X","10.1016/j.est.2020.102064","","The establishment of an accurate battery model is of great significance to improve the reliability of electric vehicles (EVs). However, the battery is a complex electrochemical system with hardly observable and simulatable internal chemical reactions, and it is challenging to estimate the state of battery accurately. This paper proposes a novel flexible and reliable battery management method based on the battery big data platform and Cyber-Physical System (CPS) technology. First of all, to integrate the battery big data resources in the cloud, a Cyber-physical battery management framework is defined and served as the basic data platform for battery modeling issues. And to improve the quality of the collected battery data in the database, this work reports the first attempt to develop an adaptive data cleaning method for the cloud battery management issue. Furthermore, a deep learning algorithm-based feature extraction model, as well as a feature-oriented battery modeling method, is developed to mitigate the under-fitting problem and improve the accuracy of the cloud-based battery model. The actual operation data of electric buses is used to validate the proposed methodologies. The maximum data restoring error can be limited within 1.3% in the experiments, which indicates that the proposed data cleaning method is able to improve the cloud battery data quality effectively. Meanwhile, the maximum SoC estimation error in the proposed feature-oriented battery modeling method is within 2.47%, which highlights the effectiveness of the proposed method.  2020 Elsevier Ltd","2021","2022-06-10 02:11:05","2022-07-31 14:44:04","","","","","33","","Journal of Energy Storage","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.est.2020.102064","Big data; Deep learning; Learning algorithms; Information management; Embedded systems; Battery management systems; Electric vehicles; Cyber Physical System; Secondary batteries; System-on-chip; Battery energy storage; Cyber-physical battery management system; MODEL; ALGORITHM; NEURAL-NETWORK; STATE; POWER; CHARGE ESTIMATION; DATA ANALYTICS; ELECTRIC VEHICLES; INTEGRATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"29M5YTLQ","journalArticle","2018","Kaiyi Zhao; Ruizhi Sun; Chao Deng; Li Li; Qiannan Wu; Sicong Li","Visual Analysis System for Market Sales Data of Agricultural Products","IFAC - Papers Online","","2405-8963","10.1016/j.ifacol.2018.08.107","","In order to realize the automation of large data analysis and mining, a series of advanced algorithms, such as data cleaning and clustering, are used to deeply excavate the market sales data of agricultural and sideline products and it provide the necessary data basis for the decision layer of the enterprise. We designed and developed a visual analysis system of market sales data orients to products and business circles in the article. First, we clean and filter the original market sales data, and then establish the model based on clustering analysis in machine learning. Finally, the automatic display of analysis result views are achieved through excellent visualization framework technology. The experimental results show that in the actual sales data onto agricultural products, the characteristics of the business circle that the system automatically aggregates are obvious, and the combined display mode of the main and auxiliary views can show the characteristics of the sales data of a commercial circle from the macro and micro perspectives, respectively. It not only utilizes the ability of computer automatic analysis, but also fully exploits people's cognitive ability of visual information and it helps people understand the information, knowledge and wisdom behind the big data of the market sales more intuitively and efficiently. Based on web visualization technology, a case of visual analysis of market sales data onto agricultural products and business circles is presented in this paper. And it has practical reference significance of other typical marketing analysis, especially for agricultural products market. [All rights reserved Elsevier].","2018","2022-06-10 02:11:06","2022-07-31 03:38:31","","741-6","","17","51","","IFAC - Papers Online","","IFAC, Pap. Online (Netherlands)","","","","","","","","","","","","","Place: Netherlands Publisher: Elsevier B.V.","","","http://dx.doi.org/10.1016/j.ifacol.2018.08.107","pattern clustering; data analysis; learning (artificial intelligence); data mining; Visualization; Big Data; data visualisation; Clustering; agricultural products; marketing data processing; sales management; Business circles; Interaction; Sales data sets","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BYV7U65R","journalArticle","2019","Shuo Bai; Mingchao Li; Rui Kong; Shuai Han; Heng Li; Liang Qin","Data mining approach to construction productivity prediction for cutter suction dredgers","Automation in Construction","","0926-5805","10.1016/j.autcon.2019.102833","","Cutter suction dredgers are important equipment in the dredging engineering. However, dredging construction productivity is affected by many factors such as soil, hydrology, meteorology and underwater sundries, making it difficult to obtain accurate prediction results. This paper presents a new integrated approach for using intelligent data mining algorithms to analyze dredger monitoring data and estimate the effective productivity. Through these combination algorithms, alongside Lasso and Maximal Information Coefficient (MIC), the key features affecting the productivity are filtered out from a 255-dimensional monitoring data set. The continuous mean data cleaning method is proposed according to the characteristics of the filtered data, followed by a clean-up of the feature data to increase smoothness. Four machine learning algorithms, Random Forest, K-Nearest, Naive Bayes and eXtreme Gradient Enhancement (XGBoost), are used to estimate and analyze the productivity of a cutter suction dredger and applied to actual engineering cases. The results show that the prediction accuracy of XGBoost exceeds 90%, which is better than other algorithms used. Finally, the model is compared with the predictive model trained by the characteristics that influence productivity derived from the traditional method. The results still show that the XGBoost model with features obtained from machine learning as input terms has a better prediction effect. [All rights reserved Elsevier].","2019-09","2022-06-10 02:11:06","2022-07-31 14:28:07","","208-20","","","105","","Automation in Construction","","Autom. Constr. (Netherlands)","","","","","","","","","","","","","Place: Netherlands Publisher: Elsevier B.V.","","","http://dx.doi.org/10.1016/j.autcon.2019.102833","Machine learning; data handling; data analysis; learning (artificial intelligence); data mining; excavators; mechanical engineering computing; Construction productivity; Cutter suction dredger; Monitoring data mining; OPTIMIZATION; EXPERT-SYSTEM; FEATURE-SELECTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EWUC46LI","journalArticle","2019","Zhu, Lin; Qiu, Dafeng; Ergu, Daji; Ying, Cai; Liu, Kuiyi","A study on predicting loan default based on the random forest algorithm","7th International Conference on Information Technology and Quantitative Management, ITQM 2019, November 3, 2019  -  November 6, 2019","","","10.1016/j.procs.2019.12.017","","Recently, with the advance of electronic commerce and big data technology, P2P online lending platforms have brought opportunities to businessmen, but at the same time, they are also faced with the risk of user loan default, which is related to the sustainable and healthy development of platforms. Therefore, based on the Random Forest algorithm, this paper builds a loan default prediction model in view of the real-world user loan data on Lending Club. The SMOTE method is adopted to cope with the problem of imbalance class in the dataset, and then a series of operations such as data cleaning and dimensionality reduction are carried out. The experimental results show that: Random Forest algorithm outperforms than logistic regression, decision tree and other machine learning algorithms in predicting default samples.  2020 The Authors. Published by Elsevier B.V.","2019","2022-06-10 02:11:06","2022-07-31 01:41:49","","503-513","","","162","","","","Procedia Computer Science","","","","","","","","","","","","","","","","http://dx.doi.org/10.1016/j.procs.2019.12.017","Decision trees; Forecasting; Finance; Predictive analytics; Logistic regression; Random forests; Dimensionality reduction; Random Forest; Random Forest, loan default, P2P lending; loan default; P2P lending; CREDIT RISK","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KJ8GF8KF","journalArticle","2021","Zhou, Yang; Gong, Xun; Yang, Peng","A directional margin paradigm for noise suppression in face recognition","Journal of Visual Communication and Image Representation","","10473203","10.1016/j.jvcir.2021.103182","","Convolutional neural networks (CNN) have achieved outstanding face recognition (FR) performance with increasing large-scale face datasets. With face dataset size grown, noisy data will inevitably increase, undoubtedly bringing difficulties to data cleaning. In this paper, the probability that the sample belongs to noise can be determined based on the cosine distance (cos) of normalized angle center and face feature vector in the margin-based loss functions. According to this finding, we propose a two-step learning method integrated into the loss function. The new proposed directional margin loss function combines the noise probability with the label as the supervision information. Experiments show that our method can tolerate noisy data and get high FR accuracy when the training datasets mix with more than 30% noise. Our approach can also achieve a great result of 79.33% in MegaFace challenge one using a noisy training dataset.  2021 Elsevier Inc.","2021","2022-06-10 02:11:08","2022-07-30 22:23:44","","","","","78","","Journal of Visual Communication and Image Representation","","","","","","","","","","","","","","","Publisher: Academic Press Inc.","","","http://dx.doi.org/10.1016/j.jvcir.2021.103182","Learning systems; Large dataset; Convolutional neural networks; Face recognition; Noisy labels, Face recognition, Two-step learning, Margin paradigm, Loss function; Loss function; Margin paradigm; Noisy labels; Two-step learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FKYBELM8","journalArticle","2020","Qi, Zhixin; Wang, Hongzhi; He, Tao; Li, Jianzhong; Gao, Hong","FRIEND: Feature selection on inconsistent data","Neurocomputing","","09252312","10.1016/j.neucom.2020.01.094","","With the explosive growth of information, inconsistent data are increasingly common. However, traditional feature selection methods are lack of efficiency due to inconsistent data repairing beforehand. Therefore, it is necessary to take inconsistencies into consideration during feature selection to not only reduce time costs but also guarantee accuracy of machine learning models. To achieve this goal, we present FRIEND, a feature selection approach on inconsistent data. Since features in consistency rules have higher correlation with each other, we aim to select a specific amount of features from these. We prove that the specific feature selection problem is NP-hard and develop an approximation algorithm for this problem. Extensive experimental results demonstrate the efficiency and effectiveness of our proposed approach.  2020","2020","2022-06-10 02:11:09","2022-07-31 13:40:16","","52-64","","","391","","Neurocomputing","","","","","","","","","","","","","","","Publisher: Elsevier B.V.","","","http://dx.doi.org/10.1016/j.neucom.2020.01.094","Feature extraction; Efficiency; Approximation algorithms; Data quality; Feature selection; Mutual information; Approximation; Inconsistent data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FLJC82DU","journalArticle","2019","Li, Shuangqi; Li, Jianwei; He, Hongwen; Wang, Hanxiao","Lithium-ion battery modeling based on Big Data","2018 Renewable Energy Integration with Mini/Microgrid, REM 2018, September 28, 2018  -  September 30, 2018","","","10.1016/j.egypro.2018.12.046","","Battery is the bottleneck technology of electric vehicles. The complex chemical reactions inside the battery are difficult to monitor directly. The establishment of a precise mathematical model for the battery is of great significance in ensuring the secure and stable operation of the battery management system. First of all, a data cleaning method based on machine learning is put forward, which is applicable to the characteristics of big data from batteries in electric vehicles. Secondly, this paper establishes a lithium-ion battery model based on deep learning algorithm and the error of model based on different algorithms is compared. The data of electric buses are used for validating the effectiveness of the model. The result shows that the data cleaning method achieves good results, in the case of the terminal voltage missing, the mean absolute percentage error of filling is within 4%, and the battery modeling method in this paper is able to simulate the battery characteristics accurately, and the mean absolute percentage error of the terminal voltage estimation is within 2.5%.  2019 The Authors. Published by Elsevier Ltd.","2019","2022-06-10 02:11:10","2022-07-31 05:37:10","","168-173","","","159","","","","Energy Procedia","","","","","","","","","","","","","","","","http://dx.doi.org/10.1016/j.egypro.2018.12.046","Big data; Deep learning; Learning algorithms; Learning systems; Errors; learning (artificial intelligence); battery management systems; secondary cells; Battery management systems; Lithium-ion batteries; Automotive batteries; Electric vehicles; Ions; Models; battery management; bigdata; deeplearning; electric vehicle; lithium-ion power battery; modeling; electric vehicles; battery charge measurement; NETWORK; DESIGN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ARSQHT6T","journalArticle","2020","Razavi-Far, R.; Boyuan Cheng; Saif, M.; Ahmadi, M.","Similarity-learning information-fusion schemes for missing data imputation","Knowledge-Based Systems","","0950-7051","10.1016/j.knosys.2019.06.013","","Missing data imputation is a very important data cleaning task for machine learning and data mining with incomplete data. This paper proposes two novel methods for missing data imputation, named kEMI and kEMI+, that are based on the k-Nearest Neighbours algorithm for pre-imputation and the Expectation-Maximization algorithm for posterior-imputation. The former is a local search mechanism that aims to automatically find the best value for k and the latter makes use of the best k nearest neighbours to estimate missing scores by learning global similarities. kEMI+ makes use of a novel information fusion mechanism. It fuses top estimations through the Dempster-Shafer fusion module to obtain the final estimation. They handle both numerical and categorical features. The performance of the proposed imputation techniques are evaluated by applying them on twenty one publicly available datasets with different missingness and ratios, and, then, compared with other state-of-the-art missing data imputation techniques in terms of standard evaluation measures such as the normalized root mean square difference and the absolute error. The attained results indicate the effectiveness of the proposed novel missing data imputation techniques. [All rights reserved Elsevier].","2020-01","2022-06-10 02:11:10","2022-07-31 04:19:52","","236-48","","","187","","Knowledge-Based Systems","","Knowl.-Based Syst. (Netherlands)","","","","","","","","","","","","","Place: Netherlands Publisher: Elsevier B.V.","","","http://dx.doi.org/10.1016/j.knosys.2019.06.013","data handling; pattern clustering; data analysis; learning (artificial intelligence); Data mining; Nearest neighbor search; data mining; mean square error methods; nearest neighbour methods; sensor fusion; Bayes methods; inference mechanisms; Information fusion; expectation-maximisation algorithm; uncertainty handling; Dempster–Shafer theory; Expectation–Maximization; Imputation; Missing data; Similarity learning; PREDICTION; CLASSIFICATION; FRAMEWORK; Dempster-Shafer theory; DEMPSTER-SHAFER THEORY; Expectation-Maximization; FAULTS; INCOMPLETE DATA; VALUES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KITHHYFH","journalArticle","2022","Xu, Yue; Jia, Li; Yang, Wei","Correlation based neuro-fuzzy Wiener type wind power forecasting model by using special separate signals","Energy Conversion and Management","","01968904","10.1016/j.enconman.2021.115173","","The wind power system is characterized by complex structures, numerous effect elements, and complicated physical relationships, which bring great difficulties to establish the wind power forecasting model and result in the unsatisfactory prediction accuracy of wind power. In this paper, a correlation based neuro-fuzzy Wiener type wind power forecasting model is proposed by using special separate signals to decouple dynamic linear and static nonlinear characteristics of wind power systems for high-accuracy wind power forecasting. This method introduces an autoregressive exogenous model and fuzzy neural network to explore the underlying distribution characteristics of wind power systems by correlation analysis of the linear and nonlinear information contained in time-series data of the wind power system. In addition, in order to eliminate outliers in the original data set, an abnormal data cleaning approach combining quartile and two-stage clustering algorithm is employed to reduce the computation time and improve the model accuracy. Moreover, the convergence of the Wiener model is proved by the Lyapunov function. Simulation results verify the high accuracy and generalization ability of the proposed model both in the gale and breeze seasons.  2021 Elsevier Ltd","2022","2022-06-10 02:11:10","2022-07-31 14:34:11","","","","","253","","Energy Conversion and Management","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.enconman.2021.115173","Fuzzy inference; Fuzzy neural networks; Wind power; Clustering algorithms; Time series analysis; Correlation methods; Lyapunov functions; Separation; Abnormal data cleaning; Correlation analysis method; Special separate signals; Wiener model; Wind power forecasting; PREDICTION; IDENTIFICATION; ALGORITHM; CURVE; ENERGY-STORAGE; STRATEGY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6X64PRAI","journalArticle","2020","Igarashi, Shohei; Sasaki, Yoshihiro; Mikami, Tatsuya; Sakuraba, Hirotake; Fukuda, Shinsaku","Anatomical classification of upper gastrointestinal organs under various image capture conditions using AlexNet","Computers in Biology and Medicine","","00104825","10.1016/j.compbiomed.2020.103950","","Background: Machine learning has led to several endoscopic studies about the automated localization of digestive lesions and prediction of cancer invasion depth. Training and validation dataset collection are required for a disease in each digestive organ under a similar image capture condition; this is the first step in system development. This data cleansing task in data collection causes a great burden among experienced endoscopists. Thus, this study classified upper gastrointestinal (GI) organ images obtained via routine esophagogastroduodenoscopy (EGD) into precise anatomical categories using AlexNet. Method: In total, 85,246 raw upper GI endoscopic images from 441 patients with gastric cancer were collected retrospectively. The images were manually classified into 14 categories: 0) white-light (WL) stomach with indigo carmine (IC); 1) WL esophagus with iodine; 2) narrow-band (NB) esophagus; 3) NB stomach with IC; 4) NB stomach; 5) WL duodenum; 6) WL esophagus; 7) WL stomach; 8) NB oralpharynxlarynx; 9) WL oralpharynxlarynx; 10) WL scaling paper; 11) specimens; 12) WL muscle fibers during endoscopic submucosal dissection (ESD); and 13) others. AlexNet is a deep learning framework and was trained using 49,174 datasets and validated using 36,072 independent datasets. Results: The accuracy rates of the training and validation dataset were 0.993 and 0.965, respectively. Conclusions: A simple anatomical organ classifier using AlexNet was developed and found to be effective in data cleansing task for collection of EGD images. Moreover, it could be useful to both expert and non-expert endoscopists as well as engineers in retrospectively assessing upper GI images.  2020 Elsevier Ltd","2020","2022-06-10 02:11:10","2022-07-31 02:31:22","","","","","124","","Computers in Biology and Medicine","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.compbiomed.2020.103950","Deep learning; Artificial intelligence; Diseases; Integrated circuits; Image classification; Digestive system; Endoscopy; Convolutional neural network (CNN); Anatomical classification; Upper gastrointestinal tract; CAPSULE ENDOSCOPY; GASTRIC-CANCER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CF22C3TD","journalArticle","2022","Alimohammadi, Hamzeh; Nancy Chen, Shengnan","Performance evaluation of outlier detection techniques in production timeseries: A systematic review and meta-analysis","Expert Systems with Applications","","09574174","10.1016/j.eswa.2021.116371","","Time-series data have been extensively collected and analyzed in many disciplines, such as stock market, medical diagnosis, meteorology, and oil and gas industry. Numerous data in these disciplines are sequence of observations measured as functions of time, which can be further used for different applications via analytical or data analytics techniques (e.g., to forecast future price, climate change, etc.). However, presence of outliers can cause significant uncertainties to interpretation results; hence, it is essential to remove the outliers accurately and efficiently before conducting any further analysis. A total of 17 techniques that belong to statistical, regression-based, and machine learning (ML) based categories for outlier detection in timeseries are applied to the oil and gas production data analysis. 15 of these methods are utilized for production data analysis for the first time. Two state-of-the-art and high-performance techniques are then selected for data cleaning which require minimum control and time complexity. Moreover, performances of these techniques are evaluated based on several metrics including the accuracy, precision, recall, F1 score, and Cohen's Kappa to rank the techniques. Results show that eight unsupervised algorithms outperform the rest of the methods based on the synthetic case study with known outliers. For example, accuracies of the eight shortlisted methods are in the range of 0.830.99 with a precision between 0.83 and 0.98, compared to 0.650.82 and 0.070.77 for the others. In addition, ML-based techniques perform better than statistical techniques. Our experimental results on real field data further indicate that the k-nearest neighbor (KNN) and Fulford-Blasingame methods are superior to other outlier detection frameworks for outlier detection in production data, followed by four others including density-based spatial clustering of applications with noise (DBSCAN), and angle-based outlier detection (ABOD). Even though the techniques are examined with oil and gas production data, but the same data cleaning workflow can be used to detect timeseries outliers in other disciplines.  2021","2022","2022-06-10 02:11:14","2022-07-31 04:53:30","","","","","191","","Expert Systems with Applications","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.eswa.2021.116371","Data handling; Diagnosis; Data Analytics; Statistics; Nearest neighbor search; Uncertainty analysis; Gas industry; Climate change; Outlier detection; Performance evaluation; Binary classification; Decline curve analysis; Production data analysis; ANOMALY DETECTION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D8KRCWF7","journalArticle","2021","Föll, Simon; Maritsch, Martin; Spinola, Federica; Mishra, Varun; Barata, Filipe; Kowatsch, Tobias; Fleisch, Elgar; Wortmann, Felix","FLIRT: A feature generation toolkit for wearable data","Comput. Methods Prog. Biomed.","","","","https://doi.org/10.1016/j.cmpb.2021.106461","","2021","2022-06-10 02:43:19","2022-07-31 13:41:49","","11","","C","212","","","","","","","","","","","","","","","","","ISBN: 0169-2607 Publisher: Elsevier North-Holland, Inc. Type: 10.1016/j.cmpb.2021.106461","","","http://dx.doi.org/10.1016/j.cmpb.2021.106461","Data handling; Machine learning; Feature extraction; Wearable sensors; Feature engineering; Wearable sensors, Signal filtering, Artifact detection, Feature engineering, Machine learning, Physiological signal processing; Artifact detection; Physiological signal processing; Signal filtering; Information filtering; Physiology; SYSTEM; TIME; HEART-RATE-VARIABILITY; HUMAN ACTIVITY RECOGNITION; POWER SPECTRAL DENSITY; STRESS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WHG269A5","journalArticle","2019","Ahmad, Nor Bahiah; Alias, Umi Farhana; Mohamad, Nadirah; Yusof, Norazah","Principal Component Analysis and Self-Organizing Map Clustering for Student Browsing Behaviour Analysis","Procedia Comput. Sci.","","","","https://doi.org/10.1016/j.procs.2019.12.137","","2019","2022-06-10 02:43:19","2022-07-31 05:13:34","","550–559","","C","163","","","","","","","","","","","","","","","","","ISBN: 1877-0509 Publisher: Elsevier Science Publishers B. V. Type: 10.1016/j.procs.2019.12.137","","","","Clustering; Principal Component Analysis (PCA); Student behaviour, Log file, Clustering, Self-Organizing Map (SOM), Principal Component Analysis (PCA); Log file; Self-Organizing Map (SOM); Student behaviour","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2AK6ID4J","journalArticle","2021","Egwim, Christian Nnaemeka; Alaka, Hafiz; Toriola-Coker, Luqman Olalekan; Balogun, Habeeb; Sunmola, Funlade","Applied artificial intelligence for predicting construction projects delay","Machine Learning with Applications","","2666-8270","10.1016/j.mlwa.2021.100166","https://www.sciencedirect.com/science/article/pii/S2666827021000839","This study presents evidence of a developed ensemble of ensembles predictive model for delay prediction – a global phenomenon that has continued to strangle the construction sector despite considerable mitigation efforts. At first, a review of the existing body of knowledge on influencing factors of construction project delay was used to survey experts to approach its quantitative data collection. Secondly, data cleaning, feature selection, and engineering, hyperparameter optimization, and algorithm evaluation were carried out using the quantitative data to train ensemble machine learning algorithms (EMLA) – bagging, boosting, and naïve bayes, which in turn was used to develop hyperparameter optimized predictive models: Decision Tree, Random Forest, Bagging, Extremely Randomized Trees, Adaptive Boosting (CART), Gradient Boosting Machine, Extreme Gradient Boosting, Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes. Finally, a multilayer high performant ensemble of ensembles (stacking) predictive model was developed to maximize the overall performance of the EMLA combined. Results from the evaluation metrics: accuracy score, confusion matrix, precision, recall, f1 score, and Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) indeed proved that ensemble algorithms are capable of improving the predictive force relative to the use of a single algorithm in predicting construction projects delay.","2021-12-15","2022-06-10 03:07:28","2022-07-31 03:27:40","","100166","","","6","","Machine Learning with Applications","","","","","","","","","","","","","","","","","","","Machine learning; Artificial intelligence; Predictive analytics; Ensemble learning; Ensemble of ensembles; Project delay","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3QDJ9TWM","journalArticle","2016","Xie, Jingrui; Hong, Tao","GEFCom2014 probabilistic electric load forecasting: An integrated solution with forecast combination and residual simulation","International Journal of Forecasting","","0169-2070","10.1016/j.ijforecast.2015.11.005","https://www.sciencedirect.com/science/article/pii/S0169207015001405","We present an integrated solution for probabilistic load forecasting. The proposed solution was the basis for Jingrui Xie’s submission to the probabilistic load forecasting track of the Global Energy Forecasting Competition 2014 (GEFCom2014), and consists of three components: pre-processing, forecasting, and post-processing. The pre-processing component includes data cleansing and temperature station selection. The forecasting component involves the development of point forecasting models, forecast combination, and temperature scenario based probabilistic forecasting. The post-processing component embodies residual simulation for probabilistic forecasting. In addition, we also discuss several other variations that were implemented during the competition.","2016-07-01","2022-06-10 03:07:29","2022-07-31 13:38:54","","1012-1016","","3","32","","International Journal of Forecasting","","","","","","","","","","","","","","","","","","","Neural networks; Regression analysis; Load forecasting; Forecast combination; Probabilistic forecasting; Residual simulation; Time series modeling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DUTIXUNR","journalArticle","2020","Ahmed, R.; Sreeram, V.; Mishra, Y.; Arif, M.D.","A review and evaluation of the state-of-the-art in PV solar power forecasting: Techniques and optimization","Renewable and Sustainable Energy Reviews","","1364-0321","10.1016/j.rser.2020.109792","https://www.sciencedirect.com/science/article/pii/S1364032120300885","Integration of photovoltaics into power grids is difficult as solar energy is highly dependent on climate and geography; often fluctuating erratically. This causes penetrations and voltage surges, system instability, inefficient utilities planning and financial loss. Forecast models can help; however, time stamp, forecast horizon, input correlation analysis, data pre and post-processing, weather classification, network optimization, uncertainty quantification and performance evaluations need consideration. Thus, contemporary forecasting techniques are reviewed and evaluated. Input correlational analyses reveal that solar irradiance is most correlated with Photovoltaic output, and so, weather classification and cloud motion study are crucial. Moreover, the best data cleansing processes: normalization and wavelet transforms, and augmentation using generative adversarial network are recommended for network training and forecasting. Furthermore, optimization of inputs and network parameters, using genetic algorithm and particle swarm optimization, is emphasized. Next, established performance evaluation metrics MAE, RMSE and MAPE are discussed, with suggestions for including economic utility metrics. Subsequently, modelling approaches are critiqued, objectively compared and categorized into physical, statistical, artificial intelligence, ensemble and hybrid approaches. It is determined that ensembles of artificial neural networks are best for forecasting short term photovoltaic power forecast and online sequential extreme learning machine superb for adaptive networks; while Bootstrap technique optimum for estimating uncertainty. Additionally, convolutional neural network is found to excel in eliciting a model's deep underlying non-linear input-output relationships. The conclusions drawn impart fresh insights in photovoltaic power forecast initiatives, especially in the use of hybrid artificial neural networks and evolutionary algorithms.","2020-05-01","2022-06-10 03:07:29","2022-07-31 01:32:25","","109792","","","124","","Renewable and Sustainable Energy Reviews","","","","","","","","","","","","","","","","","","http://dx.doi.org/10.1016/j.rser.2020.109792","Long short-term memory; Electric power transmission networks; Learning systems; Forecasting; Genetic algorithms; Deep neural networks; Convolutional neural networks; Convolution; Uncertainty analysis; Optimization; Photovoltaic cells; Wavelet transforms; Particle swarm optimization (PSO); Solar power generation; Solar energy; Long short term memory; Deep convolutional neural network; Forecast accuracy; Forecasting technique; Solar power; Wavelet transform; Statistical methods; Losses; System stability; ARTIFICIAL NEURAL-NETWORK; BOLTZMANN MACHINES; CLOUD DETECTION; EXTREME LEARNING-MACHINE; HYBRID APPROACH; LONG-TERM; OUTPUT POWER; PROCESSING STRATEGY; TIME-SERIES; WIND-SPEED","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HTPDI5R7","journalArticle","2018","Deng, Huan; Wang, Jing; Liu, Xingyu; Liu, Bangtao; Lei, Jianbo","Evaluating the outcomes of medical informatics development as a discipline in China: A publication perspective","Computer Methods and Programs in Biomedicine","","0169-2607","10.1016/j.cmpb.2018.07.001","https://www.sciencedirect.com/science/article/pii/S016926071830573X","Background As the world's second largest economy, China makes unique contributions to the world in many fields, including sociology, the economy, technology and defense. Medical informatics (MI) is an important cross-disciplinary field that, along with its applications, has received massive funding from the Chinese government. However, the question of how to evaluate China's input and output in MI remains important and complex issue of great significance for China and the rest of the world. Objective This paper analyzed, for the first time, the quality and quantity of research by Chinese academics in MI based on their articles published in international specialty journals in recent years and examined MI research hotspots in China. Our purpose is to summarize the experiences and lessons learned by China and the rest of the world as they develop MI. Method We targeted 18 MI journals listed in the JCR 2016 report and searched for papers published by Chinese academics in these 18 journals in the WOS and PUBMED databases and on journal sites. We also performed data cleansing and categorized the obtained information. We used Excel, SPSS, Ucinet and NetDraw to conduct quantitative analyses on the research papers. Results A total of 1340 articles satisfied the inclusion criteria of this study. We observed a significant upward trend in the number of articles published over time, particularly after 2011. Lei Jianbo, Huang Zhengxing and Li Jin-song are active Chinese authors in the MI discipline who have written many high-quality publications. Meanwhile, universities remain the primary breeding grounds for scientific research: 93.36% of the articles came from universities. Zhejiang University published the most first-author articles, whereas Zhejiang University, Shanghai Jiao Tong University and Tsinghua University produced 17.76% of the total articles. According to the lists of authors, 24% of the papers were co-authored with foreign researchers. This rate of cooperation is increasing each year, from 5.88% to the current rate of 39.04%. An analysis of keywords showed that “EMR”, “SVM”, “Authentication”, “Telecare medical information system”, “EEG”, “ECG” and “RFID” were the most frequently searched terms in popular technological fields, including artificial intelligence and image processing. In recent years, there has been a significant increase in the number of high-frequency keywords and a broadening range of research fields, which has led to the emergence of several research hotspots, including MI systems, mobile health care, telecare, data mining and machine learning. Conclusions Through the quantitative analysis of publications, we discovered the emergence of three stages – infancy, slow growth and rapid growth – in China's MI research in recent years as academics make achievements in their research works. The global influence of Chinese academics is growing, and they are making increasingly conscious efforts to enter into research collaborations with foreign researchers. The findings of Chinese academics’ publications are gaining international recognition.","2018-10-01","2022-06-10 03:07:29","2022-07-31 13:54:25","","75-85","","","164","","Computer Methods and Programs in Biomedicine","","","","","","","","","","","","","","","","","","","Medical informatics; Article; China; Discipline development; Output; Research paper quantitative analysis; BIOMEDICAL INFORMATICS; EDUCATION; TRENDS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U4MMDELY","journalArticle","2019","Zhang, Shi-hong; Xiao, Ke-yan; Chen, Jian-ping; Xiang, Jie; Cui, Ning; Wang, Xiao-nan","Development and future prospects of quantitative mineral assessment in China","China Geology","","2096-5192","10.31035/cg2018097","https://www.sciencedirect.com/science/article/pii/S2096519219301302","ABSTRACT Mineral potential assessment at the Earth’s surface has been an important research for geoscientists around the world in the past five decades. The fundamental aspects of mineral assessment at different scales can be associated with the following tasks, e.g., mineral potential mapping and estimation of mineral resources. This paper summarized the history and development in terms of theories, methods technologies and software platforms for quantitative assessment of mineral resources in China, e.g. comprehensive information methodology, geological anomaly, three-component quantitative prediction method, 5P ore-finding area, integrated information assessment method, nonlinear process modeling and fractals, three dimensional mineral potential mapping, etc. At last, to discuss the future of quantitative mineral assessment in an era of big data including platform for 3D visualization, analysis and sharing, new methods and protocols for data cleaning, information enhancement, information integration, and uncertainties and multiple explanations of multi-information. © 2019 China Geology Editorial Office.","2019-06-01","2022-06-10 03:07:29","2022-07-31 14:10:47","","198-210","","2","2","","China Geology","","","","","","","","","","","","","","","","","","","Big data; Machine learning; 3D Geological modeling; Fractals; Quantitative mineral assessment; Synthesis information","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RX546X7F","journalArticle","2016","Djouvas, Costantinos; Mendez, Fernando; Tsapatsoulis, Nicolas","Mining online political opinion surveys for suspect entries: An interdisciplinary comparison","Journal of Innovation in Digital Ecosystems","","2352-6645","10.1016/j.jides.2016.11.003","https://www.sciencedirect.com/science/article/pii/S2352664516300256","Filtering data generated by so-called Voting Advice Applications (VAAs) in order to remove entries that exhibit unrealistic behavior (i.e., cannot correspond to a real political view) is of primary importance. If such entries are significantly present in VAA generated datasets, they can render conclusions drawn from VAA data analysis invalid. In this work we investigate approaches that can be used for automating the process of identifying entries that appear to be suspicious in terms of a users’ answer patterns. We utilize two unsupervised data mining techniques and compare their performance against a well established psychometric approach. Our results suggest that the performance of data mining approaches is comparable to those drawing on psychometric theory with a fraction of the complexity. More specifically, our simulations show that data mining techniques as well as psychometric approaches can be used to identify truly ‘rogue’ data (i.e., completely random data injected into the dataset under investigation). However, when analysing real datasets the performance of all approaches dropped considerably. This suggests that ‘suspect’ entries are neither random nor clustered. This finding poses some limitations on the use of unsupervised techniques, suggesting that the latter can only complement rather than substitute existing methods to identifying suspicious entries.","2016-12-01","2022-06-10 03:07:29","2022-07-31 05:21:35","","172-182","","2","3","","Journal of Innovation in Digital Ecosystems","","","","","","","","","","","","","","","","","","","Anomaly detection; Machine learning; Data mining; Data cleaning; Psychometric Likert scale; Voting advice applications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VRBLPAG3","journalArticle","2019","Martinez-Luengo, Maria; Shafiee, Mahmood; Kolios, Athanasios","Data management for structural integrity assessment of offshore wind turbine support structures: data cleansing and missing data imputation","Ocean Engineering","","0029-8018","10.1016/j.oceaneng.2019.01.003","https://www.sciencedirect.com/science/article/pii/S0029801818308576","Structural Health Monitoring (SHM) and Condition Monitoring (CM) Systems are currently utilised to collect data from offshore wind turbines (OWTs), to enhance the accurate estimation of their operational performance. However, industry accepted practices for effectively managing the information that these systems provide have not been widely established yet. This paper presents a four-step methodological framework for the effective data management of SHM systems of OWTs and illustrates its applicability in real-time continuous data collected from three operational units, with the aim of utilising more complete and accurate datasets for fatigue life assessment of support structures. Firstly, a time-efficient synchronisation method that enables the continuous monitoring of these systems is presented, followed by a novel approach to noise cleansing and the posterior missing data imputation (MDI). By the implementation of these techniques those data-points containing excessive noise are removed from the dataset (Step 2), advanced numerical tools are employed to regenerate missing data (Step 3) and fatigue is estimated for the results of these two methodologies (Step 4). Results show that after cleansing, missing data can be imputed with an average absolute error of 2.1%, while this error is kept within the [+ 15.2%−11.0%] range in 95% of cases. Furthermore, only 0.15% of the imputed data fell outside the noise thresholds. Fatigue is found to be underestimated both, when data cleansing does not take place and when it takes place but MDI does not. This makes this novel methodology an enhancement to conventional structural integrity assessment techniques that do not employ continuous datasets in their analyses.","2019-02-01","2022-06-10 03:07:29","2022-07-31 03:12:02","","867-883","","","173","","Ocean Engineering","","","","","","","","","","","","","","","","","","http://dx.doi.org/10.1016/j.oceaneng.2019.01.003","Neural networks; Information management; Condition monitoring; Structural health monitoring; Real time systems; Offshore oil well production; Artificial neural network (ANN); Data synchronisation; Missing data imputation; Noise cleansing; Offshore wind; Structural health monitoring (SHM); Continuous time systems; Fatigue of materials; Ground supports; Offshore wind turbines; Structural integrity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IHKUQBQ2","journalArticle","2019","Cheng, Xu; Li, Guoyuan; Skulstad, Robert; Major, Pierre; Chen, Shengyong; Hildre, Hans Petter; Zhang, Houxiang","Data-driven uncertainty and sensitivity analysis for ship motion modeling in offshore operations","Ocean Engineering","","0029-8018","10.1016/j.oceaneng.2019.03.014","https://www.sciencedirect.com/science/article/pii/S0029801819301106","To build a compact data-driven ship motion model for offshore operations that require high control safety, it is necessary to select the most influential parameters and to analyze the uncertainty of the input parameters. This paper proposes a framework of uncertainty and sensitivity analysis for ship motion data. The framework consists of four components: data cleaning, surrogate model, sensitivity and uncertainty analysis, and results visualization. Data cleaning focuses on the removal of noise, and necessary transformation for the easy analysis. An artificial neural network (ANN) based surrogate model is constructed on the basis of cleaned ship motion data. The sensitivity and uncertainty analysis would be performed on the sample or weights which the ANN based surrogate model generated. The result of the sensitivity and uncertainty analysis can be beneficial to the optimization of data-driven ship motion models. Three distinctive sensitivity analysis (SA) methods (Garson/Morris/Sobol), and PDF-based and CDF-based uncertainty methods are investigated in two types of ship motion datasets with and without environmental factors. The experimental results also demonstrate the proposed framework can be applied to estimate the sensitivity and uncertainty in different datasets.","2019-05-01","2022-06-10 03:07:29","2022-07-31 14:25:11","","261-272","","","179","","Ocean Engineering","","","","","","","","","","","","","","","","","","","Sensitivity analysis; Uncertainty analysis; Data-driven; Offshore operations; Ship motion; FRAMEWORK; IDENTIFICATION; RS-HDMR","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J4Y2SFIG","journalArticle","2020","Castejón-Limas, Manuel; Alaiz-Moreton, Hector; Fernández-Robles, Laura; Alfonso-Cendón, Javier; Fernández-Llamas, Camino; Sánchez-González, Lidia; Pérez, Hilde","Robust weighted regression via PAELLA sample weights","Neurocomputing","","0925-2312","10.1016/j.neucom.2019.03.108","https://www.sciencedirect.com/science/article/pii/S0925231219316066","This paper reports the usage of the occurrence vector provided by the PAELLA algorithm in the context of robust regression. PAELLA was originally conceived as an outlier detection and data cleaning technique. A novel approach is to use this algorithm not for discarding outliers but to generate information related to the reliability of the observations recorded in the dataset. This approach proves to provide successful results when compared to traditional common practice such as outlier removal. A set of experiments using a contrived difficult artificial dataset are described using both neural networks and classical polynomial fitting. Finally, a successful comparison of our approach to two state-of-the-art algorithms proves the benefits of using the PAELLA algorithm in the context of robust regression.","2020-05-28","2022-06-10 03:07:29","2022-07-31 03:05:09","","325-333","","","391","","Neurocomputing","","","","","","","","","","","","","","","","","","http://dx.doi.org/10.1016/j.neucom.2019.03.108","Neural networks; Statistics; Outlier detection; Multilayer perceptron; PAELLA; Robust regression; Weighted regression; Computer applications","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I2FRQ5DH","journalArticle","2020","Li, Pei; Abdel-Aty, Mohamed; Cai, Qing; Yuan, Cheng","⋆This paper has been handled by associate editor Tony Sze.The application of novel connected vehicles emulated data on real-time crash potential prediction for arterials","Accident Analysis & Prevention","","0001-4575","10.1016/j.aap.2020.105658","https://www.sciencedirect.com/science/article/pii/S0001457520305339","Real-time crash potential prediction could provide valuable information for Active Traffic Management Systems. Fixed infrastructure-based vehicle detection devices were widely used in the previous studies to obtain different types of data for crash potential prediction. However, it was difficult to obtain data in large range through these devices due to the costs of installation and maintenance. This paper introduced a novel connected vehicle (CV) emulated data for real-time crash potential prediction. Different from the fixed devices’ data, CV emulated data have high flexibility and can be obtained continuously with relatively low cost. Crash and CV emulated data were collected from two urban arterials in Orlando, USA. Crash data were archived by the Signal for Analytics system (S4A), while the CV emulated data were obtained through the data collection API with a high frequency. Different data cleaning and preparation techniques were implemented, while various speed-related variables were generated from the CV emulated data. A Long Short-term Memory (LSTM) neural network was trained to predict the crash potential in the next 5−10 min. The results from the model illustrated the feasibility of using a novel CV emulated data to predict real-time crash potential. The average and 50th percentile speed were the two most important variables for the crash potential prediction. In addition, the proposed LSTM outperformed Bayesian logistics regression and XGBoost in terms of sensitivity, Area under Curve (AUC), and false alarm rate. With the rapid development of the connected vehicle systems, the results from this paper can be extended to other types of vehicles and data, which can significantly enhance traffic safety.","2020-09-01","2022-06-10 03:07:29","2022-07-30 20:20:17","","105658","","","144","","Accident Analysis & Prevention","","","","","","","","","","","","","","","","","","http://dx.doi.org/10.1016/j.aap.2020.105658","Long short-term memory; Deep learning; Forecasting; Information management; Advanced traffic management systems; Costs; Logistic regression; Vehicles; Real time systems; Accidents; Traffic control; Connected vehicle emulated data; Real-time crash potential prediction; Urban arterials; Speed control; MACHINE; FREEWAYS; INJURY SEVERITY; RISK PREDICTION; SHANGHAI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SMZP7WMT","journalArticle","2021","Marriott Haresign, I.; Phillips, E.; Whitehorn, M.; Noreika, V.; Jones, E.J.H.; Leong, V.; Wass, S.V.","Automatic classification of ICA components from infant EEG using MARA","Developmental Cognitive Neuroscience","","1878-9293","10.1016/j.dcn.2021.101024","https://www.sciencedirect.com/science/article/pii/S1878929321001146","Automated systems for identifying and removing non-neural ICA components are growing in popularity among EEG researchers of adult populations. Infant EEG data differs in many ways from adult EEG data, but there exists almost no specific system for automated classification of source components from paediatric populations. Here, we adapt one of the most popular systems for adult ICA component classification for use with infant EEG data. Our adapted classifier significantly outperformed the original adult classifier on samples of naturalistic free play EEG data recorded from 10 to 12-month-old infants, achieving agreement rates with the manual classification of over 75% across two validation studies (n = 44, n = 25). Additionally, we examined both classifiers’ ability to remove stereotyped ocular artifact from a basic visual processing ERP dataset compared to manual ICA data cleaning. Here, the new classifier performed on level with expert manual cleaning and was again significantly better than the adult classifier at removing artifact whilst retaining a greater amount of genuine neural signal operationalised through comparing ERP activations in time and space. Our new system (iMARA) offers developmental EEG researchers a flexible tool for automatic identification and removal of artifactual ICA components.","2021-12-01","2022-06-10 03:07:30","2022-07-31 14:51:14","","101024","","","52","","Developmental Cognitive Neuroscience","","","","","","","","","","","","","","","","","","","Deep learning; EEG; Artifact correction; Event-related potentials (ERP); Independent component analysis (ICA)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FAPMQNTL","journalArticle","2022","Guo, Xiaohui; Wang, Yuanfeng; Mei, Shengqi; Shi, Chengcheng; Liu, Yinshan; Pan, Lei; Li, Kai; Zhang, Boqun; Wang, Junshan; Zhong, Zhiwu; Dong, Minzhong","Monitoring and modelling of PM2.5 concentration at subway station construction based on IoT and LSTM algorithm optimization","Journal of Cleaner Production","","0959-6526","10.1016/j.jclepro.2022.132179","https://www.sciencedirect.com/science/article/pii/S0959652622017851","Fine particulate matter (PM2.5) generated during construction not only has great influences on the health of the workers, but also has a negative impact on the health of the surrounding public. In-depth study of PM2.5 during construction is of great significance to the environment and human health. Traditional prediction methods have limited consideration of influencing factors and low prediction accuracy. Therefore, this study proposed a Bayesian optimization-based Long Short-Time Method (LSTM) algorithm which can achieve effective PM2.5 prediction at construction sites. In this study, The Internet of Things (IoT) technology was used to conduct real-time monitoring of a subway station construction site in China for 6 months. The PM2.5 concentrations generated by different construction processes were obtained through data cleaning and analysis. The average PM2.5 increments for the excavation and support works, reinforcement works and concrete works were 17 μg/m3, 20 μg/m3, and 21 μg/m3, respectively. After that, feature extraction was performed by the gray correlation algorithm to eliminate redundant information. Then, a Bayesian optimization algorithm was introduced to tune the hyperparameters to optimize the LSTM model performance. Finally, the validity of the proposed model was verified using multiple base models. The results showed that the accuracy of the LSTM model was improved by 6% (R2 from 0.88 to 0.94), after the Bayesian optimization. And the optimized model also has better evaluation indicators, with RMSE = 13.06μg/m3, MAE = 8.61μg/m3. It was proved that the method can effectively predict air pollution.","2022-08-01","2022-06-10 03:07:30","2022-07-31 05:19:32","","132179","","","360","","Journal of Cleaner Production","","","","","","","","","","","","","","","","","","","Internet of Things (IoT); PM2.5; Bayesian optimization; Long short-Time method (LSTM); Subway station","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K5LPDUR6","journalArticle","2016","Tang, Guoming; Wu, Kui; Lei, Jingsheng; Tang, Jiuyang","A simple and robust approach to energy disaggregation in the presence of outliers","Sustainable Computing: Informatics and Systems","","2210-5379","10.1016/j.suscom.2016.01.004","https://www.sciencedirect.com/science/article/pii/S2210537916000056","Energy disaggregation is to discover the energy consumption of individual appliances from their aggregated energy values. Most existing approaches rely on either appliances’ signatures or their state transition patterns, both hard to obtain in practice. In addition, load data may be corrupted due to various reasons. To overcome the problems, this paper utilizes easily accessible knowledge of appliances and the sparsity of the switching events to design a Sparse Switching Event Recovering (SSER) method. Furthermore, a robust version of this method (RSSER) is developed to tackle the problems caused by corrupted data and unknown appliances. By minimizing the total variation of the sparse event matrix and introducing a virtual appliance, RSSER can obtain accurate energy disaggregation results in the presence of outliers, without using any explicit data cleansing method. To speed up RSSER, a Parallel Local Optimization Algorithm (PLOA) is proposed to solve the problem in active epochs of appliance activities in parallel. To automatically acquire the power consumption knowledge of appliances whose information is unknown, we develop a K-median clustering based power division approach and establish an appliance power configuration platform. Using real-world trace data from our energy monitoring platform, the performance of RSSER is compared with that of the state-of-the-art solutions, including the least square estimation methods and a machine learning method using iterative Hidden Markov Model. The results show that RSSER not only has an overall better performance in both detection accuracy and overhead, but also can tolerate the interference of corrupted data and unknown appliances.","2016-03-01","2022-06-10 03:07:30","2022-07-31 01:40:37","","8-19","","","9","","Sustainable Computing: Informatics and Systems","","","","","","","","","","","","","","","","","","","Optimization; Measurement; Energy disaggregation; Non-intrusive appliance load monitoring","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W58FAIW5","journalArticle","2020","Corrales, David Camilo; Ledezma, Agapito; Corrales, Juan Carlos","A case-based reasoning system for recommendation of data cleaning algorithms in classification and regression tasks","Applied Soft Computing","","1568-4946","10.1016/j.asoc.2020.106180","https://www.sciencedirect.com/science/article/pii/S1568494620301204","Recently, advances in Information Technologies (social networks, mobile applications, Internet of Things, etc.) generate a deluge of digital data; but to convert these data into useful information for business decisions is a growing challenge. Exploiting the massive amount of data through knowledge discovery (KD) process includes identifying valid, novel, potentially useful and understandable patterns from a huge volume of data. However, to prepare the data is a non-trivial refinement task that requires technical expertise in methods and algorithms for data cleaning. Consequently, the use of a suitable data analysis technique is a headache for inexpert users. To address these problems, we propose a case-based reasoning system (CBR) to recommend data cleaning algorithms for classification and regression tasks. In our approach, we represent the problem space by the meta-features of the dataset, its attributes, and the target variable. The solution space contains the algorithms of data cleaning used for each dataset. We represent the cases through a Data Cleaning Ontology. The case retrieval mechanism is composed of a filter and similarity phases. In the first phase, we defined two filter approaches based on clustering and quartile analysis. These filters retrieve a reduced number of relevant cases. The second phase computes a ranking of the retrieved cases by filter approaches, and it scores a similarity between a new case and the retrieved cases. The retrieval mechanism proposed was evaluated through a set of judges. The panel of judges scores the similarity between a query case against all cases of the case-base (ground truth). The results of the retrieval mechanism reach an average precision on judges ranking of 94.5% in top 3 (P@3), for top 7 (P@7) 84.55%, while in top 10 (P@10) 78.35%.","2020-05-01","2022-06-10 03:07:30","2022-07-30 21:35:56","","106180","","","90","","Applied Soft Computing","","","","","","","","","","","","","","","","","","","Classification; Case-based reasoning; Regression","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QGYSKZRT","journalArticle","2022","Nemade, Bhushankumar; Shah, Deven","An efficient IoT based prediction system for classification of water using novel adaptive incremental learning framework","Journal of King Saud University - Computer and Information Sciences","","1319-1578","10.1016/j.jksuci.2022.01.009","https://www.sciencedirect.com/science/article/pii/S1319157822000222","Creating an adaptive, accurate, and reliable model is a universal problem. Machine learning models give poor accuracy on unseen data, and therefore, the testing accuracy of the trained model is affected. This study presents a novel adaptive incremental learning framework for IoT based smart water quality classification system to predict the suitability of water for different applications. Initially, water quality data is collected using IoT sensors. After that, data cleaning is performed by removing missing values and outliers. Next, features associated with the sensed data are obtained, and unwanted features are removed. Then, the G-SMOTE technique is proposed, which hybridizes the SMOTE and the genetic algorithm to address the imbalanced data set problem. After that, the multi-class classification is performed using a modified deep learning neural network classifier which uses hyperparameter tunning technique to obtain better accuracy with minimum validation loss. Finally, the study presents a novel framework for adaptive incremental learning on unseen data. Experimental result shows that our method presents a new state-of-the-art multi-class water quality classification method with an accuracy of 99.34% and validation loss of 0.0415.","2022-01-28","2022-06-10 03:07:30","2022-07-31 02:19:33","","","","","","","Journal of King Saud University - Computer and Information Sciences","","","","","","","","","","","","","","","","","","","Water quality; Internet of Things; Adaptive incremental learning framework; classification of water; CPCB; Forward Feature Selection; G-SMOTE; MDLNN; smart environmental monitoring; Synthetic Minority Over sampling Technique; water quality monitoring; Water quality prediction; WBPCBWIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PUFUYWZ5","journalArticle","2020","Muhammad, Waqar; Esposito, Flavio; Maimaitijiang, Maitiniyazi; Sagan, Vasit; Bonaiuti, Enrico","Polly: A Tool for Rapid Data Integration and Analysis in Support of Agricultural Research and Education","Internet of Things","","2542-6605","10.1016/j.iot.2019.100141","https://www.sciencedirect.com/science/article/pii/S254266051930246X","Data analysis and modeling is a complex and demanding task. While a variety of software and tools exist to cope with this problem and tame big data operations, most of these tools are either not free, and when they are, they require large amount of configuration and steep learning curve. Moreover, they provide limited functionalities. In this paper we propose Polly, an online data analysis and modeling open-source tool that is intuitive to use and can be used with minimal or no configuration. Users can use Polly to rapidly integrate, analyze their data, prototype and test their novel methodologies. Polly can be used also as an educational tool. Users can use Polly to upload or connect to their structured data sources, load the required data into our system and perform various data processing tasks. Examples of such operations include data cleaning, data pre-processing, attribute encoding, regression and classification analysis. Aside from modeling, users can then download their results in the form of graphs in several standard visualization formats. While in this paper we focus on analyzing dataset for smart farming, our tool usage fits to a more general audience. To justify our backend design and implementation choices, we also present a performance analysis between backend virtualization technologies (containers or serverless computing), showing both expected and surprising results.","2020-03-01","2022-06-10 03:07:30","2022-07-31 04:48:20","","100141","","","9","","Internet of Things","","","","","","","","","","","","","","","","","","","machine learning; network virtualization; serverless computing; smart farming; UAV","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X743VEW5","journalArticle","2021","Lu, Xiang; Zhou, Wei; Qi, Chongchong; Luo, Huaiting; Zhang, Dongxu; Pham, Binh Thai","Prediction into the future: A novel intelligent approach for PM2.5 forecasting in the ambient air of open-pit mining","Atmospheric Pollution Research","","1309-1042","10.1016/j.apr.2021.101084","https://www.sciencedirect.com/science/article/pii/S1309104221001501","PM2.5 is a major pollutant in the ambient air of open-pit mining, whose accurate prediction is significant for its removal and control design. In this study, a hybrid method was proposed for analyzing PM2.5 concentration. A field measurement of PM2.5 concentration was conducted at an operating open-pit mine in northern China. The data was cleaned to remove the outliers in the PM2.5 results. Gradient boosting machine (GBM) optimized by particle swarm optimization (PSO) was used for the regression and classification analysis. In terms of regression, different scenarios were designed to evaluate the effect of time interval for future predictions (5 min, 10 min, 20 min, 40 min, 1 h, and 2 h ahead) on the performance. The classification of PM2.5 concentration into ‘severe’ and ‘not severe’ was also analysed. The results are as follows: (i) A total of 37 data instances were detected to be outliers, and the regression performance was improved after data cleaning (from 0.902 to 0.937 on the training set and from 0.877 to 0.940 on the testing set). (ii) The percentage of training set percentage was determined to be 70%, and PSO performed well in optimizing the hyper-parameters of GBM, (iii) The regression was quite satisfactory with the correlation coefficient being larger than 0.9. The testing performance decreased with the increase in time interval. (iv) An average accuracy of 0.954 was achieved during the classification of PM2.5 concentration. The predicted PM2.5 concentration could work as a precursor for the heavy PM pollution around open-pit mining.","2021-06-01","2022-06-10 03:07:30","2022-07-31 04:42:56","","101084","","6","12","","Atmospheric Pollution Research","","","","","","","","","","","","","","","","","","","Data cleaning; Gradient boosting machine; Hybrid prediction; Particle swarm optimization; PM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6CGBLH8I","journalArticle","2020","Sabbagh, David; Ablin, Pierre; Varoquaux, Gaël; Gramfort, Alexandre; Engemann, Denis A.","Predictive regression modeling with MEG/EEG: from source power to signals and cognitive states","NeuroImage","","1053-8119","10.1016/j.neuroimage.2020.116893","https://www.sciencedirect.com/science/article/pii/S1053811920303797","Predicting biomedical outcomes from Magnetoencephalography and Electroencephalography (M/EEG) is central to applications like decoding, brain-computer-interfaces (BCI) or biomarker development and is facilitated by supervised machine learning. Yet, most of the literature is concerned with classification of outcomes defined at the event-level. Here, we focus on predicting continuous outcomes from M/EEG signal defined at the subject-level, and analyze about 600 MEG recordings from Cam-CAN dataset and about 1000 EEG recordings from TUH dataset. Considering different generative mechanisms for M/EEG signals and the biomedical outcome, we propose statistically-consistent predictive models that avoid source-reconstruction based on the covariance as representation. Our mathematical analysis and ground-truth simulations demonstrated that consistent function approximation can be obtained with supervised spatial filtering or by embedding with Riemannian geometry. Additional simulations revealed that Riemannian methods were more robust to model violations, in particular geometric distortions induced by individual anatomy. To estimate the relative contribution of brain dynamics and anatomy to prediction performance, we propose a novel model inspection procedure based on biophysical forward modeling. Applied to prediction of outcomes at the subject-level, the analysis revealed that the Riemannian model better exploited anatomical information while sensitivity to brain dynamics was similar across methods. We then probed the robustness of the models across different data cleaning options. Environmental denoising was globally important but Riemannian models were strikingly robust and continued performing well even without preprocessing. Our results suggest each method has its niche: supervised spatial filtering is practical for event-level prediction while the Riemannian model may enable simple end-to-end learning.","2020-11-15","2022-06-10 03:07:30","2022-07-31 04:58:23","","116893","","","222","","NeuroImage","","","","","","","","","","","","","","","","","","","Machine learning; EEG; Covariance; MEG/EEG; Neuronal oscillations; Riemannian geometry; Spatial filters; CLASSIFICATION; INFORMATION; BRAIN-COMPUTER INTERFACES; CROSS-VALIDATION; FUNCTIONAL CONNECTIVITY; INDEPENDENT COMPONENT ANALYSIS; LINEAR-MODELS; MEG; NEURONAL OSCILLATIONS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NP7QX7VS","journalArticle","2019","Li, Shuangqi; He, Hongwen; Li, Jianwei","Big data driven lithium-ion battery modeling method based on SDAE-ELM algorithm and data pre-processing technology","Applied Energy","","0306-2619","10.1016/j.apenergy.2019.03.154","https://www.sciencedirect.com/science/article/pii/S0306261919305495","As one of the bottleneck technologies of electric vehicles (EVs), the battery hosts complex and hardly observable internal chemical reactions. Therefore, a precise mathematical model is crucial for the battery management system (BMS) to ensure the secure and stable operation of the battery in a multi-variable environment. First, a Cloud-based BMS (C-BMS) is established based on a database containing complete battery status information. Next, a data cleaning method based on machine learning is applied to the big data of batteries. Meanwhile, to improve the model stability under dynamic conditions, an F-divergence-based data distribution quality assessment method and a sampling-based data preprocess method is designed. Then, a lithium-ion battery temperature-dependent model is built based on Stacked Denoising Autoencoders- Extreme Learning Machine (SDAE-ELM) algorithm, and a new training method combined with data preprocessing is also proposed to improve the model accuracy. Finally, to improve reliability, a conjunction working mode between the C-BMS and the BMS in vehicles (V-BMS) is also proposed, providing as an applied case of the model. Using the battery data extracted from electric buses, the effectiveness and accuracy of the model are validated. The error of the estimated battery terminal voltage is within 2%, and the error of the estimated State of Charge (SoC) is within 3%.","2019-05-15","2022-06-10 03:07:30","2022-07-31 14:44:21","","1259-1273","","","242","","Applied Energy","","","","","","","","","","","","","","","","","","","Big data; Deep learning; Electric vehicles; Battery energy storage; Battery management system; Temperature-dependent model; REGRESSION; MACHINE; CONSUMPTION; NETWORK; DESIGN; ENERGY-STORAGE SYSTEM; STATE-OF-CHARGE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5L3LMCD8","journalArticle","2021","Zheng, Shuo; Zhu, Yu-Xin; Li, Dian-Qing; Cao, Zi-Jun; Deng, Qin-Xuan; Phoon, Kok-Kwang","Probabilistic outlier detection for sparse multivariate geotechnical site investigation data using Bayesian learning","Geoscience Frontiers","","1674-9871","10.1016/j.gsf.2020.03.017","https://www.sciencedirect.com/science/article/pii/S1674987120300918","Various uncertainties arising during acquisition process of geoscience data may result in anomalous data instances (i.e., outliers) that do not conform with the expected pattern of regular data instances. With sparse multivariate data obtained from geotechnical site investigation, it is impossible to identify outliers with certainty due to the distortion of statistics of geotechnical parameters caused by outliers and their associated statistical uncertainty resulted from data sparsity. This paper develops a probabilistic outlier detection method for sparse multivariate data obtained from geotechnical site investigation. The proposed approach quantifies the outlying probability of each data instance based on Mahalanobis distance and determines outliers as those data instances with outlying probabilities greater than 0.5. It tackles the distortion issue of statistics estimated from the dataset with outliers by a re-sampling technique and accounts, rationally, for the statistical uncertainty by Bayesian machine learning. Moreover, the proposed approach also suggests an exclusive method to determine outlying components of each outlier. The proposed approach is illustrated and verified using simulated and real-life dataset. It showed that the proposed approach properly identifies outliers among sparse multivariate data and their corresponding outlying components in a probabilistic manner. It can significantly reduce the masking effect (i.e., missing some actual outliers due to the distortion of statistics by the outliers and statistical uncertainty). It also found that outliers among sparse multivariate data instances affect significantly the construction of multivariate distribution of geotechnical parameters for uncertainty quantification. This emphasizes the necessity of data cleaning process (e.g., outlier detection) for uncertainty quantification based on geoscience data.","2021-01-01","2022-06-10 03:07:30","2022-07-31 14:28:38","","425-439","","1","12","","Geoscience Frontiers","","","","","","","","","","","","","","","","","","","Outlier detection; Bayesian machine learning; Mahalanobis distance; Resampling by half-means; Site investigation; Sparse multivariate data; REGRESSION; MODEL; PRIOR DISTRIBUTIONS; RELIABILITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZA4AWPDF","journalArticle","2020","Díaz-Verdejo, Jesús E.; Estepa, Antonio; Estepa, Rafael; Madinabeitia, German; Muñoz-Calle, Fco. Javier","A methodology for conducting efficient sanitization of HTTP training datasets","Future Generation Computer Systems","","0167-739X","10.1016/j.future.2020.03.033","https://www.sciencedirect.com/science/article/pii/S0167739X19322629","The performance of anomaly-based intrusion detection systems depends on the quality of the datasets used to form normal activity profiles. Suitable datasets should include high volumes of real-life data free from attack instances. On account of this requirement, obtaining quality datasets from collected data requires a process of data sanitization that may be prohibitive if done manually, or uncertain if fully automated. In this work, we propose a sanitization approach for obtaining datasets from HTTP traces suited for training, testing, or validating anomaly-based attack detectors. Our methodology has two sequential phases. In the first phase, we clean known attacks from data using a pattern-based approach that relies on tools that detect URI-based known attacks. In the second phase, we complement the result of the first phase by conducting assisted manual labeling systematically and efficiently, setting the focus of expert examination not on the raw data (which would be millions of URIs), but on the set of words that compose the URIs. This dramatically downsizes the volume of data that requires expert discernment, making manual sanitization of large datasets feasible. We have applied our method to sanitize a trace that includes 45 million requests received by the library web server of the University of Seville. We were able to generate clean datasets in less than 84 h with only 33 h of manual supervision. We have also applied our method to some public benchmark datasets, confirming that attacks unnoticed by signature-based detectors can be discovered in a reduced time span.","2020-08-01","2022-06-10 03:07:30","2022-07-30 22:39:58","","67-82","","","109","","Future Generation Computer Systems","","","","","","","","","","","","","","","","","","","Data acquisition; Anomaly based intrusion detection; Training datasets","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ENBHT5NC","journalArticle","2016","Yan, Wai Yeung; Morsy, Salem; Shaker, Ahmed; Tulloch, Mark","Automatic extraction of highway light poles and towers from mobile LiDAR data","Optics & Laser Technology","","0030-3992","10.1016/j.optlastec.2015.09.017","https://www.sciencedirect.com/science/article/pii/S0030399215301031","Mobile LiDAR has been recently demonstrated as a viable technique for pole-like object detection and classification. Despite that a desirable accuracy (around 80%) has been reported in the existing studies, majority of them were presented in the street level with relatively flat ground and very few of them addressed how to extract the entire pole structure from the ground or curb surface. Therefore, this paper attempts to fill the research gap by presenting a workflow for automatic extraction of light poles and towers from mobile LiDAR data point cloud, with a particular focus on municipal highway. The data processing workflow includes (1) an automatic ground filtering mechanism to separate aboveground and ground features, (2) an unsupervised clustering algorithm to cluster the aboveground data point cloud, (3) a set of decision rules to identify and classify potential light poles and towers, and (4) a least-squares circle fitting algorithm to fit the circular pole structure so as to remove the ground points. The workflow was tested with a set of mobile LiDAR data collected for a section of highway 401 located in Toronto, Ontario, Canada. The results showed that the proposed method can achieve an over 91% of detection rate for five types of light poles and towers along the study area.","2016-03-01","2022-06-10 03:07:31","2022-07-31 14:49:41","","162-168","","","77","","Optics & Laser Technology","","","","","","","","","","","","","","","","","","","Remote sensing; DBSCAN; Decision tree classification; GIS; Ground filtering; Least-squares; Light poles; Mobile LiDAR; Unsupervised clustering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2V35SNKC","journalArticle","2021","Bridgelall, Raj; Tolliver, Denver D.","Railroad accident analysis using extreme gradient boosting","Accident Analysis & Prevention","","0001-4575","10.1016/j.aap.2021.106126","https://www.sciencedirect.com/science/article/pii/S0001457521001573","Railroads are critical to the economic health of a nation. Unfortunately, railroads lose hundreds of millions of dollars from accidents each year. Trends reveal that derailments consistently account for more than 70 % of the U.S. railroad industry’s average annual accident cost. Hence, knowledge of explanatory factors that distinguish derailments from other accident types can inform more cost-effective and impactful railroad risk management strategies. Five feature scoring methods, including ANOVA and Gini, agreed that the top four explanatory factors in accident type prediction were track class, type of movement authority, excess speed, and territory signalization. Among 11 different types of machine learning algorithms, the extreme gradient boosting method was most effective at predicting the accident type with an area under the receiver operating curve (AUC) metric of 89 %. Principle component analysis revealed that relative to other accident types, derailments were more strongly associated with lower track classes, non-signalized territories, and movement authorizations within restricted limits. On average, derailments occurred at 16 kph below the speed limit for the track class whereas other accident types occurred at 32 kph below the speed limit. Railroads can use the integrated data preparation, machine learning, and feature ranking framework presented to gain additional insights for managing risk, based on their unique operating environments.","2021-06-01","2022-06-10 03:07:31","2022-07-31 15:19:08","","106126","","","156","","Accident Analysis & Prevention","","","","","","","","","","","","","","","","","","","Machine learning; Risk management; Data cleaning; Feature engineering; Financial loss; Principle component analysis; MODELS; SEVERITY","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IMBAFQUC","journalArticle","2021","Lee, Jun S.; Min Kim, Hyun; Il Kim, Sung; Min Lee, Hyun","Evaluation of structural integrity of railway bridge using acceleration data and semi-supervised learning approach","Engineering Structures","","0141-0296","10.1016/j.engstruct.2021.112330","https://www.sciencedirect.com/science/article/pii/S0141029621004806","In order to investigate the structural integrity of a railway bridge, supervised and semi-supervised deep learning techniques incorporating wavelet transform (WT) were used where the measured acceleration data were transformed into images. Specifically, the structural integrity was evaluated both by acceleration datasets of a newly built bridge and by damaged datasets calculated from numerical analyses, and assumed damage in the structure was detected by supervised and semi-supervised learning methods. For the supervised learning, the well-known AlexNet and VGG16 convolutional neural network (CNN) models were employed, and during the one class (OC) classification of the semi-supervised learning approach, wherein only the label of the normal data was known a priori, a transfer learning method was utilized. It was found that the minimum value of damage with which novelty was detected was found to be at least 15% reduction of the stiffness in our case. It was also found that the cosine rather than Euclidean distance metric was more accurate during damage prediction. Although both methods showed very reliable prediction results, the semi-supervised learning method was shown to be more practical under the given field conditions.","2021-07-15","2022-06-10 03:07:31","2022-07-31 13:53:54","","112330","","","239","","Engineering Structures","","","","","","","","","","","","","","","","","","","Anomaly detection; Semi-supervised learning; Novelty detection; Wavelet transform; Acceleration data; Railway bridge","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z8ZUQ9AC","bookSection","2021","Algren, Mikaela; Fisher, Wendy; Landis, Amy E.","Chapter 8 - Machine learning in life cycle assessment","Data Science Applied to Sustainability Analysis","978-0-12-817976-5","","","https://www.sciencedirect.com/science/article/pii/B9780128179765000097","Machine learning (ML) has been used in life cycle assessment (LCA) to estimate the values of environmental impact characterization factors and to conduct sensitivity analyses. ML has even been used to develop surrogate LCAs, which have enabled prediction of future products’ full life cycle environmental impacts based on design-phase product characteristics. Outside of LCA, applications of ML algorithms have included data cleaning, predicting system output flows or performance, ecosystem informatics, and system optimization. Considering these uses and capabilities of ML, opportunities exist for using ML in cleaning data for life cycle inventories (LCI), estimating flow data for unit processes, improving the quality and quantity of data used to determine impact characterization factors, and generating inventory data for scenario analyses. In this chapter, we introduce LCA and ML, look at how ML has been used in LCA and in development of surrogate LCAs, and discuss other applications that could inform future ML-based tools for LCA.","2021-01-01","2022-06-10 03:07:31","2022-07-31 14:39:21","","167-190","","","","","","","","","","","Elsevier","","","","","","","","","DOI: 10.1016/B978-0-12-817976-5.00009-7","","","","Machine learning; Characterization factors; Inventory data; Life cycle assessment; Scenario analyses; Sensitivity analyses; Surrogate LCA","","Dunn, Jennifer; Balaprakash, Prasanna","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IWW3ZG78","journalArticle","2022","Xiao, Tong; Xu, Peng; Ding, Renrong; Chen, Zhe","An interpretable method for identifying mislabeled commercial building based on temporal feature extraction and ensemble classifier","Sustainable Cities and Society","","2210-6707","10.1016/j.scs.2021.103635","https://www.sciencedirect.com/science/article/pii/S2210670721008982","Proper building categorization is important in building energy efficiency analysis. Primary space usage (PSU) is a typical and widely used commercial building categorization method. The PSU labels are ascertained once the buildings are put into use but not always modified on time when the building usages change, which may lead to false results in analysis. In this paper, we propose a method to identify mislabeled commercial buildings based on analysis of the energy time series collected by electric meters. The method is constructed as follows: (1) data cleaning and transformation; (2) three types of temporal feature extraction; (3) several single classifier training, and the ensemble classifier building; (4) mislabel building identification and correction. The method provides a supervise way to identify mislabeled building. We applied the method to a public dataset from the Department of General Services from Washington, D.C. and found that 22.4% of the buildings were mislabeled. We also designed 1000 evaluation cases to prove the effectiveness of the method. Based on the results of the cases and the good interpretation of the method, we discuss the mislabeled buildings in reality and the temporal differences among different PSU-type buildings. We also discuss the renewal or improvement of PSU categorization.","2022-03-01","2022-06-10 03:07:31","2022-07-31 02:23:39","","103635","","","78","","Sustainable Cities and Society","","","","","","","","","","","","","","","","","","","Ensemble classification; Mislabel; Model interpretability; Primary space usage (PSU); Temporal features extraction; PREDICTION; KNOWLEDGE; FRAMEWORK; MODEL; ANALYTICS; ELECTRICITY CONSUMPTION; METER DATA; OPERATIONS; PROFILES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4B5EWRQW","journalArticle","2019","Simonini, Giovanni; Gagliardelli, Luca; Bergamaschi, Sonia; Jagadish, H.V.","Scaling entity resolution: A loosely schema-aware approach","Information Systems","","0306-4379","10.1016/j.is.2019.03.006","https://www.sciencedirect.com/science/article/pii/S0306437918304083","In big data sources, real-world entities are typically represented with a variety of schemata and formats (e.g., relational records, JSON objects, etc.). Different profiles (i.e., representations) of an entity often contain redundant and/or inconsistent information. Thus identifying which profiles refer to the same entity is a fundamental task (called Entity Resolution) to unleash the value of big data. The naïve all-pairs comparison solution is impractical on large data, hence blocking methods are employed to partition a profile collection into (possibly overlapping) blocks and limit the comparisons to profiles that appear in the same block together. Meta-blocking is the task of restructuring a block collection, removing superfluous comparisons. Existing meta-blocking approaches rely exclusively on schema-agnostic features, under the assumption that handling the schema variety of big data does not pay-off for such a task. In this paper, we demonstrate how “loose” schema information (i.e., statistics collected directly from the data) can be exploited to enhance the quality of the blocks in a holistic loosely schema-aware (meta-)blocking approach that can be used to speed up your favorite Entity Resolution algorithm. We call it Blast (Blocking with Loosely-Aware Schema Techniques). We show how Blast can automatically extract the loose schema information by adopting an LSH-based step for efficiently handling volume and schema heterogeneity of the data. Furthermore, we introduce a novel meta-blocking algorithm that can be employed to efficiently execute Blast on MapReduce-like systems (such as Apache Spark). Finally, we experimentally demonstrate, on real-world datasets, how Blast outperforms the state-of-the-art (meta-)blocking approaches.","2019-07-01","2022-06-10 03:07:31","2022-07-31 04:27:30","","145-165","","","83","","Information Systems","","","","","","","","","","","","","","","","","","","Data cleaning; Apache Spark; Entity resolution; Big data integration; Meta-blocking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LZ6G3KLV","journalArticle","2021","Owolabi, Oluwafisayo; Okoh, Daniel; Rabiu, Babatunde; Obafaye, Aderonke; Dauda, Kashim","A median absolute deviation-neural network (MAD-NN) method for atmospheric temperature data cleaning","MethodsX","","2215-0161","10.1016/j.mex.2021.101533","https://www.sciencedirect.com/science/article/pii/S2215016121003265","Some of the biggest challenges in climate change arise from bad dataset. To address this issue, we have developed a novel method for cleaning coarse atmospheric dataset; the median absolute deviation-neural network (MAD-NN) method. By combining the median absolute deviation (MAD) technique with neural network training, this method uses a sequence of steps to clean coarse atmospheric dataset and to predict high accuracy dataset for periods when measurements are not available. To demonstrate this method, we used atmospheric temperature data for 17 different observational weather stations across Nigeria. In brief:•We developed a novel method for generating consistent data stream from coarse dataset.•The MAD-NN method can be used to fill observational data gaps and remove spikes in data.•This method is specifically useful for weather observatories with coarse atmospheric data, as well as increasing the credibility of scientific findings.","2021-01-01","2022-06-10 03:07:31","2022-07-30 22:39:07","","101533","","","8","","MethodsX","","","","","","","","","","","","","","","","","","","Climate change; Data cleaning; Neural network; Outliers; Atmospheric dataset; Coarse dataset; MAD-NN; Observational data gaps; Surface air temperature; Weather observatories","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VNSS56NJ","journalArticle","2021","Mucchielli, P.; Bhowmik, B.; Ghosh, B.; Pakrashi, V.","Real-time accurate detection of wind turbine downtime - An Irish perspective","Renewable Energy","","0960-1481","10.1016/j.renene.2021.07.139","https://www.sciencedirect.com/science/article/pii/S0960148121011496","Wind turbines are complex systems that are susceptible to frequent anomalies, faults, and abnormal behaviour. These are caused mainly due to off-nominal conditions, catastrophic events, and major failures, resulting in downtime conditions. An accurate and timely detection of downtime events provides crucial information for planning and decision-making. This study investigates the utility of wind power and wind speed as potential parameters for real-time downtime detection. Early and accurate detection of these anomalies using system outputs collected from monitoring stations is challenging and involved, especially when attempted in real-time. In this article, a real-time downtime detection framework is proposed that maps system outputs to turbine events - faults, scheduled, and unplanned maintenance - through online condition indicators. Without imposing strong distributional assumptions, using available training samples, an optimal, cost-sensitive real-time anomaly detection framework is proposed to determine whether a sample is anomalous. Considering the trade-off between misclassification errors and detection rates, detection studies are performed using wind power and speed - calibrated against available alarm classifiers - obtained from two Irish wind farms. The data cleaning and formatting for analysis was automated and subjected to classification with several levels of complexity. Recursive condition indicators (RCIs) such as Recursive Mahalanobis distance (RMD) and Recursive Residual Error (RRE) are chosen as features for classification. The real-time detection model becomes particularly useful when it is prohibitive to identify in advance the anomalies without a baseline of the system behaviour under such conditions. Case studies involving Irish wind Supervisory Control And Data Acquisition (SCADA) data demonstrate the successful application of the proposed work for early and accurate downtime detection with comparison to a reference machine learning approach.","2021-12-01","2022-06-10 03:07:31","2022-07-31 15:36:18","","1969-1989","","","179","","Renewable Energy","","","","","","","","","","","","","","","","","","http://dx.doi.org/10.1016/j.renene.2021.07.139","Anomaly detection; Wind power; Wind turbines; Decision making; Maintenance; Data acquisition; Economic and social effects; Real time systems; Downtime detection; Dynamic systems; Eigen perturbation; Real-time; Wind turbine; Dynamical systems; DIAGNOSIS","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z3ZAWWS3","bookSection","2021","Belyadi, Hoss; Haghighat, Alireza","Chapter 3 - Machine learning workflows and types","Machine Learning Guide for Oil and Gas Using Python","978-0-12-821929-4","","","https://www.sciencedirect.com/science/article/pii/B9780128219294000019","This chapter walks the reader through a step-by-step guide for building a Machine Learning (ML) model. These steps include but are not limited to data gathering and integration, data cleaning (data visualization, outlier detection, and data imputation), feature ranking and selection, data normalization or standardization, cross-validation (including holdout method, k-fold cross-validation, stratified k-fold cross-validation, leave-P-out cross-validation), and blind set validation. Bias–variance trade-off is also discussed with the visualization illustration for building a successful general ML model. Afterward, various ML types such as supervised, unsupervised, and reinforcement learning are discussed. General information about various types of data centers as well as cloud versus edge computing are also included in this chapter. Next, various algorithms for dimensionality reductions such as principal component analysis (PCA) and nonnegative matrix factorization (NMF) along with step-by-step math and scikit-learn implementation in Python are illustrated. Dimensionality reduction was used for a completions data set to reduce the dimensionality of data from four to two (components) using both PCA and NMF. The clear illustration of the codes can be easily followed to apply the same techniques and algorithms to any other desired data sets.","2021-01-01","2022-06-10 03:07:31","2022-07-31 14:39:27","","97-123","","","","","","","","","","","Gulf Professional Publishing","","","","","","","","","DOI: 10.1016/B978-0-12-821929-4.00001-9","","","","Principal component analysis; Data centers; Bias–variance trade-off; Cloud/edge computing; Cross-validation; Data gathering and integration; Data normalization and standardization; Feature ranking and selection; Nonnegative matrix factorization; Scikit-learn; Supervised/unsupervised/reinforcement learning","","Belyadi, Hoss; Haghighat, Alireza","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YML4WKMZ","journalArticle","2022","Mancipe-Castro, L.; Gutiérrez-Carvajal, R.E.","Prediction of environment variables in precision agriculture using a sparse model as data fusion strategy","Information Processing in Agriculture","","2214-3173","10.1016/j.inpa.2021.06.007","https://www.sciencedirect.com/science/article/pii/S2214317321000561","Precision agriculture seeks to optimize production processes by monitoring and analyzing environmental variables. For example, establishing farming actions on the crop requires analyzing variables such as temperature, ambient humidity, soil moisture, solar irradiance, and Rainfall. Although these signals might contain valuable information, it is vital to mix up the monitored signals and analyze them as a whole to provide more accurate information than analyzing the signals separately. Unfortunately, monitoring all these variables results in high costs. Hence it is necessary to establish an appropriate method that allows the infer variables behavior without the direct measurement of all of them. This paper introduces a multi-sensor data fusion technique, based on a sparse representation, to find the most straightforward and complete linear equation to predict and understand a particular variable behavior based on other monitored environmental variables measurements. Moreover, this approach aims to provide an interpretable model that allows understanding how these variables are combined to achieve such results. The fusion strategy explained in this manuscript follows a four-step process that includes 1. data cleaning, 2. redundant variable detection, 3. dictionary generation, and 4. sparse regression. The algorithm requires a target variable and two highly correlated signals. It is essential to point out that the developed method has no restrictions to specific variables. Consequently, it is possible to replicate this method for the semiautomatic prediction of multiple critical environmental variables. As a case study, this work used the SML2010 data set of the UCI machine learning repository to predicted the humidity's derivative trend function with an error rate lower than 17% and a mean absolute error lower than 6%. The experiment results show that even though sparse model predictions might not be the most accurate compared to those of linear regression (LR), support vector machine (SVM), and extreme learning machine (ELM) since it is not a black-box model, it guarantees greater interpretability of the problem.","2022-06-01","2022-06-10 03:07:31","2022-07-31 03:09:31","","171-183","","2","9","","Information Processing in Agriculture","","","","","","","","","","","","","","","","","","http://dx.doi.org/10.1016/j.inpa.2021.06.007","Learning systems; Support vector machines; Forecasting; Support vector regression; Agricultural robots; Precision agriculture; Sensor data fusion; Humidity; Inference of variables; Multi-sensor data fusion; Sparse representation; Soil moisture","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5XPNG3M6","journalArticle","2021","Giglioni, Valentina; García-Macías, Enrique; Venanzi, Ilaria; Ierimonti, Laura; Ubertini, Filippo","The use of receiver operating characteristic curves and precision-versus-recall curves as performance metrics in unsupervised structural damage classification under changing environment","Engineering Structures","","0141-0296","10.1016/j.engstruct.2021.113029","https://www.sciencedirect.com/science/article/pii/S0141029621011706","The development of long-term structural health monitoring systems is recently receiving a growing scientific interest in the field of Civil Engineering. In the context of unsupervised learning processes, deviations of dynamic parameters from their normal conditions can allow damage detection. However, due to the fact that modal properties are highly sensitive to environmental and operational factors, it is extremely important to remove such effects in order to obtain suitable damage sensitive features. In this regard, the selection of a proper multivariate statistical data analysis method for removing environmental effects is a key issue, heavily affecting the distribution of the residuals, the control chart and therefore the damage detection. However, specific criteria guiding the optimal definition of such statistical methods are yet to be established. In order to bridge this research gap, an original methodology is proposed in the present paper, based on Receiver Operating Characteristic (ROC) curves in combination with Precision-versus-Recall (PR) curves. Specifically, ROC and PR curves are computed and compared for a variety of statistical methods for data normalization and different damage scenarios and the model selection strategy is formulated as an optimization problem. The proposed approach is exemplified by application in two case studies of continuously monitored structures: the Z24 Bridge in Switzerland and the Consoli Palace, a mediaeval masonry building in Italy. The results highlight that the combined use of both ROC and PR curves represents a suitable tool for defining the most effective statistical data analysis method and the optimal damage threshold, in order to minimize the occurrence of false alarms and missing alarms.","2021-11-01","2022-06-10 03:07:31","2022-07-31 03:58:47","","113029","","","246","","Engineering Structures","","","","","","","","","","","","","","","","","","","Unsupervised learning; Damage detection; Precision–recall curves; ROC curves; Vibration-based SHM","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NSD947S8","journalArticle","2020","Gutierrez-Torre, Alberto; Berral, Josep Ll.; Buchaca, David; Guevara, Marc; Soret, Albert; Carrera, David","Improving maritime traffic emission estimations on missing data with CRBMs","Engineering Applications of Artificial Intelligence","","0952-1976","10.1016/j.engappai.2020.103793","https://www.sciencedirect.com/science/article/pii/S0952197620301822","Maritime traffic emissions are a major concern to governments as they heavily impact the Air Quality in coastal cities. Ships use the Automatic Identification System (AIS) to continuously report position and speed among other features, and therefore this data is suitable to be used to estimate emissions, if it is combined with engine data. However, important ship features are often inaccurate or missing. State-of-the-art complex systems, like CALIOPE at the Barcelona Supercomputing Center, are used to model Air Quality. These systems can benefit from AIS based emission models as they are very precise in positioning the pollution. Unfortunately, these models are sensitive to missing or corrupted data, and therefore they need data curation techniques to significantly improve the estimation accuracy. In this work, we propose a methodology for treating ship data using Conditional Restricted Boltzmann Machines (CRBMs) plus machine learning methods to improve the quality of data passed to emission models that can also be applied to other GPS and time-series problems. Results show that we can improve the default methods proposed to cover missing data. In our results, we observed that using our method the models boosted their accuracy to detect otherwise undetectable emissions. In particular, we used a real data-set of AIS data, provided by the Spanish Port Authority, to estimate that thanks to our method, the model was able to detect 45% of additional emissions, representing 152 tonnes of pollutants per week in Barcelona and propose new features that may enhance emission modeling.","2020-09-01","2022-06-10 03:07:31","2022-07-31 05:57:24","","103793","","","94","","Engineering Applications of Artificial Intelligence","","","","","","","","","","","","","","","","","","","Global positioning system; Automation; Learning systems; Ships; Air quality; Time series; Data cleaning; AIS; CRBM; Emission modeling; GPS; Ship time series","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VUJBYM5Z","journalArticle","2020","Jaiswal, Devendra Prakash; Kumar, Srishti; Mukherjee, Partha","Customer Transaction Prediction System","“Complex Adaptive Systems”Malvern, PennsylvaniaNovember 13-15, 2019","","1877-0509","10.1016/j.procs.2020.02.256","https://www.sciencedirect.com/science/article/pii/S1877050920303951","In this data-driven world, every innovation is targeted towards the attainment of a better future where we can sustain ourselves in the easiest and most comfortable of ways. The desire of this utopia has induced numerous inventions which has led us all to this era where Artificial Intelligence has become a very crucial part of our daily lives. One such implementation which we discuss here, pertains to building a customer transaction predictions system using a completely anonymized dataset. We incorporate deep learning methodologies along with a gradient boosting tree-based algorithm which would help us in identifying the best approach for our problem. This implementation aims to enhance human intuition through techniques, which would be capable of helping the institutions in achieving customer satisfaction and in identifying important features from the anonymized dataset.","2020-01-01","2022-06-10 03:07:32","2022-07-31 02:54:39","","49-56","","","168","","Procedia Computer Science","","","","","","","","","","","","","","","","","","","Data Cleaning; Machine Learning; Artificial Intelligence; XGBoost; Anonymized Dataset Handling; Artificial Neural Networks; Boosting Algorithms; Pre-processing; Data Cleaning and Pre-processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D722SFF4","journalArticle","2021","Chen, X.; Van Hillegersberg, Jos; Topan, E.; Smith, S.; Roberts, M.","Application of data-driven models to predictive maintenance: Bearing wear prediction at TATA steel","Expert Systems with Applications","","0957-4174","10.1016/j.eswa.2021.115699","https://www.sciencedirect.com/science/article/pii/S0957417421010836","Industries that are in transition to Industry 4.0 often face challenges in applying data-driven methods to improve performance. While ample methods are available in literature, knowledge on how to select and apply them is scarce. This study aims to address this gap reported on the design and implementation of data-driven models for predictive maintenance at TATA Steel, Shotton. The objective of the project is to predict the wearing behaviour of the components in the steel production line for maintenance activity decision support. To achieve the predictive maintenance goal, the approach applied can be summarized as follows: 1. business understanding and data collection, 2. literature review, 3. data preparation and exploration, 4. modelling and result analysis and 5. conclusion and recommendation. The data-driven methods that were analysed and compared are: Partial Least Squares Regression (PLSR), Artificial Neu- ral Network (ANN) and Random Forest(RF). After cleaning and analysing the production line data, predictive maintenance with the current available data in TATA Steel, Shotton is best feasible with PLSR. The study further concludes that, predictive maintenance is likely to be feasible in similar industries that are in transition to industry 4.0 and have growing volumes of production data with varying quality and detail. However, as illustrated in this case study, careful understanding of the industrial process, thorough modeling and cleaning of the data as well as careful method selection and tuning are required. Moreover, the resulting model needs to be packaged in a user friendly way to find its way to the job floor.","2021-12-30","2022-06-10 03:07:32","2022-07-31 03:25:52","","115699","","","186","","Expert Systems with Applications","","","","","","","","","","","","","","","","","","","Machine learning; Industry 4.0; Predictive maintenance; Data-driven","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9E5KYQGZ","journalArticle","2022","Gao, Guangyuan; Meng, Shengwang; Wüthrich, Mario V.","What can we learn from telematics car driving data: A survey","Insurance: Mathematics and Economics","","0167-6687","10.1016/j.insmatheco.2022.02.004","https://www.sciencedirect.com/science/article/pii/S0167668722000233","We give a survey on the field of telematics car driving data research in actuarial science. We describe and discuss telematics car driving data, we illustrate the difficulties of telematics data cleaning, and we highlight the transparency issue of telematics car driving data resulting in associated privacy concerns. Transparency of telematics data is demonstrated by aiming at correctly allocating different car driving trips to the right drivers. This is achieved rather successfully by a convolutional neural network that manages to discriminate different car drivers by their driving styles. In a last step, we describe two approaches of using telematics data for improving claims frequency prediction, one is based on telematics heatmaps and the other one on time series of individual trips, respectively.","2022-05-01","2022-06-10 03:07:32","2022-07-31 03:35:56","","185-199","","","104","","Insurance: Mathematics and Economics","","","","","","","","","","","","","","","","","","","Convolutional neural networks; Heatmaps; Limited fluctuation credibility model; Poisson regression models; Telematics car driving data; RISK; CLASSIFICATION; ACCIDENT; CYCLE; INSURANCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HJKWU4WM","journalArticle","2020","Koppu, Srinivas; Maddikunta, Praveen Kumar Reddy; Srivastava, Gautam","Deep learning disease prediction model for use with intelligent robots","Computers & Electrical Engineering","","0045-7906","10.1016/j.compeleceng.2020.106765","https://www.sciencedirect.com/science/article/pii/S0045790620306200","Deep learning applications with robotics contribute to massive challenges that are not addressed in machine learning. The present world is currently suffering from the COVID-19 pandemic, and millions of lives are getting affected every day with extremely high death counts. Early detection of the disease would provide an opportunity for proactive treatment to save lives, which is the primary research objective of this study. The proposed prediction model caters to this objective following a stepwise approach through cleaning, feature extraction, and classification. The cleaning process constitutes the cleaning of missing values ,which is proceeded by outlier detection using the interpolation of splines and entropy-correlation. The cleaned data is then subjected to a feature extraction process using Principle Component Analysis. A Fitness Oriented Dragon Fly algorithm is introduced to select optimal features, and the resultant feature vector is fed into the Deep Belief Network. The overall accuracy of the proposed scheme experimentally evaluated with the traditional state of the art models. The results highlighted the superiority of the proposed model wherein it was observed to be 6.96% better than Firefly, 6.7% better than Particle Swarm Optimization, 6.96% better than Gray Wolf Optimization ad 7.22% better than Dragonfly Algorithm.","2020-10-01","2022-06-10 03:07:32","2022-07-31 14:22:03","","106765","","","87","","Computers & Electrical Engineering","","","","","","","","","","","","","","","","","","","Deep learning; Feature extraction; Data cleaning; COVID-19; Disease prediction; Dragonfly optimization; Fitness basis; Intelligent robotics; ALGORITHM; CLOUD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SNDN86FE","journalArticle","2022","Schmidt, Leon J.; Rieger, Oliver; Neznansky, Mark; Hackelöer, Max; Dröge, Lisa A.; Henrich, Wolfgang; Higgins, David; Verlohren, Stefan","A machine-learning–based algorithm improves prediction of preeclampsia-associated adverse outcomes","American Journal of Obstetrics and Gynecology","","0002-9378","10.1016/j.ajog.2022.01.026","https://www.sciencedirect.com/science/article/pii/S0002937822000503","Background Preeclampsia presents a highly prevalent burden on pregnant women with an estimated incidence of 2% to 5%. Preeclampsia increases the maternal risk of death 20-fold and is one of the main causes of perinatal morbidity and mortality. Novel biomarkers, such as soluble fms-like tyrosine kinase-1 and placental growth factor in addition to a wide span of conventional clinical data (medical history, physical symptoms, laboratory parameters, etc.), present an excellent basis for the application of early-detection machine-learning models. Objective This study aimed to develop, train, and test an automated machine-learning model for the prediction of adverse outcomes in patients with suspected preeclampsia. Study Design Our real-world dataset of 1647 (2472 samples) women was retrospectively recruited from women who presented to the Department of Obstetrics at the Charité – Universitätsmedizin Berlin, Berlin, Germany, between July 2010 and March 2019. After standardization and data cleaning, we calculated additional features regarding the biomarkers soluble fms-like tyrosine kinase-1 and placental growth factor and sonography data (umbilical artery pulsatility index, middle cerebral artery pulsatility index, mean uterine artery pulsatility index), resulting in a total of 114 features. The target metric was the occurrence of adverse outcomes throughout the remaining pregnancy and 2 weeks after delivery. We trained 2 different models, a gradient-boosted tree and a random forest classifier. Hyperparameter training was performed using a grid search approach. All results were evaluated via a 10 × 10-fold cross-validation regimen. Results We obtained metrics for the 2 naive machine-learning models. A gradient-boosted tree model was performed with a positive predictive value of 88%±6%, a negative predictive value of 89%±3%, a sensitivity of 66%±5%, a specificity of 97%±2%, an overall accuracy of 89%±3%, an area under the receiver operating characteristic curve of 0.82±0.03, an F1 score of 0.76±0.04, and a threat score of 0.61±0.05. The random forest classifier returned an equal positive predictive value (88%±6%) and specificity (97%±1%) while performing slightly inferior on the other available metrics. Applying differential cutoffs instead of a naive cutoff for positive prediction at ≥0.5 for the classifier’s results yielded additional increases in performance. Conclusion Machine-learning techniques were a valid approach to improve the prediction of adverse outcomes in pregnant women at high risk of preeclampsia vs current clinical standard techniques. Furthermore, we presented an automated system that did not rely on manual tuning or adjustments.","2022-02-01","2022-06-10 03:07:32","2022-07-30 22:38:43","","","","","","","American Journal of Obstetrics and Gynecology","","","","","","","","","","","","","","","","","","","machine learning; random forest; adverse outcomes; clinical decision support; placental growth factor; predictive models; preeclampsia; soluble fms-like tyrosine kinase-1","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F8H63L9R","journalArticle","2020","Rokham, Hooman; Pearlson, Godfrey; Abrol, Anees; Falakshahi, Haleh; Plis, Sergey; Calhoun, Vince D.","Addressing Inaccurate Nosology in Mental Health: A Multilabel Data Cleansing Approach for Detecting Label Noise From Structural Magnetic Resonance Imaging Data in Mood and Psychosis Disorders","Understanding the Nature and Treatment of Psychopathology: Letting the Data Guide the Way","","2451-9022","10.1016/j.bpsc.2020.05.008","https://www.sciencedirect.com/science/article/pii/S2451902220301324","Background Mental health diagnostic approaches are seeking to identify biological markers to work alongside advanced machine learning approaches. It is difficult to identify a biological marker of disease when the traditional diagnostic labels themselves are not necessarily valid. Methods We worked with T1 structural magnetic resonance imaging data collected from 1493 individuals comprising healthy control subjects, patients with psychosis, and their unaffected first-degree relatives. Specifically, the dataset included 176 bipolar disorder probands, 134 schizoaffective disorder probands, 240 schizophrenia probands, 362 control subjects, and 581 patient relatives. We assumed that there might be noise in the diagnostic labeling process. We detected label noise by classifying the data multiple times using a support vector machine classifier, and then we flagged those individuals in which all classifiers unanimously mislabeled those subjects. Next, we assigned a new diagnostic label to these individuals, based on the biological data (magnetic resonance imaging), using an iterative data cleansing approach. Results Simulation results showed that our method was highly accurate in identifying label noise. Both diagnostic and biotype categories showed about 65% and 63% of noisy labels, respectively, with the largest amount of relabeling occurring between the healthy control subjects and individuals with bipolar disorder and schizophrenia as well as in unaffected close relatives. The extraction of imaging features highlighted regional brain changes associated with each group. Conclusions This approach represents an initial step toward developing strategies that need not assume that existing mental health diagnostic categories are always valid but rather allows us to leverage this information while also acknowledging that there are misassignments.","2020-08-01","2022-06-10 03:07:32","2022-07-31 02:10:11","","819-832","","8","5","","Biological Psychiatry: Cognitive Neuroscience and Neuroimaging","","","","","","","","","","","","","","","","","","","Deep learning; Machine learning; Data cleansing; Label noise; Psychosis disorders; Structural MRI; CLASSIFICATION; BIPOLAR-SCHIZOPHRENIA NETWORK; FRAMEWORK; HETEROGENEITY; PHENOTYPES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YWMZ9RRL","journalArticle","2019","Makkar, Aaisha; Kumar, Neeraj","Cognitive spammer: A Framework for PageRank analysis with Split by Over-sampling and Train by Under-fitting","Future Generation Computer Systems","","0167-739X","10.1016/j.future.2018.07.046","https://www.sciencedirect.com/science/article/pii/S0167739X18305703","From the past few years, there is an exponential increase in one of the most popular technologies of the modern era called as Internet of Things (IoT). In IoT, various objects perform the tasks of sensing, communication, and computation for providing uninterrupted services (e.g., e-health, e-transportation, security access, etc.) to the end users. In this era, Cognitive Internet of Things (CIoT) is an another paradigm of IoT developed to enhance the capabilities of intelligence in IoT objects where these objects can take independent decisions in any environment. IoT follows the service oriented architecture (SOA), in which the application layer is the topmost layer. It enables the IoT objects to interact with the other objects located across the globe. The power of learning, thinking, and understanding by these objects, can make the information access more accurate and reliable but Web spam is one of the challenges while accessing information from the web. It has been observed from the literature review that search engines are preferred mostly by the people for accessing information. The efficient ranking by the search engines can reduce the computational cost of information exchange by IoT objects. Search engines should be able to prevent the spam from being injected into the web. But, the existing techniques for this problem target in finding the spam after its occurrence in search engine result pages. So, in this proposal, we present an intelligent cognitive spammer framework, Cognitive spammer, which eliminates the spam pages during the web page rank score calculation by search engines. The framework update the Google’s ranking algorithm, PageRank in such a way that it automatically prevents link spam by considering the link structure of web for rank score computation. The updated PageRank algorithm provided the better ranking of web pages. The proposed framework is validated with the WEBSPAM-UK2007 dataset. Before processing, the dataset is preprocessed with a new technique, called as ‘Split by Over-sampling and Train by Under-fitting’ to remove the trade off between imbalanced instances of target class. After data cleaning, we applied machine learning techniques (Bagged model, Boosted linear model, etc) with the web page features to make accurate predictions. The detection classifiers only consider the link features of the web page irrespective of the page content. Out of the fifteen classifiers, best three are ensemble, which results in better performance with overall accuracy improvement. Ten-fold cross validation has also been applied with the resulted ensemble model, which results in getting the accuracy of 99.6% in the proposed scheme.","2019-01-01","2022-06-10 03:07:32","2022-07-31 02:36:25","","381-404","","","90","","Future Generation Computer Systems","","","","","","","","","","","","","","","","","","","Cognitive IoT; Internet of Things(IoT); PageRank; Web spam; ALGORITHMS; WEB; FEATURES; THINGS; IMAGES; INTERNET; COMPUTATION; OIL-SPILLS; RADIO; TRUST PROPAGATION","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FDSHSK5S","journalArticle","2022","Maharana, Kiran; Mondal, Surajit; Nemade, Bhushankumar","A review: Data pre-processing and data augmentation techniques","International Conference on Intelligent Engineering Approach(ICIEA-2022)","","2666-285X","10.1016/j.gltp.2022.04.020","https://www.sciencedirect.com/science/article/pii/S2666285X22000565","This review paper provides an overview of data pre-processing in Machine learning, focusing on all types of problems while building the machine learning problems. It deals with two significant issues in the pre-processing process (i). issues with data and (ii). Steps to follow to do data analysis with its best approach. As raw data are vulnerable to noise, corruption, missing, and inconsistent data, it is necessary to perform pre-processing steps, which is done using classification, clustering, and association and many other pre-processing techniques available. Poor data can primarily affect the accuracy and lead to false prediction, so it is necessary to improve the dataset's quality. So, data pre-processing is the best way to deal with such problems. It makes the knowledge extraction from the data set much easier with cleaning, Integration, transformation, and reduction methods. The issue with Data missing and significant differences in the variety of data always exists as the information is collected through multiple sources and from a real-world application. So, the data augmentation approach generates data for machine learning models. To decrease the dependency on training data and to improve the performance of the machine learning model. This paper discusses flipping, rotating with slight degrees and others to augment the image data and shows how to perform data augmentation methods without distorting the original data.","2022-06-01","2022-06-10 03:07:32","2022-07-31 01:33:26","","91-99","","1","3","","Global Transitions Proceedings","","","","","","","","","","","","","","","","","","","Data cleaning; Data augmentation; Data oversampling; Data pre-processing; Data wraping","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TN7ITCH4","journalArticle","2017","Hermans, K.; Waegeman, W.; Opsomer, G.; Van Ranst, B.; De Koster, J.; Van Eetvelde, M.; Hostens, M.","Novel approaches to assess the quality of fertility data stored in dairy herd management software","Journal of Dairy Science","","0022-0302","10.3168/jds.2016-11896","https://www.sciencedirect.com/science/article/pii/S0022030217301959","ABSTRACT Scientific journals and popular press magazines are littered with articles in which the authors use data from dairy herd management software. Almost none of such papers include data cleaning and data quality assessment in their study design despite this being a very critical step during data mining. This paper presents 2 novel data cleaning methods that permit identification of animals with good and bad data quality. The first method is a deterministic or rule-based data cleaning method. Reproduction and mutation or life-changing events such as birth and death were converted to a symbolic (alphabetical letter) representation and split into triplets (3-letter code). The triplets were manually labeled as physiologically correct, suspicious, or impossible. The deterministic data cleaning method was applied to assess the quality of data stored in dairy herd management from 26 farms enrolled in the herd health management program from the Faculty of Veterinary Medicine Ghent University, Belgium. In total, 150,443 triplets were created, 65.4% were labeled as correct, 17.4% as suspicious, and 17.2% as impossible. The second method, a probabilistic method, uses a machine learning algorithm (random forests) to predict the correctness of fertility and mutation events in an early stage of data cleaning. The prediction accuracy of the random forests algorithm was compared with a classical linear statistical method (penalized logistic regression), outperforming the latter substantially, with a superior receiver operating characteristic curve and a higher accuracy (89 vs. 72%). From those results, we conclude that the triplet method can be used to assess the quality of reproduction data stored in dairy herd management software and that a machine learning technique such as random forests is capable of predicting the correctness of fertility data.","2017-05-01","2022-06-10 03:07:32","2022-07-31 05:07:46","","4078-4089","","5","100","","Journal of Dairy Science","","","","","","","","","","","","","","","","","","","random forests; data quality; dairy herd management software; dairy reproduction; PREDICTION; CLASSIFICATION; SELECTION; FRAMEWORK; PERFORMANCE; WORKLOAD; TIME; DISEASE; RECORDING-SYSTEM; SECONDARY DATA SOURCES","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CA6MEIUI","journalArticle","2022","Shelke, Nilesh; Chaudhury, Sushovan; Chakrabarti, Sudakshina; Bangare, Sunil L.; Yogapriya, G.; Pandey, Pratibha","An efficient way of text-based emotion analysis from social media using LRA-DNN","Multimedia-based Emerging Technologies and Data Analytics for Neuroscience as a Service (NaaS)","","2772-5286","10.1016/j.neuri.2022.100048","https://www.sciencedirect.com/science/article/pii/S2772528622000103","Text devices are effectively and heavily used for interactions these days. Emotion extraction from the text has derived huge importance and is upcoming area of research in Natural Language Processing. Recognition of emotions from text has high practical utilities for quality improvement like in Human-Computer Interaction, recommendation systems, online education, data mining and so on. However, there are the issues of irrelevant feature extraction during emotion extraction from text. It causes mis-prediction of emotion. To overcome such challenges, this paper proposes a Leaky Relu activated Deep Neural Network (LRA-DNN). The proposed model comes under four categories, such as pre-processing, feature extraction, ranking and classification. The collected data from the dataset are pre-processed for data cleansing, appropriate features are extracted from the pre-processed data, relevant ranks are assigned for each extracted feature in the ranking phase and finally, the data are classified and accurate output is obtained from the classification phase. Publically available datasets are used in this research to compare the results obtained by the proposed LRA-DNN with the previous state-of-art algorithms. The outcomes indicated that the proposed LRA-DNN obtains the highest accuracy, sensitivity, and specificity at the rate of 94.77%, 92.23%, and 95.91% respectively which is promising compared to the existing ANN, DNN and CNN methods. It also efficiently reduces the mis-prediction and misclassification error.","2022-09-01","2022-06-10 03:07:32","2022-07-31 02:19:48","","100048","","3","2","","Neuroscience Informatics","","","","","","","","","","","","","","","","","","","Sentiment analysis; Deep neural network; Emotion analysis; Leaky Relu; Predictive analytic; Social media","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L24WP4PW","journalArticle","2020","Kong, Lingqiang; Liu, Zhifeng; Wu, Jianguo","A systematic review of big data-based urban sustainability research: State-of-the-science and future directions","Journal of Cleaner Production","","0959-6526","10.1016/j.jclepro.2020.123142","https://www.sciencedirect.com/science/article/pii/S0959652620331875","The future of humanity depends increasingly on the performance of cities. Big data provide new and powerful ways of studying and improving coupled urban environmental, social, and economic systems to achieve urban sustainability. However, the term big data has been defined variably, and its urban applications have so far been sporadic in terms of research topic and location. A comprehensive review of big data-based urban environment, society, and sustainability (UESS) research is much needed. The aim of this study was to summarize the big data-based UESS research using a systematic review approach in combination with bibliometric and thematic analyses. The results showed that the numbers of publications and citations of related articles have been increasing exponentially in recent years. The most frequently used big data in UESS research are human behavior data, and the major analytical methods are of five types: classification, clustering, regression, association rules, and social network analysis. The major research topics of big data-based UESS research include urban mobility, urban land use and planning, environmental sustainability, public health and safety, social equity, tourism, resources and energy utilization, real estate, and retail, accommodation and catering. Big data benefit UESS research by proving a people-oriented perspective, timely and real-time information, and fine-resolution spatial dynamics. In addition, several obstacles were identified to applying big data in UESS research, which are related to data quality and acquisition, data storage and management, data security and privacy, data cleaning and preprocessing, and data analysis and information mining. To move forward, future research should integrate multiple big data sources, develop and utilize new methods such as deep learning and cloud computing, and expand the application fields to focus on the interactions between human activities and urban environments. This review can contribute to understanding the current situation of big data-based UESS research, and provide a reference for studies of this topic in the future.","2020-11-10","2022-06-10 03:07:32","2022-07-31 01:44:11","","123142","","","273","","Journal of Cleaner Production","","","","","","","","","","","","","","","","","","http://dx.doi.org/10.1016/j.jclepro.2020.123142","Big data; Deep learning; Quality control; Digital storage; Information management; Security of data; Behavioral research; Energy utilization; Sustainable development; Smart city; Land use; Urban planning; Social media data; Urban landscape sustainability; Tourism; CHINA; AIR-QUALITY; COMMUTING PATTERNS; ECOSYSTEM SERVICES; GOOGLE STREET VIEW; LAND; MOBILITY INFORMATION; SMART CITY; SOCIAL-MEDIA DATA; TAXI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8T5X8MTZ","journalArticle","2022","Kumar, Sudhanshu; Singh, Thoudam Doren","Fake news detection on Hindi news dataset","International Conference on Intelligent Engineering Approach(ICIEA-2022)","","2666-285X","10.1016/j.gltp.2022.03.014","https://www.sciencedirect.com/science/article/pii/S2666285X2200019X","With the increase in social networks, more number of people are creating and sharing information than ever before, many of them have no relevance to reality. Due to this, fake news for various political and commercial purposes are spreading quickly. Online newspaper has made it challenging to identify trustworthy news sources. In this work, Hindi news articles from various news sources are collected. Preprocessing, feature extraction, classification and prediction processes are discussed in detail. Different machine learning algorithms such as Naïve Bayes, logistic regression and Long Short-Term Memory (LSTM) are used to detect the fake news. The preprocessing step includes data cleaning, stop words removal, tokenizing and stemming. Term frequency inverse document frequency(TF-IDF) is used for feature extraction. Naïve Bayes, logistic regression and LSTM classifiers are used and compared for fake news detection with probability of truth. It is observed that among these three classifiers, LSTM achieved best accuracy of 92.36%.","2022-06-01","2022-06-10 03:07:32","2022-07-31 13:45:58","","289-297","","1","3","","Global Transitions Proceedings","","","","","","","","","","","","","","","","","","","Logistic regression; LSTM; Naive Bayes; Fake news; Hindi news dataset; TF-IDF","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8BRXRHDG","journalArticle","2022","Neunzig, Christian; Fahle, Simon; Schulz, Jürgen; Möller, Matthias; Kuhlenkötter, Bernd","Model Selection for Predictive Quality in Hydraulic Testing","Leading manufacturing systems transformation – Proceedings of the 55th CIRP Conference on Manufacturing Systems 2022","","2212-8271","10.1016/j.procir.2022.04.052","https://www.sciencedirect.com/science/article/pii/S2212827122002682","Manufacturing companies are confronted with enormous challenges such as increasing product complexity, shorter product life cycles and growing product diversity. Politically and socially, increased demands regarding sustainability and resource consumption are streaming into the focus of companies. One solution strategy to increase the productivity of existing production systems while ensuring existing quality standards is the application of data-driven analytical methods such as machine learning. Due to the frequent changes in production conditions, the analysis of real manufacturing data is linked to sophisticated data pre-processing. Changes in production data are manifested in trends and systematic shifts over time. Data pre-processing includes rule-based data cleaning, the application of dimension reduction techniques and the identification of comparable data subsets. Within the used dataset of hydraulic valves by Bosch, the comparability of the same production conditions in the manufacturing of hydraulic valves can be identified within certain periods. Machine learning methods can process large amounts of data, unfavorable row-column ratios and discover dependencies between the input data and the specified target variable as well as evaluate the multidimensional influence of all input variables on the target variable. For use cases in manufacturing, neural networks, support vector machines and tree-based methods have so far proved to be very successful. The use of cross-process production data along the value chain of hydraulic valves is a promising approach to predict the quality characteristics of workpieces. Within this research, machine learning methods with deep and shallow structures are applied to predict the internal leakage of hydraulic valves based on geometric gauge blocks from machining, mating data from assembly and hydraulic measurement data from end-of-line testing. Moreover, the most suitable methods are selected, and accurate quality predictions are obtained.","2022-01-01","2022-06-10 03:07:32","2022-07-31 05:20:01","","320-325","","","107","","Procedia CIRP","","","","","","","","","","","","","","","","","","http://dx.doi.org/10.1016/j.procir.2022.04.052","Machine Learning; Supervised Learning; Hydraulic Testing; Predictive Quality","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GMA7ETD2","bookSection","2017","Witten, Ian H.; Frank, Eibe; Hall, Mark A.; Pal, Christopher J.","Chapter 8 - Data transformations","Data Mining (Fourth Edition)","978-0-12-804291-5","","","https://www.sciencedirect.com/science/article/pii/B9780128042915000088","Abstracts There are many transformations that can make real-world datasets more amenable to the learning algorithms discussed in the rest of the book. We first consider methods for attribute selection, which remove attributes that are not useful for the task at hand. Then we look at discretization methods: algorithms for turning numeric attributes into discrete ones. Next we discuss several techniques for projecting data into a space that is more suitable for learning: well-known methods for dimensionality reduction, including unsupervised approaches such as principal component analysis, independent component analysis, and random projections, as well as supervised approaches such as partial least squares regression and linear discriminant analysis. We consider how to turn textual data into numeric attribute vectors so that standard learning techniques can be applied, and present simple methods for approaching time series data. The last four sections deal with data sampling, data cleansing, generic approaches for multiclass classification, and calibration of class probabilities, respectively. Sampling is nontrivial when the data arrives as a stream, and we discuss the “reservoir” method for taking an unbiased sample in this case. Data cleansing can be performed by iteratively applying standard supervised learning algorithms to remove outliers, but there are also dedicated techniques for anomaly detection and so-called “one-class learning” that are applicable. For dealing with multiclass classification problems, we consider several ways of decomposing them into a set of two-class problems, e.g., by applying error-correcting output codes. Finally, we describe how to calibrate class probability estimates to improve their accuracy.","2017-01-01","2022-06-10 03:07:32","2022-07-31 14:39:25","","285-334","","","","","","","","","","","Morgan Kaufmann","","","","","","","","","DOI: 10.1016/B978-0-12-804291-5.00008-8","","","","dimensionality reduction; data cleansing; attribute selection; class probability calibration; data sampling; Data transformations; multiclass classification; vector space model","","Witten, Ian H.; Frank, Eibe; Hall, Mark A.; Pal, Christopher J.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N7BUMGE9","journalArticle","2020","Brown, Vanessa M.; Chen, Jiazhou; Gillan, Claire M.; Price, Rebecca B.","Improving the Reliability of Computational Analyses: Model-Based Planning and Its Relationship With Compulsivity","Biological Psychiatry: Cognitive Neuroscience and Neuroimaging","","2451-9022","10.1016/j.bpsc.2019.12.019","https://www.sciencedirect.com/science/article/pii/S2451902220300161","Background Computational models show great promise in mapping latent decision-making processes onto dissociable neural substrates and clinical phenotypes. One prominent example in reinforcement learning is model-based planning, which specifically relates to transdiagnostic compulsivity. However, the reliability of computational model-derived measures such as model-based planning is unclear. Establishing reliability is necessary to ensure that such models measure stable, traitlike processes, as assumed in computational psychiatry. Although analysis approaches affect validity of reinforcement learning models and reliability of other task-based measures, their effect on reliability of reinforcement learning models of empirical data has not been systematically studied. Methods We first assessed within- and across-session reliability and effects of analysis approaches (model estimation, parameterization, and data cleaning) of measures of model-based planning in patients with compulsive disorders (n = 38). The analysis approaches affecting test-retest reliability were tested in 3 large generalization samples (healthy participants: n = 541 and 111; people with a range of compulsivity: n = 1413). Results Analysis approaches greatly influenced reliability: reliability of model-based planning measures ranged from 0 (no concordance) to above 0.9 (acceptable for clinical applications). The largest influence on reliability was whether model-estimation approaches were robust and accounted for the hierarchical structure of estimated parameters. Improvements in reliability generalized to other datasets and greatly reduced the sample size needed to find a relationship between model-based planning and compulsivity in an independent dataset. Conclusions These results indicate that computational psychiatry measures such as model-based planning can reliably measure latent decision-making processes, but when doing so must assess the ability of methods to estimate complex models from limited data.","2020-06-01","2022-06-10 03:07:32","2022-07-31 05:56:49","","601-609","","6","5","","Biological Psychiatry: Cognitive Neuroscience and Neuroimaging","","","","","","","","","","","","","","","","","","","Reinforcement learning; Reliability; Computational modeling; Compulsivity; Computational psychiatry; Psychometrics; PREDICTION; SYSTEMS; ERROR; TRACKING; DECISION-MAKING; PROTECTS; REWARD","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JX6JLML3","journalArticle","2021","Twumasi, Clement; Twumasi, Juliet","Machine learning algorithms for forecasting and backcasting blood demand data with missing values and outliers: A study of Tema General Hospital of Ghana","International Journal of Forecasting","","0169-2070","10.1016/j.ijforecast.2021.10.008","https://www.sciencedirect.com/science/article/pii/S0169207021001710","The major challenge in managing blood products lies in the uncertainty of blood demand and supply, with a trade-off between shortage and wastage, especially in most developing countries. Thus, reliable demand predictions can be imperative in planning voluntary blood donation campaigns and improving blood availability within Ghana hospitals. However, most historical datasets on blood demand in Ghana are predominantly contaminated with missing values and outliers due to improper database management systems. Consequently, time-series prediction can be challenging since data cleaning can affect models’ predictive power. Also, machine learning (ML) models’ predictive power for backcasting past years’ lost data is understudied compared to their forecasting abilities. This study thus aims to compare K-Nearest Neighbour regression (KNN), Generalised Regression Neural Network (GRNN), Neural Network Auto-regressive (NNAR), Multi-Layer Perceptron (MLP), Extreme Learning Machine (ELM) and Long Short-Term Memory (LSTM) models via a rolling-origin strategy, for forecasting and backcasting a blood demand data with missing values and outliers from a government hospital in Ghana. KNN performed well in forecasting blood demand (12.55% error); whereas, ELM achieved the highest backcasting power (19.36% error). Future studies can also employ ML algorithms as a good alternative for backcasting past values of time-series data that are time-reversible.","2021-12-31","2022-06-10 03:07:32","2022-07-31 05:33:31","","","","","","","International Journal of Forecasting","","","","","","","","","","","","","","","","","","","Machine learning; Neural networks; Forecasting; Imputation; Kalman smoothing; Backcasting; Blood demand; Blood supply; Time-reversibility; PREDICTION; PERFORMANCE; NEURAL-NETWORKS; TIME-SERIES; INVENTORY MANAGEMENT; MODELS; STRATEGIES; SUPPLY CHAIN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BPADZJRD","journalArticle","2022","Fitton, D.; Laurens, E.; Hongkarnjanakul, N.; Schwob, C.; Mezeix, L.","Land cover classification through Convolutional Neur-al Network model assembly: A case study of a local rural area in Thailand","Remote Sensing Applications: Society and Environment","","2352-9385","10.1016/j.rsase.2022.100740","https://www.sciencedirect.com/science/article/pii/S2352938522000489","Recent Convolutional Neural Network (CNN) has shown great potential in image classification, segmentation and object detection. Land cover takes advantage of CNN development for a large type of applications as water management and urban growing. However, to perform a land cover with numerous features – classes in classical CNN terminology, CNN models require a significant number of layers and neurons, resulting in high computational costs. To address this problem, a methodology is proposed in this paper to build a land cover using the aggregation of several CNN models. The overall process is based on 7 steps. The first two steps are the dataset creation and arrangement in smaller dataset fit for the specific features to detect. Then, a CNN architecture is built and validated on each sub-dataset corresponding to each class. Post-processing is conducted on each prediction before assembling the results. In the last step, a data cleaning is performed, giving the final land cover. The land cover of a rural area in Thailand is performed as a demonstration of the method, using satellite images with a resolution of 0.15 m/pixel. A 5-class (buildings, crops, forests, roads, and wastelands) dataset is created, consisting of a total of 1 million tiles of 64 × 64 pixels. The prediction results using the developed CNN model show an accuracy greater than 90% for each class, except for the road class where the accuracy only reaches 72%. Post-processing is performed on each of the 5 predictions. Only the 4 best results are retained and assembled to obtain the land cover, which generally corresponds to buildings, crops, forests, and wastelands. This method enables to identify by substitution with improved accuracy the last class whose prediction is the least accurate, and which generally corresponds to roads due to their small width relative to the tile size. The proposed methodology to perform a land cover by aggregating the prediction of different CNN models is found to predict correctly the land cover of two areas, especially roads can be classified, demonstrating the usefulness of the approach.","2022-04-01","2022-06-10 03:07:33","2022-07-31 05:44:21","","100740","","","26","","Remote Sensing Applications: Society and Environment","","","","","","","","","","","","","","","","","","","Artificial intelligence; Image processing; Convolutional neural network; Land cover; Satellite image; LOP BURI PROVINCE","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9B5Q6YEL","journalArticle","2017","Soliman, Abu Bakr; Eissa, Kareem; El-Beltagy, Samhaa R.","AraVec: A set of Arabic Word Embedding Models for use in Arabic NLP","Arabic Computational Linguistics","","1877-0509","10.1016/j.procs.2017.10.117","https://www.sciencedirect.com/science/article/pii/S1877050917321749","Advancements in neural networks have led to developments in fields like computer vision, speech recognition and natural language processing (NLP). One of the most influential recent developments in NLP is the use of word embeddings, where words are represented as vectors in a continuous space, capturing many syntactic and semantic relations among them. AraVec is a pre-trained distributed word representation (word embedding) open source project which aims to provide the Arabic NLP research community with free to use and powerful word embedding models. The first version of AraVec provides six different word embedding models built on top of three different Arabic content domains; Tweets, World Wide Web pages and Wikipedia Arabic articles. The total number of tokens used to build the models amounts to more than 3,300,000,000. This paper describes the resources used for building the models, the employed data cleaning techniques, the carried out preprocessing step, as well as the details of the employed word embedding creation techniques.","2017-01-01","2022-06-10 03:07:33","2022-07-31 15:39:52","","256-265","","","117","","Procedia Computer Science","","","","","","","","","","","","","","","","","","","NLP; Word2Vec; Arabic; Word Embeddings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A5XY5M2I","journalArticle","2019","Corizzo, Roberto; Ceci, Michelangelo; Japkowicz, Nathalie","Anomaly Detection and Repair for Accurate Predictions in Geo-distributed Big Data","Big Data Research","","2214-5796","10.1016/j.bdr.2019.04.001","https://www.sciencedirect.com/science/article/pii/S2214579618302119","The increasing presence of geo-distributed sensor networks implies the generation of huge volumes of data from multiple geographical locations at an increasing rate. This raises important issues which become more challenging when the final goal is that of the analysis of the data for forecasting purposes or, more generally, for predictive tasks. This paper proposes a framework which supports predictive modeling tasks from streaming data coming from multiple geo-referenced sensors. In particular, we propose a distance-based anomaly detection strategy which considers objects described by embedding features learned via a stacked auto-encoder. We then devise a repair strategy which repairs the data detected as anomalous exploiting non-anomalous data measured by sensors in nearby spatial locations. Subsequently, we adopt Gradient Boosted Trees (GBTs) to predict/forecast values assumed by a target variable of interest for the repaired newly arriving (unlabeled) data, using the original feature representation or the embedding feature representation learned via the stacked auto-encoder. The workflow is implemented with distributed Apache Spark programming primitives and tested on a cluster environment. We perform experiments to assess the performance of each module, separately and in a combined manner, considering the predictive modeling of one-day-ahead energy production, for multiple renewable energy sites. Accuracy results show that the proposed framework allows reducing the error up to 13.56%. Moreover, scalability results demonstrate the efficiency of the proposed framework in terms of speedup, scaleup and execution time under a stress test.","2019-07-01","2022-06-10 03:07:51","2022-07-31 02:32:28","","18-35","","","16","","Big Data Research","","","","","","","","","","","","","","","","","","","Anomaly detection; Neural networks; Data repair; Geo-distributed big data; Gradient-boosting; Spatial autocorrelation; POWER","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZK48M3IF","journalArticle","2019","Moeyersons, Jonathan; Smets, Elena; Morales, John; Villa, Amalia; De Raedt, Walter; Testelmans, Dries; Buyse, Bertien; Van Hoof, Chris; Willems, Rik; Van Huffel, Sabine; Varon, Carolina","Artefact detection and quality assessment of ambulatory ECG signals","Computer Methods and Programs in Biomedicine","","0169-2607","10.1016/j.cmpb.2019.105050","https://www.sciencedirect.com/science/article/pii/S0169260719312817","Background and Objectives The presence of noise sources could reduce the diagnostic capability of the ECG signal and result in inappropriate treatment decisions. To mitigate this problem, automated algorithms to detect artefacts and quantify the quality of the recorded signal are needed. In this study we present an automated method for the detection of artefacts and quantification of the signal quality. The suggested methodology extracts descriptive features from the autocorrelation function and feeds these to a RUSBoost classifier. The posterior probability of the clean class is used to create a continuous signal quality assessment index. Firstly, the robustness of the proposed algorithm is investigated and secondly, the novel signal quality assessment index is evaluated. Methods Data were used from three different studies: a Sleep study, the PhysioNet 2017 Challenge and a Stress study. Binary labels, clean or contaminated, were available from different annotators with experience in ECG analysis. Two types of realistic ECG noise from the MIT-BIH Noise Stress Test Database (NSTDB) were added to the Sleep study to test the quality index. Firstly, the model was trained on the Sleep dataset and subsequently tested on a subset of the other two datasets. Secondly, all recording conditions were taken into account by training the model on a subset derived from the three datasets. Lastly, the posterior probabilities of the model for the different levels of agreement between the annotators were compared. Results AUC values between 0.988 and 1.000 were obtained when training the model on the Sleep dataset. These results were further improved when training on the three datasets and thus taking all recording conditions into account. A Pearson correlation coefficient of 0.8131 was observed between the score of the clean class and the level of agreement. Additionally, significant quality decreases per noise level for both types of added noise were observed. Conclusions The main novelty of this study is the new approach to ECG signal quality assessment based on the posterior clean class probability of the classifier.","2019-12-01","2022-06-10 03:08:02","2022-07-31 15:24:15","","105050","","","182","","Computer Methods and Programs in Biomedicine","","","","","","","","","","","","","","","","","","","ECG; Quality assessment; Ambulatory monitoring; Artefacts","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7R83PK58","journalArticle","2022","Khan, Zulfiqar Ahmad; Ullah, Amin; Ul Haq, Ijaz; Hamdy, Mohamed; Maria Maurod, Gerardo; Muhammad, Khan; Hijji, Mohammad; Baik, Sung Wook","Efficient Short-Term Electricity Load Forecasting for Effective Energy Management","Sustainable Energy Technologies and Assessments","","22131388","10.1016/j.seta.2022.102337","","Short-term electrical energy load forecasting is one of the most significant problems associated with energy management for smart grids, which aims to optimize the operational strategies of buildings. Electricity forecasting models are considered a key aspect of the provision of better electricity management and reductions in energy consumption. This motivates the researchers to develop efficient electricity load forecasting (ELF) models, based on historical nonlinear and high volatile data, which require appropriate forecasting strategies. Therefore, in this article, we present an innovative two-phase framework for short-term ELF. The first phase is dedicated to data cleansing, in which pre-processing strategies are applied to raw data. In the second phase, a deep residual Convolutional Neural Network (CNN) is designed to extract the important features from the refined data. To the best of our knowledge, this is the first work to introduce a deep CNN architecture for the extraction of spatial features from electricity data. The output of the residual CNN network is forwarded to a stacked Long Short-Term Memory (LSTM) network to learn the temporal information of the electricity data. The proposed model is then evaluated using the Individual-Household-Electric-Power-Consumption (IHEPC) and PennsylvaniaNew JerseyMaryland (PJM) datasets. The results reveal a significant reduction in the error rate over the IHEPC dataset in terms of Mean-Absolute-Error (MAE) (15.65%), Mean-Square-Error (MSE) (8.77%), and Root-Mean-Square-Error (RMSE) (14.85%) and over the PJM dataset our method reduced RMSE up to 3.4% as compared to baseline models i.e., linear regression, LSTM, and Gated Recurrent Unit (GRU). Furthermore, we performed several experiments with CNN, LSTM, and GRU models and evaluated it with additional Coefficient of Variation of the RMSE (CV-RMSE) metrics, which proves the effectiveness of our model for short-term load forecasting.  2022 Elsevier Ltd","2022","2022-07-27 17:24:45","2022-07-31 14:02:46","","","","","53","","Sustainable Energy Technologies and Assessments","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.seta.2022.102337","Brain; Long short-term memory; Electric power transmission networks; Errors; Data mining; Convolution; Mean square error; Electric power utilization; Energy efficiency; Smart power grids; Electric utilities; Electric power plant loads; Electric load forecasting; Smart grids; Convolutional neural network; Building electricity consumption; Building energy simulation; CNN-LSTM; Electricity load forecasting; Residual CNN","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QQDPWQ7U","journalArticle","2022","Uher, Vojtch; Dradilova, Pavla; Plato, Jan; Badura, Petr","Automation of cleaning and ensembles for outliers detection in questionnaire data","Expert Systems with Applications","","09574174","10.1016/j.eswa.2022.117809","","This article is focused on the automatic detection of the corrupted or inappropriate responses in questionnaire data using unsupervised outliers detection. The questionnaire surveys are often used in psychology research to collect self-report data and their preprocessing takes a lot of manual effort. Unlike with numerical data where the distance-based outliers prevail, the records in questionnaires have to be assessed from various perspectives that do not relate so much. We identify the most frequent types of errors in questionnaires. For each of them, we suggest different outliers detection methods ranking the records with the usage of normalized scores. Considering the similarity between pairs of outlier scores (some are highly uncorrelated), we propose an ensemble based on the union of outliers detected by different methods. Our outlier detection framework consists of some well-known algorithms but we also propose novel approaches addressing the typical issues of questionnaires. The selected methods are based on distance, entropy, and probability. The experimental section describes the process of assembling the methods and selecting their parameters for the final model detecting significant outliers in the real-world HBSC dataset.  2022 The Author(s)","2022","2022-07-27 17:24:46","2022-07-31 14:48:16","","","","","206","","Expert Systems with Applications","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.eswa.2022.117809","Anomaly detection; Surveys; Statistics; Data cleaning; Outliers; HBSC; Questionnaire data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K2WCNRX9","journalArticle","2022","Baduge, Shanaka Kristombu; Thilakarathna, Sadeep; Perera, Jude Shalitha; Arashpour, Mehrdad; Sharafi, Pejman; Teodosio, Bertrand; Shringi, Amkit; Mendis, Priyan","Artificial intelligence and smart vision for building and construction 4.0: Machine and deep learning methods and applications","Automation in Construction","","09265805","10.1016/j.autcon.2022.104440","","This article presents a state-of-the-art review of the applications of Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) in building and construction industry 4.0 in the facets of architectural design and visualization; material design and optimization; structural design and analysis; offsite manufacturing and automation; construction management, progress monitoring, and safety; smart operation, building management and health monitoring; and durability, life cycle analysis, and circular economy. This paper presents a unique perspective on applications of AI/DL/ML in these domains for the complete building lifecycle, from conceptual stage, design stage, construction stage, operational and maintenance stage until the end of life. Furthermore, data collection strategies using smart vision and sensors, data cleaning methods (post-processing), data storage for developing these models are discussed, and the challenges in model development and strategies to overcome these challenges are elaborated. Future trends in these domains and possible research avenues are also presented.  2022 The Authors","2022","2022-07-27 17:24:53","2022-07-31 15:39:42","","","","","141","","Automation in Construction","","","","","","","","","","","","","","","Publisher: Elsevier B.V.","","","http://dx.doi.org/10.1016/j.autcon.2022.104440","Generative adversarial networks; Data handling; Deep learning; Machine learning; Automation; Learning systems; Artificial intelligence; Internet of things; Deep neural networks; Digital storage; Data acquisition; Life cycle; Accident prevention; Structural optimization; Architectural design; Construction; Construction industry; Structural design; SUPPORT VECTOR MACHINE; COMPRESSIVE STRENGTH; ELASTIC-MODULUS; HIGH-STRENGTH CONCRETE; 3D ASPHALT SURFACES; Artificial neural network; Building information modelling; Convolution neural network; DAMAGE DETECTION; Generative adversarial network; LOAD PREDICTION; NEURAL-NETWORK PREDICTION; PAVEMENT CRACK DETECTION; Smart vision; TENSILE-STRENGTH","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"47A24TPN","journalArticle","2022","Zhang, Dongliang; Li, Mingchao; Tian, Dan; Song, Lingguang; Shen, Yang","Intelligent text recognition based on multi-feature channels network for construction quality control","Advanced Engineering Informatics","","14740346","10.1016/j.aei.2022.101669","","Construction quality control is achieved primarily through various testing and inspections and subsequent analysis of the massive unstructured quality records. The quality professionals are required to classify and review the inspection texts according to the project category. However, manual processing of a sheer amount of textual data is not only time-consuming, laborious but also error-prone, which could lead to overlooked quality issues and harm the overall project performance. In response, this paper uses the text mining method to mine the hidden information from unstructured text records. First, obtain quality text records on-site, use data cleaning method to obtain 9859 clean data, then use both Bidirectional Encoder Representation from Transformers (BERT) pre-training and Word2vec methods to quantify the text into a digital representation, next improve the Convolutional Neural Network (CNN) model by expanding input channels, and input the quantified text into the model to extract key features to realize the integration of quality records according to established categories. The results show that the average precision of the proposed model is 89.69%. Compared with CNN, BERT, and other models, this model has less manual intervention, less time-consuming training, and higher precision. Finally, through data augmentation of small sample data, the precision of the model is further improved, reaching 92.02%. The proposed model can assist quality professionals to quickly spot key quality issues and reference corresponding quality standards for further actions, and allow them to focus on more value-added efforts, e.g., making decisions and planning for corrective actions. This research also provides a reference for the ultimate goal of constructing an intelligent project management system.  2022 Elsevier Ltd","2022","2022-07-27 17:24:58","2022-07-31 05:49:50","","","","","53","","Advanced Engineering Informatics","","","","","","","","","","","","","","","Publisher: Elsevier Ltd","","","http://dx.doi.org/10.1016/j.aei.2022.101669","Deep learning; Quality control; Information management; Natural language processing systems; Data mining; Convolutional neural networks; Quality assurance; Natural language processing; Text processing; Text mining; Character recognition; Neural network models; Project management; CLASSIFICATION; MODEL; CONVOLUTIONAL NEURAL-NETWORK; BIG DATA; Auxiliary management; Construction quality control","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6YP5FW37","journalArticle","2022","Nagpal, Sunil; Pinna, Nishal Kumar; Pant, Namrata; Singh, Rohan; Srivastava, Divyanshu; Mande, Sharmila S.","Can machines learn the mutation signatures of SARS-CoV-2 and enable viral-genotype guided predictive prognosis?","Artificial Intelligence, Machine Learning and the Changing Landscape of Molecular Biology","","0022-2836","10.1016/j.jmb.2022.167684","https://www.sciencedirect.com/science/article/pii/S0022283622002765","Motivation Continuous emergence of new variants through appearance/accumulation/disappearance of mutations is a hallmark of many viral diseases. SARS-CoV-2 variants have particularly exerted tremendous pressure on global healthcare system owing to their life threatening and debilitating implications. The sheer plurality of variants and huge scale of genomic data have added to the challenges of tracing the mutations/variants and their relationship to infection severity (if any). Results We explored the suitability of virus-genotype guided machine-learning in infection prognosis and identification of features/mutations-of-interest. Total 199,519 outcome-traced genomes, representing 45,625 nucleotide-mutations, were employed. Among these, post data-cleaning, Low and High severity genomes were classified using an integrated model (employing virus genotype, epitopic-influence and patient-age) with consistently high ROC-AUC (Asia:0.97 ± 0.01, Europe:0.94 ± 0.01, N.America:0.92 ± 0.02, Africa:0.94 ± 0.07, S.America:0.93 ± 03). Although virus-genotype alone could enable high predictivity (0.97 ± 0.01, 0.89 ± 0.02, 0.86 ± 0.04, 0.95 ± 0.06, 0.9 ± 0.04), the performance was not found to be consistent and the models for a few geographies displayed significant improvement in predictivity when the influence of age and/or epitope was incorporated with virus-genotype (Wilcoxon p_BH < 0.05). Neither age or epitopic-influence or clade information could out-perform the integrated features. A sparse model (6 features), developed using patient-age and epitopic-influence of the mutations, performed reasonably well (>0.87 ± 0.03, 0.91 ± 0.01, 0.87 ± 0.03, 0.84 ± 0.08, 0.89 ± 0.05). High-performance models were employed for inferring the important mutations-of-interest using Shapley Additive exPlanations (SHAP). The changes in HLA interactions of the mutated epitopes of reference SARS-CoV-2 were then subsequently probed. Notably, we also describe the significance of a ‘temporal-modeling approach’ to benchmark the models linked with continuously evolving pathogens. We conclude that while machine learning can play a vital role in identifying relevant mutations and factors driving the severity, caution should be exercised in using the genotypic signatures for predictive prognosis.","2022-08-15","2022-07-27 17:47:44","2022-07-27 17:47:44","","167684","","15","434","","Journal of Molecular Biology","","","","","","","","","","","","","","","","","","","Machine learning; Mutation identification; Predictive prognosis; SARS-CoV-2; Temporal benchmarking","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AYFLMBBE","journalArticle","2022","Rana, Mashud; Sethuvenkatraman, Subbu; Heidari, Rahmat; Hands, Stuart","Solar thermal generation forecast via deep learning and application to buildings cooling system control","Renewable Energy","","0960-1481","10.1016/j.renene.2022.07.005","https://www.sciencedirect.com/science/article/pii/S0960148122010011","Reliable prediction of solar thermal power is essential for optimal operation and control of renewable energy driven distributed power systems. This paper presents a Convolutional Neural Networks (CNNs) based multivariate approach for forecasting power generation from solar thermal collectors over multiple horizons simultaneously. It also demonstrates an application of solar thermal power generation forecasting in a building cooling system as part of a predictive central controller. Historical data from an evacuated collector field and a single axis tracking collector field have been used to develop the prediction models and assess the performance of the proposed approach. Experimental results show that the proposed approach provides accurate prediction for multiple forecast horizons: MAPE is 2.99%–4.18% for 30 min to 24 h ahead prediction. The proposed approach utilising both historical and predicted future weather data achieves 25%–37% improvements of accuracy compared to its univariate counterpart that uses only lagged power data as input. It also outperforms existing data driven approaches based on NNs, LSTM, and RF, and achieves 5.46%–21.28% statistically significant improvements compared to them.","2022-08-01","2022-07-27 17:47:46","2022-07-31 15:14:55","","694-706","","","196","","Renewable Energy","","","","","","","","","","","","","","","","","","","Deep learning; Convolutional neural networks; Multivariate models; Solar cooling; Solar thermal power; Time series prediction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZPL6Z9H6","journalArticle","2022","Chen, Lei; Yan, Hexiang; Yan, Jieru; Wang, Jiaying; Tao, Tao; Xin, Kunlun; Li, Shuping; Pu, Zhengheng; Qiu, Jian","Short-term water demand forecast based on automatic feature extraction by one-dimensional convolution","Journal of Hydrology","","0022-1694","10.1016/j.jhydrol.2022.127440","https://www.sciencedirect.com/science/article/pii/S0022169422000154","Short-term water demand forecast is one of the most important technology for urban water supply management. The accuracy and timeliness of the forecast have an important impact. Most of the reported water demand forecast models based on deep learning methods apply a manual features extraction strategy, resulting in incomplete mining of the data and weak model self-adaptability capability. To address these issues, a new framework of short-term water demand forecast is proposed, in which a data preprocessing approach, S-H-ESD (Seasonal Hybrid Extreme Student Deviate), and a forecasting model, Conv1D-GRU (one-dimensional convolution-gated recurrent unit) are mainly developed. Based on the historical monitoring data, different hyper-parameter settings and training strategies were carried out with the proposed models. The results show that the data preprocessing model S-H-ESD can effectively deal with a variety of abnormal values, therefore significantly improving the accuracy of forecast (When the training dataset length is 7 days, the average accuracy of the three models is improved by1.23% when using S-H-ESD method compared with Z-Score method) and the Conv1D-GRU model shows better capability in forecast accuracy and self-adaptability of data features extraction compared with other models in literature (GRUN, ANN). With the achieving optimal parameter setting and training strategy, the developed methodology shows the best forecasted value of MAPE and NSE indicator are 1.677%, 0.983, respectively.","2022-03-01","2022-06-10 03:07:31","2022-07-31 04:20:59","","127440","","","606","","Journal of Hydrology","","","","","","","","","","","","","","","","","","","Deep learning; Gated recurrent unit; Automatic feature extraction; One-dimensional convolution; Water demand forecast; Water distribution system","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BG7JXHV2","journalArticle","2022","Wongchai, Anupong; Shukla, Surendra Kumar; Ahmed, Mohammed Altaf; Sakthi, Ulaganathan; Jagdish, Mukta; kumar, Ravi","Artificial intelligence - enabled soft sensor and internet of things for sustainable agriculture using ensemble deep learning architecture","Computers and Electrical Engineering","","0045-7906","10.1016/j.compeleceng.2022.108128","https://www.sciencedirect.com/science/article/pii/S0045790622003780","IoT (Internet of things) and Artificial Intelligence (AI), as well as other advanced computing technologies, have long been used in agriculture.AI-enabled sensors function as smart sensors and IoT has made various types of sensor-based equipment in the field of agriculture. This research proposes novel techniques in AI technique based soft sensor integrated with remote sensing model using deep learning architectures. The input has been pre-processed to recognize the missing value, data cleaning and noise removal from the image which is collected from the agricultural land. The feature representation has been carried out usingweight-optimized neural network with maximum likelihood (WONN_ML). after representing the features, classification process has been carried out using ensemble architecture of stacked auto-encoder and kernel-based convolution network (SAE_KCN). The experimental results have been done for various crops in terms of computational time of 56%, accuracy 98%, precision of 85.5%, recall of 89.9% and F-1 score of 86% by proposed technique.","2022-09-01","2022-07-27 17:47:48","2022-07-31 15:24:07","","108128","","","102","","Computers and Electrical Engineering","","","","","","","","","","","","","","","","","","","Deep learning; Agriculture; Predictive maintenance; Classification; Soft sensors; CPS; Feature representation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
