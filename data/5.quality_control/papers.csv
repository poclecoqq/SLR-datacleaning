,Name,Author's affiliation,venue name,Item Type,Publication Year,Subject category,Data type,task,Abstract Note,Author,Assignee,Relevant,DOI,Compared approaches,Dataset,Error type,Limitations and shortcomings,Model,"Performance (ML-wise e.g. accuracy, etc.)","Performance (engineering-wise e.g. time, memory, etc.)",Quality measurements,In SLR,Key,Personal comments,Q1,Q1.1,Q1.2,Q1.3,Q1.4,Q1.5,Q1.6,Q1.7,Q2,Q2.1,Q2.2,Replication package link,from
0,Automated Detection of Label Errors in Semantic Segmentation Datasets via Deep Learning and Uncertainty Quantification,Academia,IEEE/CVF Winter Conference on Applications of Computer Vision,journalArticle,2022,ML4DC,img,mislabel correction,"… labels at its boundary, which makes label error detection on pixel level a complex task. For … We study the performance of our label error detection method on synthetic image data from …","Rottmann, M; Reese, M",PO,YES,,-,(1) CARLA + a bit of noise because CARLA is a simulator and it is not realistic to have 0 label error in training set (2) CityScape,-,-,"Deeplabv3+ [4] architecture with a WideResNet38 [40]
backbone, and Nvidia’s multi-scale attention approach [36]
in combination with an HRNet-OCR trunk",around 60 F1-Score on Cityscape dataset,-,"tp, fn, fp, prec, recall, f1",,WPBQEEIM,they simply used an uncertainty measure (a previous work) to send labels to be reviewed,0,,,,,,,,0,,,-,
1,READ: Aggregating Reconstruction Error into Out-of-distribution Detection,Academia,AAAI,journalArticle,2022,,,outliers detection,"Detecting out-of-distribution (OOD) samples is crucial to the safe deployment of a classifier in the real world. However, deep neural networks are known to be overconfident for abnormal data. Existing works directly design score function by mining the inconsistency from classifier for in-distribution (ID) and OOD. In this paper, we further complement this inconsistency with reconstruction error, based on the assumption that an autoencoder trained on ID data can not reconstruct OOD as well as ID. We propose a novel method, READ (Reconstruction Error Aggregated Detector), to unify inconsistencies from classifier and autoencoder. Specifically, the reconstruction error of raw pixels is transformed to latent space of classifier. We show that the transformed reconstruction error bridges the semantic gap and inherits detection performance from the original. Moreover, we propose an adjustment strategy to alleviate the overconfidence problem of autoencoder according to a fine-grained characterization of OOD data. Under two scenarios of pre-training and retraining, we respectively present two variants of our method, namely READ-MD (Mahalanobis Distance) only based on pre-trained classifier and READ-ED (Euclidean Distance) which retrains the classifier. Our methods do not require access to test time OOD data for fine-tuning hyperparameters. Finally, we demonstrate the effectiveness of the proposed methods through extensive comparisons with state-of-the-art OOD detection algorithms. On a CIFAR-10 pre-trained WideResNet, our method reduces the average FPR@95TPR by up to 9.8% compared with previous state-of-the-art.  2022, CC BY-NC-ND.","Jiang, Wenyu; Cheng, Hao; Chen, Mingcai; Feng, Shuai; Ge, Yuxin; Wang, Chongjun",PO,YES,10.48550/arXiv.2206.07459,G-ODIN-I / G-ODIN-C / G-ODIN-E,(1) SVHN (2) LSUN (3) Textures (4) Places365 (5) CIFAR-100 (6) TIN (7) LSUN (8) TIN (9) iSUN,-,-,NN and autoencoder,better,-,(1) AUROC (2) FPR@95TPR,,P78F43QV,-,12,2.0,2.0,1.0,2.0,1.0,2.0,2.0,2,0.0,2.0,https://github.com/lygjwy/READ,
2,Annotation Error Detection: Analyzing the Past and Present for a More Coherent Future,Academia,Computational Linguistics,journalArticle,2022,"DC4ML, ML4DC",text,mislabel correction,"… Therefore, many automatic methods for annotation error detection (AED) have been devised over the years. These methods enable dataset creators and machine learning practitioners …","Klie, JC; Webber, B; Gurevych, I",,YES,"https://doi.org/10.48550/arXiv.2206.02280
10.1162/coli_a_00464","1. Variation-based (Variation n-grams, Label Entropy and Weighted Discrepancy)
2. Model-based (Re-tagging, ..)
3. Training Dynamics
4. Vector Space Proximity 
5. Ensembling
6. Rule-based","1. ATIS contains transcripts of user interactions with travel inquiry systems, annotated with intents and slots.
2. IMDb contains movie reviews labeled with sentiment.
3. SST The STANFORD SENTIMENT TREEBANK is a dataset for sentiment analysis of movie reviews from Rotten Tomatoes
4. GUM The GEORGETOWN UNIVERSITY MULTILAYER CORPUS is an open source corpus annotated with several layers from the Universal Dependencies project
5. Plank POS contains Twitter posts
6. CoNLL-2003
7. Slot Inconsistencies contains documents of three domains (COMPANIES, FOREX, FLIGHTS) that were annotated via crowdsourcing","Annotation Error 
Inconsistencies","Artificial errors (used clean datasets and injected random noise) which can lead to overestimate the ability of the detector.

Focuses on errors, inconsistencies, and ambiguities related to
instance labels, but not errors concerning tokenization, sentence splitting, or missing entities.",-,"The methods that worked best overall across tasks and datasets are Borda Count (BC), Diverse Ensemble (DE), Label Aggregation (LA), and Retag (RE).

Inconsistencies seems to be more difficult to detect for most methods, especially for model-based ones.",,"for Flagger tasks (binary classification): F1, precision, recall and percentage of flagged instances
for Scorers (liklihood or ranking): AP, precision@10% and recall @10% (Precision and recall at
10% evaluate a scenario in which a scorer was applied and the first 10% with the highest score—most likely to be incorrectly annotated—are manually corrected)",,P6D23SBS,This is more as empirical study rather than proposing new approach for cleaning data. They re-implement 18 methods for detecting potential annotation errors and evaluate them on 9 English datasets for text classification as well as token and span labeling,12,2.0,2.0,2.0,2.0,2.0,1.0,1.0,2,1.0,1.0,https://github.com/UKPLab/nessie,
3,Complaint-Driven Training Data Debugging at Interactive Speeds,Academia,ACM SIGMOD,conferencePaper,2022,ML4DC,tabular,mislabel correction,"Modern databases support queries that perform model inference (inference queries). Although powerful and widely used, inference queries are susceptible to incorrect results if the model is biased due to training data errors. Recently, prior work Rain proposed complaint-driven data debugging which uses user-specified errors in the output of inference queries (Complaints) to rank erroneous training examples that most likely caused the complaint. This can help users better interpret results and debug training sets. Rain combined influence analysis from the ML literature with relaxed query provenance polynomials from the DB literature to approximate the derivative of complaints w.r.t. training examples. Although effective, the runtime is O(|T|d), where T and d are the training set and model sizes, due to its reliance on the model's second order derivatives (the Hessian). On a Wide Resnet Network (WRN) model with 1.5 million parameters, it takes 1 minute to debug a complaint. We observe that most complaint debugging costs are independent of the complaint, and that modern models are overparameterized. In response, Rain++ uses precomputation techniques, based on non-trivial insights unique to data debugging, to reduce debugging latencies to a constant factor independent of model size. We also develop optimizations when the queried database is known apriori, and for standing queries over streaming databases. Combining these optimizations in Rain++ ensures interactive debugging latencies (1ms) on models with millions of parameters.  2022 ACM.","Flokas, Lampros; Wu, Weiyuan; Liu, Yejia; Wang, Jiannan; Verma, Nakul; Wu, Eugene",PO,YES,10.1145/3514221.3517849,Rain (the initial implementation they want to improve the engineering performances),"(1) MNIST, (2) Fashion-MNIST,  (3) CIFAR-10, (4) SST-2, (5) ADULT",any,-,any,"even if it uses approximations, it provides similar results (sometimes better, sometimes worse)","10 times faster online, with some pre-computation required before","precision, recall, AUC of top-k, like in the initial paper",,X8C6K9G7,"the paper is only focussed on optimization, not really data-cleaning",12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,2.0,0.0,-,
4,A Study on How Data Quality Influences Machine Learning Predictability and Interpretability for Tabular Data,,,,2022,DC4ML,tabular,error detection/repair,… of data cleaning and feature engineering on the results of training Machine Learning models on … Few of the supervised Machine Learning methods discussed below are used to train the …,"Ahsan, H",PO,score too low,,,,,,,,,,,VPQ3CK4X,,0,,,,,,,,0,0.0,0.0,,
5,Can Foundation Models Wrangle Your Data?,Both,arxiv,journalArticle,2022,ML4DC,tabular,more-than-one,"… As a proof-of-concept, we cast three data cleaning and … achieve SoTA performance on data cleaning and integration tasks, … from data science and machine learning experts who have …","Narayan, A; Chami, I; Orr, L; Ré, C",PO,YES,,"“We compare against the SoTA methods for each task. For
entity matching, we benchmark against Ditto [46], the current SoTA
DL-based approach which finetunes BERT [28]. For data imputation,
we benchmark against IMP [60], which finetunes RoBERTa [52]
and HoloClean [71], a statistical-based SoTA data repairing engine.
Finally, for error detection, we compare against HoloClean and
HoloDetect [34], a data-augmentation based ML approach.”","entity matching: Magellan. imputation: Restaurants and Buy. error detection,: Hospital","duplicate removal, missing value, wrong value (error detection)",See paper summary for more details,GPT-3-175B parameter model (text-davinci-002) in the OpenAI API endpoint,"Entity linkage: better  half the time, data imputation and error detection: always better ",Adapting the model to the data task may take some time.,"“For both the error detection and entity match-
ing datasets, we evaluate performance using F1 score. For imputa-
tion, we evaluate performance using accuracy.”",YES,NIGFJBI6,-,14,2.0,2.0,2.0,2.0,2.0,2.0,2.0,4,2.0,2.0,https://github.com/HazyResearch/fm_data_tasks,
6,Graph-Based Unsupervised Entity Resolution for Identifying Entity Profiles in Ambiguous Data,Academia,proquest,journalArticle,2022,ML4DC,tabular,entity matching / duplicate removal,"… On the other hand, machine learning and deep learning methods are … data cleaning, curation, and integration has become the goal for many organizations. Accordingly, unsupervised …","Ebeid, IA",PO,score too low - 2,,,,,,,,,,,EPJPYJAB,,0,,,,,,,,0,0.0,0.0,,
7,Sudowoodo: Contrastive Self-supervised Learning for Multi-purpose Data Integration and Preparation,Both,arxiv,journalArticle,2022,ML4DC,tabular,more-than-one,"… For data cleaning, we combine the error detection and correction stages and evaluate the quality of the final corrections. We also conduct a case study of column semantic type …","Wang, R; Li, Y; Wang, J",PO,YES,,(1) Baran+ Raha (2) Perfect error detection + Baran (3) Sudowoodo without pretraining of embeddings,(1) beers (2) hospital (3) rayyan (4) tax,any,-,a few ones. transformers are a key component.,Better than Baran with perfect ED by 2.1% on average!,-,F1-score of correct repairs,,A8N4FHG4,"The paper is not so clear, but the tool shows the author has significant ML skills.",12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,0.0,2.0,-,
8,Comparing Methods of Imputation for Time Series Missing Values,,,conferencePaper,2022,DC4ML,tabular,imputation,"Due to the rapid development of modern information engineering, a lot of data are used in machine learning and data cleaning and data mining of the hot research fields, such as a large portion of the data algorithm and related data model are built for complete data set, But in our real life and work, the absence of data exists in a large number of data collection, collation, transmission, storage and other links, it causes many obstacles and difficulties to build a model for complete data. The general way of dealing with missing values for simple delete, that deal with missing value method is a simple convenient but can cause: two aspects of the problem and the inconvenience caused by the original data set to reduce, reduce the reliability of the data, especially in the case of data loss is bigger, can cause a large number of data sets to reduce and missing, This has caused a lot of trouble to our work and research, so we need to find a more efficient and better method than direct deletion. In order to better solve the above problems, we mainly fill in the missing values of time series data, which has become an urgent problem to be solved. In this paper, mean filling, median filling, mode filling, PCA-EM filling and other methods are used to fill traffic data. By comparing these methods, the filling effect of each method is evaluated.  2022, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.","Geng, Renkang; Li, Mingran; Sun, Mingxu; Wang, Yujie",PO,Not accessible,10.1007/978-3-030-94182-6_24,,,,,,,,,,ZLQBSW7P,,0,,,,,,,,0,,,,
9,"Kern: A Labeling Environment forLarge-Scale, High-Quality Training Data",,,journalArticle,2022,ML4DC,any,mislabel correction,"The lack of large-scale, high-quality training data is a significant bottleneck in supervised learning. We introduce kern, a labeling environment used by machine learning experts and subject matter experts to create training data and find manual labeling errors powered by weak supervision, active transfer learning, and confident learning. We explain the current workflow and system overview and showcase the benefits of our system in an intent classification experiment, where we reduce the labeling error rate of a given dataset by an absolute 4.9% while improving the F 1 score of a baseline classifier by a total of 9.7%.  2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Hotter, Johannes; Wenck, Henrik; Feuerpfeil, Moritz; Witzke, Simon",PO,Not accessible,10.1007/978-3-031-08473-7_46,,,,,,,,,,GHS3HN7M,,0,,,,,,,,0,,,,
10,Correction to: Co-active neuro-fuzzy inference system model as single imputation approach for non-monotone pattern of missing data,Academia,Neural Computing and Applications,journalArticle,2022,ML4DC,tabular,imputation,"… that are used to measure the machine learning approaches precision. … on machine learning achieve in the data cleaning process. Moreover, it is considered that the machine learning-…","Silva-Ramirez, EL; Cabrera-Sánchez, JF",,YES,"https://doi.org/10.1007/s00521-020-05661-5(0123456789().,-volV","ANN baseline (MLP)
Mean/Mode
Regression
Hot-deck  e6ztd","18 datasets collected from UCI Repository: Abalone, Cleveland, Contraceptive, Credit, Flag, Heart, Glass, Image-segmentation, Pima, Sonar, Wine, Yeast, Breast, Car, Hayes-Roth, Lymphography, Soybean, Tic-Tac-Toe",missing data ,,CANFIS-ART based on Neural Networks and Fuzzy logic (Fuzzy-ART algorithm)," CANFIS-ART model has the highest GCI for all datasets with both qualitative and quantitative data, but for two of the datasets with only quantitative data, Hot-deck outperforms it and for one of the qualitative only dataset Mean/Mode outperform it.
CANFIS-ART model presents the best results of all the imputation methods with the greatest difference for almost all databases, standing out mainly in the block of databases with quantitative variables.",,"**to assess the goodness of fit between observed and predicted values: 
MSE Mean of Squared Error
RMSE Root Mean of Squared Error
MAPE Mean Absolute Percentage Error
ER Error rate
R2 Coefficient of determination
GCI Global Criteria Indicator

**to measure impact of imputation: accuracy of classifiers CART, SVM and MLP applied on the original database and the predicted data sets with estimated missing values using 10-fold cross-validation then Wilcoxon signed-rank test was performed for Original and CANFIS-ART as well as between CANFIS-ART and each of the compared approaches",,SDDXK8RH,correction paper! extracted information from the original,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,0.0,2.0,,
11,Performance evaluation of outlier detection techniques in production timeseries: A systematic review and meta-analysis,Academia,Expert Syst. Appl.,journalArticle,2022,ML4DC,tabular,outliers detection,"Time-series data have been extensively collected and analyzed in many disciplines, such as stock market, medical diagnosis, meteorology, and oil and gas industry. Numerous data in these disciplines are sequence of observations measured as functions of time, which can be further used for different applications via analytical or data analytics techniques (e.g., to forecast future price, climate change, etc.). However, presence of outliers can cause significant uncertainties to interpretation results; hence, it is essential to remove the outliers accurately and efficiently before conducting any further analysis. A total of 17 techniques that belong to statistical, regression-based, and machine learning (ML) based categories for outlier detection in timeseries are applied to the oil and gas production data analysis. 15 of these methods are utilized for production data analysis for the first time. Two state-of-the-art and high-performance techniques are then selected for data cleaning which require minimum control and time complexity. Moreover, performances of these techniques are evaluated based on several metrics including the accuracy, precision, recall, F1 score, and Cohen's Kappa to rank the techniques. Results show that eight unsupervised algorithms outperform the rest of the methods based on the synthetic case study with known outliers. For example, accuracies of the eight shortlisted methods are in the range of 0.830.99 with a precision between 0.83 and 0.98, compared to 0.650.82 and 0.070.77 for the others. In addition, ML-based techniques perform better than statistical techniques. Our experimental results on real field data further indicate that the k-nearest neighbor (KNN) and Fulford-Blasingame methods are superior to other outlier detection frameworks for outlier detection in production data, followed by four others including density-based spatial clustering of applications with noise (DBSCAN), and angle-based outlier detection (ABOD). Even though the techniques are examined with oil and gas production data, but the same data cleaning workflow can be used to detect timeseries outliers in other disciplines.  2021","Alimohammadi, Hamzeh; Nancy Chen, Shengnan",,YES,10.1016/j.eswa.2021.116371,"ML-based:
angle-based (angle-based and fast-angle based)
Classification-based (Oneclass-SVM and Iforest0
Proximity based (Density-based spatial clustering of applications with noise, K-nearset
neighbor, Local outlier factor, Clustering-based local outlier factor, Connectivity-based
outlier factor)
Besides other statistical methods and regression-based","synthetic dataset (decline curve using traditional hyperbolic Arps model consisting 3000 days of production with a measurement frequency of 10 days) for evaluation
real oil and gas production data",outliers,"Proximity-based: (n^2) complexity level, Score sensitive to the choice of number of nearest neighbors (k), Results in low performance if data has widely variable density
Density-based: O(n^2) complexity level, Must choose two parameters (k for nearest neighbors and d for distance threshold)
Clustering-based: Requires thresholds for minimum size and distanc, Sensitive to the number of clusters chosen, Hard to associate outlier scores with objects, Outliers may affect the initial formation of clusters, Low performance in small datasets
Classififcation-based: Computationally heavy, especially when in very large datasets, Returns binary results and not the outlier score",NA (comparative study),"Synthetic dataset: The best 8 detectors out of 17 are point distribution ESD, sliding window polynomial fit, FulfordBlasingame, iForest, Fast-ABOD, DBSCAN, COF, and KNN where their  accuracies are in the range of 0.83–0.99 with a precision between 0.83 and 0.98, compared to 0.65–0.82 and 0.07–0.77 for the others
Real dataset: out of the 8 detectors above, the best two are KNN and Fulford-Blasingame while point distribution ESD and polynomial fit perform slightly lower than the rest. However, all 8 performed well with few false positives
*Fulford-Blasingame performs better than KNN only for single trends data 


","KNN outperforms all other techniques and is the top choice for outlier detection in production data based on all selection criteria (performance, computation time, difficulty of tuning hyperparameters). KNN’s overall performance stands after Fulford-Blasingame only for a single trend production data.","accuracy, precision, recall, F1 score, confusion matrix and Cohen’s Kappa to rank the techniques (for synthetic dataset)
visual inspection (for real dataset)
computation time
difficulty of tuning hyperparameters",,CF22C3TD,,14,2.0,2.0,2.0,2.0,2.0,2.0,2.0,2,0.0,2.0,,
12,cleanTS: Automated (AutoML) tool to clean univariate time series at microscales,,,journalArticle,2022,"DC4ML, DC4ML - intro only, ML4DC",tabular,error detection/repair,"Data cleaning is one of the most important tasks in data analysis processes. One of the perennial challenges in data analytics is the detection and handling of non-valid data. Failing to do so can result in creating imbalanced observations that can cause bias and influence estimates, and in extreme cases, can even lead to inaccurate analytics and unreliable decisions. Usually, the process of data cleaning is time-consuming due to its growing volume, velocity, and variety. Further, the complexity and difficulty of the cleaning process increase with the amount of data to be analyzed. It is rarely the case that any real-world data is clean and error-free. Thus, pre-processing the data before using it for analysis has become standard practice. This paper is intended to provide an easy-to-use and reliable system which automates the cleaning process for univariate time series data. Also, automating the process reduces the time required for cleaning it. Another issue that the proposed system aims to solve is making the visualization of a large amount of data more effective. To tackle these issues, an R package, cleanTS is proposed. The proposed system provides a way to analyze data on different scales and resolutions. Also, it provides users with tools and a benchmark system for comparing various techniques used in data cleaning.  2022 The Author(s)","Shende, Mayur Kishor; Feijoo-Lorenzo, Andres E.; Bokde, Neeraj Dhanraj",Dima,score too low,10.1016/j.neucom.2022.05.057,No,"A time series containing 1,21,273 observations taken
from Kaggle ( https://www.kaggle.com/robikscube/hourly-energyconsumption).Power Consumption Dataset, CO2 Emission Dataset, Temperature Dataset","replacing missing values, handling anomalies",,None described ,No,"Power Consumption Dataset 24.59 sec, CO2 Emission Dataset 226.67 msec, Temperature Dataset 15.10 sec.",Running time of cleanTS function.,YES,"Time series analysis, Time series cleaning, Data cleaning, AutoML, Machine learning","Seems like a good tool, but it doesn’t present any new approach.",8,1.0,2.0,2.0,1.0,0.0,1.0,1.0,0,0.0,0.0,"https://mayur1009.shinyapps/.
io/cleanTS/.",
13,Deep entity matching with adversarial active learning,Both,VLDB Journal,journalArticle,2022,ML4DC,tabular,entity matching / duplicate removal,"Entity matching (EM), as a fundamental task in data cleansing and integration, aims to identify the data records in databases that refer to the same real-world entity. While recent deep learning technologies significantly improve the performance of EM, they are often restrained by large-scale noisy data and insufficient labeled examples. In this paper, we present a novel EM approach based on deep neural networks and adversarial active learning. Specifically, we design a deep EM model to automatically complete missing textual values and capture both similarity and difference between records. Given that learning massive parameters in the deep model needs expensive labeling cost, we propose an adversarial active learning framework, which leverages active learning to collect a small amount of ""good"" examples and adversarial learning to augment the examples for stability enhancement. Additionally, to deal with large-scale databases, we present a dynamic blocking method that can be interactively tuned with the deep EM model. Our experiments on benchmark datasets demonstrate the superior accuracy of our approach and validate the effectiveness of all the proposed modules.  2022, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Huang, Jiacheng; Hu, Wei; Bao, Zhifeng; Chen, Qijin; Qu, Yuzhong",PO,YES,10.1007/s00778-022-00745-1,(1) DeepMatcher (2) Seq2SeqMatcher (3) EMTranformer (4) DItto (5) CorDEL,(1) DBLPScholar (2) DBLP-ACM (3) Amazon-Google (4) Walmart-Amazon (5) Fodors-Zagats (6) iTunes-Amazon (7) Beer,duplicates,-,"a lot. transformers, cnns, etc.",Better or equal than others on every dataset,generally lower than other approaches,precision recall f1-score,,,It could also have been named: “how to make something relatively simple impossible to understand”,9,2.0,2.0,1.0,2.0,0.0,1.0,1.0,4,2.0,2.0,,
14,Data abnormal detection using bidirectional long-short neural network combined with artificial experience,,,journalArticle,2022,,,,"Data anomalies seriously threaten the reliability of the bridge structural health monitoring system and may trigger system misjudgment. To overcome the above problem, an efficient and accurate data anomaly detection method is desiderated. Traditional anomaly detection methods extract various abnormal features as the key indicators to identify data anomalies. Then set thresholds artificially for various features to identify specific anomalies, which is the artificial experience method. However, limited by the poor generalization ability among sensors, this method often leads to high labor costs. Another approach to anomaly detection is a data-driven approach based on machine learning methods. Among these, the bidirectional long-short memory neural network (BiLSTM), as an effective classification method, excels at finding complex relationships in multivariate time series data. However, training unprocessed original signals often leads to low computation efficiency and poor convergence, for lacking appropriate feature selection. Therefore, this article combines the advantages of the two methods by proposing a deep learning method with manual experience statistical features fed into it. Experimental comparative studies illustrate that the BiLSTM model with appropriate feature input has an accuracy rate of over 87-94%. Meanwhile, this paper provides basic principles of data cleaning and discusses the typical features of various anomalies. Furthermore, the optimization strategies of the feature space selection based on artificial experience are also highlighted. Copyright  2022 Techno-Press, Ltd.","Yang, Kang; Jiang, Huachen; Ding, Youliang; Wang, Manya; Wan, Chunfeng",PO,Not accessible,10.12989/sss.2022.29.1.117,,,,,,,,,,,,0,,,,,,,,0,,,,
15,Data Cleaning of Sound Data with Label Noise Using Self Organizing Map,,,conferencePaper,2022,,,,"The noise label of data is a problem that can cause low performance of deep learning. It is difficult to manually relabel due to huge amounts of data. In addition, there are much more problems due to the similarity of sounds that are difficult to manually distinguish and label sound data. We proposed a data cleaning method using SOM (Self-Organizing Map), one of the unsupervised learning methods. In order to extract compact features from audio, densely connected layer with log scaled Mel-spectrogram is used. Data selection is performed based on the Euclidean distance of each Best matching unit (BMU) derived through the SOM. We also experiment with various grid sizes for SOM to find an efficient grid size. In addition, an appropriate distance finding experiment is conducted. This method is evaluated in sound classification using a pre-trained DenseNet model.  2022 IEEE.","Hwang, Pildong; Kim, Yanggon",,exclusion criteria last step,10.1109/IMCOM53663.2022.9721724,,,,,,,,,,,,0,,,,,,,,0,,,,
16,Confident Learning-Based Domain Adaptation for Hyperspectral Image Classification,,,journalArticle,2022,"DC4ML, ML4DC",img,mislabel correction,"Cross-domain hyperspectral image classification is one of the major challenges in remote sensing, especially for target domain data without labels. Recently, deep learning approaches have demonstrated effectiveness in domain adaptation. However, most of them leverage unlabeled target data only from a statistical perspective but neglect the analysis at the instance level. For better statistical alignment, existing approaches employ the entire unevaluated target data in an unsupervised manner, which may introduce noise and limit the discriminability of the neural networks. In this article, we propose confident learning-based domain adaptation (CLDA) to address the problem from a new perspective of data manipulation. To this end, a novel framework is presented to combine domain adaptation with confident learning (CL), where the former reduces the interdomain discrepancy and generates pseudo-labels for the target instances, from which the latter selects high-confidence target samples. Specifically, the confident learning part evaluates the confidence of each pseudo-labeled target sample based on the assigned labels and the predicted probabilities. Then, high-confidence target samples are selected as training data to increase the discriminative capacity of the neural networks. In addition, the domain adaptation part and the confident learning part are trained alternately to progressively increase the proportion of high-confidence labels in the target domain, thus further improving the accuracy of classification. Experimental results on four datasets demonstrate that the proposed CLDA method outperforms the state-of-the-art domain adaptation approaches. Our source code is available at http://github.com/Li-ZK/CLDA-2022.  2022 IEEE.","Fang, Zhuoqun; Yang, Yuexin; Li, Zhaokui; Li, Wei; Chen, Yushi; Ma, Li; Du, Qian",PO,score too low,10.1109/TGRS.2022.3166817,,,,,,,,,,,,0,,,,,,,,0,0.0,0.0,,
17,Towards a Holistic Data Preparation Tool,,,conferencePaper,2022,"DC4ML, DC4ML - intro only",any,error detection/repair,"Data-driven systems and machine learning-based decisions are becoming increasingly important and are having an impact on our everyday lives. The prerequisite for this is good data quality, which must be ensured by preprocessing the data. However, a number of challenges arise in the process. These include the results of the process in terms of data quality, e.g., combating bias and ensuring fairness, and the preprocessing process itself. Here, human involvement and the lack of intelligent solutions and applications for domain experts without in-depth IT knowledge play a major role. This paper summarizes these challenges and provides an overview of the current state of the art. It proposes the design of a holistic tool, along with the necessary tasks to overcome these challenges and to support data preprocessing.  2022 Copyright for this paper by its authors.","Restat, Valerie; Klettke, Meike; Storl, Uta",PO,exclusion criteria last step,,,,,,,,,,,,,0,,,,,,,,0,,,,
18,Research on English Grammar Error Correction Technology Based on BLSTM Sequence Annotation,Academia,Asian Conference on Artificial Intelligence Technology,conferencePaper,2021,ML4DC,text,error detection/repair,"… of intelligent English grammatical error detection and correction technology. … neural network and feedforward neural network, tagging model based on multilayer neural network and …","Shi, Y",,score too low,10.1109/ACAIT53529.2021.9731256 ,"compared with tagging models:
(1) Senna tagging model based on convolutional neural network and feedforward neural network
(2) tagging model based on multilayer neural network

compared with error correction models:
(1) UIUC model (won the first place in the CoNLL evaluation in 2013)
(2) Corpus GEC model","corpus comes from 
(1) news corpus of WSJ Wall Street Journal 
(2) the named entity recognition corpus of CONLL 2013 
(3) PiGai corpus of correctional website",Grammatical ,"Although it performs better for correcting the fixed grammatical errors (e.g., article and preposition use errors), the performance degrades for the grammatical errors such as verbs and nouns ",BLSTM,"recall rate is 44.95%, F-measure index value is 38.26%, which is 4.85% higher than the UIUC model and 4.92% higher than the Corpus GEC model.
Precision is ~ 33% which is ~14% less than UIUC model and ~10% less than Corpus GEC model (approx. as only shown in fig.)",-,"Accuracy for comparing with tagging models
Precision, Recall and F-measure for comparing with error correction models",,XDLYWZCH,It achieves better accuracy and F-score because it has higher recall; however the precision is lower than UIUC and Corpus GEC. When compared with the tagging models only the accuracy is reported!,6,2.0,1.0,0.0,1.0,1.0,1.0,0.0,2,1.0,1.0,,
19,Detecting Adversarial Image Examples in Deep Neural Networks with Adaptive Noise Reduction,,,journalArticle,2021,ML4DC,img,error detection/repair,"Recently, many studies have demonstrated deep neural network (DNN) classifiers can be fooled by the adversarial example, which is crafted via introducing some perturbations into an original sample. Accordingly, some powerful defense techniques were proposed. However, existing defense techniques often require modifying the target model or depend on the prior knowledge of attacks. In this paper, we propose a straightforward method for detecting adversarial image examples, which can be directly deployed into unmodified off-the-shelf DNN models. We consider the perturbation to images as a kind of noise and introduce two classic image processing techniques, scalar quantization and smoothing spatial filter, to reduce its effect. The image entropy is employed as a metric to implement an adaptive noise reduction for different kinds of images. Consequently, the adversarial example can be effectively detected by comparing the classification results of a given sample and its denoised version, without referring to any prior knowledge of attacks. More than 20,000 adversarial examples against some state-of-the-art DNN models are used to evaluate the proposed method, which are crafted with different attack techniques. The experiments show that our detection method can achieve a high overall F1 score of 96.39 percent and certainly raises the bar for defense-aware attacks.  2020 IEEE.","Liang, Bin; Li, Hongcheng; Su, Miaoqiang; Li, Xirong; Shi, Wenchang; Wang, Xiaofeng",PO,score too low - 2,10.1109/TDSC.2018.2874243,,,,,,,,,,SZN9D7AK,,0,,,,,,,,0,0.0,0.0,,
20,Automatic Detection of Grammatical Errors in English Verbs Based on RNN Algorithm: Auxiliary Objectives for Neural Error Detection Models,Academia,Computational Intelligence and Neuroscience,journalArticle,2021,ML4DC,text,error detection/repair,"… On this basis, in order to propose a more reliable and accurate method, this study explores an automatic grammar error detection method based on recurrent neural network (RNN), and …","He, Y",,YES,https://doi.org/10.1155/2021/6052873,CUUI method,"conll-2014 
(selected only the sentences sentences with grammatical errors of verb form)",Grammatical,"Focus only on grammatical errors of English verbs 

",RNN,"precision 61.10%, recall rate 20.32, and F0.5 43.60. 
Compared to CUUI method, the accuracy and F0.5 are improved by 13.99% (absolute increase value =7.5) and 5.77% (absolute increase value =2.38), respectively, while recall slightly decreased (absolute decrease value ~ 1)",-,"Precision
Recall
F0.5 (assign higher weight to precision)

",,8LVSRULP,"The paper does not explain the compared approach but it seems based on Neural Networks.
The use of RNN allows to consider the sentence context which is important to detect and correct errors on verbs; thus, achieving better results than traditional NN.
Although the scope of errors is very limited (only verbs), the recall is low. ",12,2.0,2.0,1.0,2.0,1.0,2.0,2.0,2,0.0,2.0,,
21,Machine Learning-Based Grammar Error Detection Method in English Composition,Academia,Scientific Programming,journalArticle,2021,ML4DC,text,error detection/repair,"… in grammar error detection … error detection and correction in English composition based on a hybrid model. According to specific application scenarios, the corresponding neural network …","Zhu, J; Shi, X; Zhang, S",,score too low,https://doi.org/10.1155/2021/4213791,"SVM, DT, RNN, LSTM, Transformer, BERT
Besides comparing to each of the sub-models (SSA-ERDC, T-ERDC, B-ERDC)","training: an article from the Wall Street Journal (manually add type errors)
testing: student’s work for a certain English writing exercise + assignment of five kinds of students (middle school students in the Chinese English Learner Corpus, college English levels 4 and 6,
and professional English lower and upper grades)",Grammatical,,"Hybrid (H-ERDC) combination of:
(i) seq2seq model (SSA-ERDC)
(ii) Transformers-based (T-ERDC)
(iii) Bert-based (B-ERDC)","H-ERDC achieves F0.5=89 which is slightly better than using each sub-model (SSA-ERDC 83, T-ERDC 84 and B-ERDC 88)
H-ERDC significantly outperforms ML models (SVM 74 and DT 76)",-,"Precision
Recall
F0.5",,XVDQGXSY,"Does not determine which kind of grammatical error it’s tackling (general)!
Not clear how they merged the models outputs!",6,1.0,1.0,1.0,1.0,0.0,1.0,1.0,1,0.0,1.0,,
22,Unsupervised Outlier Detection: A Meta-Learning Algorithm Based on Feature Selection,Academia,Electronics,journalArticle,2021,ML4DC,tabular,outliers detection,"… unsupervised outlier detection is introduced in order to mitigate this problem. The proposed algorithm, in a fully unsupervised … ] and an invaluable step in any data cleaning process [11]. …","Papastefanopoulos, V; Linardatos, P; Kotsiantis, S",,YES,https://doi.org/10.3390/electronics10182236,"Cluster-based local outlier factor
Isolation forest
K Nearest neighbours (KNN)
Histogram-base outlier detection (HBOS)
Minimum covariance determinant (MCD)
One-class SVM (OCSVM)
Principal component analysis (PCA)
Feature bagging
Angle-based outlier detector (ABOD)
Local outlier factor (LOF)","17 datasets of different meta-data (number of rows, columns and outliers), coming from a diverse pool of domains",Outlier,"For one dataset (vertebral) all the methods including the proposed method, scored almost zero precision which means none of the methods is appropriate for this dataset",Ensemble of 6 outliers detection methods,"Even though for some datasets the proposed method has lower performance than compared methods, in general it achieved the highest rank  for both ROC and precision compared to other approaches using Freidman statistical test.
However, the precision is still very low and largely varies from 0.01 to 0.91 where most of the datasets’ results fall below 0.60",,"ROC and precision
Friedman’s non-parametric statistical test",,EW8PN28M,,8,2.0,2.0,1.0,1.0,0.0,1.0,1.0,2,0.0,2.0,https://github.com/ML-Upatras/unsupervised-outlier-detection,
23,CleanML: A study for evaluating the impact of data cleaning on ml classification tasks,Academia,IEEE ICDE,conferencePaper,2021,DC4ML,tabular,holistic,"Data quality affects machine learning (ML) model performances, and data scientists spend considerable amount of time on data cleaning before model training. However, to date, there does not exist a rigorous study on how exactly cleaning affects ML - ML community usually focuses on developing ML algorithms that are robust to some particular noise types of certain distributions, while database (DB) community has been mostly studying the problem of data cleaning alone without considering how data is consumed by downstream ML analytics.We propose a CleanML study that systematically investigates the impact of data cleaning on ML classification tasks. The open-source and extensible CleanML study currently includes 14 real-world datasets with real errors, five common error types, seven different ML models, and multiple cleaning algorithms for each error type (including both commonly used algorithms in practice as well as state-of-the-art solutions in academic literature). We control the randomness in ML experiments using statistical hypothesis testing, and we also control false discovery rate in our experiments using the Benjamini-Yekutieli (BY) procedure. We analyze the results in a systematic way to derive many interesting and nontrivial observations. We also put forward multiple research directions for researchers.  2021 IEEE.","Li, Peng; Rao, Xi; Blase, Jennifer; Zhang, Yue; Chu, Xu; Zhang, Ce",PO,YES,10.1109/ICDE51399.2021.00009,-,"Citation, EEG, Marketing, Movie, Company, Restaurant, Sensor, Titanic, Credit, University, USCensus, Airbnb, BabyProduct, Clothing","missing values, outliers, duplicates, inconsistencies and mislabels",-,"(1) Logistic Regression, (2) Decision Tree, (3) Random Forest, (4) Adaboost, (5) XGBoost, (6) k-Nearest Neighbors (KNN) and (7) Naive Bayes",-,-,(1) accuracy or (2) F1 score,,DLX6V84Q,-,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,4,2.0,2.0,https://chu-data-lab.github.io/CleanML/,
24,Data Quality Toolkit: Automatic assessment of data quality and remediation for machine learning datasets,Industry,arxiv,journalArticle,2021,DC4ML,any,more-than-one,… Our label purity algorithm is built on top of the recent confident learning [22] based approach (CleanLab). One limitation of CleanLab approach is that it can tag some correct samples as …,"Gupta, N; Patel, H; Afzal, S; Panwar, N; Mittal, RS; ...",PO,score too low,,-,-,-,-,-,-,-,-,,FRJ4XZL7,-,7,2.0,2.0,1.0,1.0,0.0,1.0,0.0,0,0.0,0.0,https://developer.ibm.com/apis/catalog/dataquality4ai--data-quality-for-ai/Introduction,
25,From papers to practice: the openclean open-source data cleaning library,Academia,VLDB Endowment,conferencePaper,2021,DC4ML,tabular,more-than-one,"… use of machine learning [17] makes data cleaning essential … of quality issues, and data cleaning to transform the data into a … 60% of their time on data cleaning and organizing data [16]. …","Müller, H; Castelo, S; Qazi, M; Freire, J",PO,score too low,10.14778/3476311.3476339,-,-,-,-,-,-,-,-,,QZIY63BD,-,11,2.0,2.0,2.0,1.0,1.0,2.0,1.0,0,0.0,0.0,-,
26,TSAR: a time series assisted relabeling tool for reducing label noise,Academia,PErvasive Technologies Related to Assistive Environments Conference,journalArticle,2021,ML4DC,tabular,mislabel correction,"… TSAR to remove mislabeled instances, and the method used to test TSAR on several machine learning models. In Section 4 we present the findings of the survey and label cleaning …","Atkinson, G; Metsis, V",PO,YES,10.1145/3453892.3453900,Letting a human review arbitrary instances using TSAR visualisation (without prioritization),"(1) the UniMiB SHAR dataset: “collected from volunteers carrying commercial smartphones in their front trousers pockets” (2) UCI HAR: “Samples were collected at 50 Hz using commercial smartphones
mounted at the waist.”",mislabels,-,CNN,"(1) Not better than the compared approach (2) obviously, it has improved model performance; someone manually cleaned the dataset!",-,(1) Confusion matrix (2) performance of end model after cleaning,,DSB98ZH2,Their approach is not better than doing nothing (not prioritizing samples),9,2.0,2.0,1.0,2.0,0.0,1.0,1.0,2,2.0,0.0,https://github.com/imics-lab/TSAR,
27,A reconstruction error-based framework for label noise detection,Academia,Journal of Big Data,journalArticle,2021,ML4DC,tabular,mislabel correction,… We point out that these are primarily supervised approaches [23]. Zhang and Tan [24] used … both data cleaning and classification quality. The authors follow an unsupervised approach …,"Salekshahrezaee, Z; Leevy, JL; Khoshgoftaar, TM",Dima,YES,10.1186/s40537-021-00447-5,,A credit card fraud dataset by Worldline and the Université Libre de Bruxelles (ULB). Kaggle: Credit Card Fraud Detection. https://www.kaggle.com/mlg-ulb/creditcardfraud.,,,"PCA, autoencoders",,,"Area Under the Receiver Operating Characteristic Curve (AUC), recall, and
False Negative Rate (FNR).",YES,94456HSI,Good for snowbowling,9,1.0,1.0,2.0,1.0,2.0,1.0,1.0,2,1.0,1.0,,
28,Unsupervised anomaly detection in data quality control,,,journalArticle,2021,ML4DC,tabular,error detection/repair,"An automated anomaly detection approach is required to improve
data management and quality control processes. This study
introduces an unsupervised anomaly detection approach based
on models comparison, consensus learning, and a combination of
rules of thumb with iterative hyper-parameter tuning to increase
data quality. Furthermore, a domain expert is considered a
human in the loop to evaluate and check the data quality and to
judge the output of the unsupervised model. An experiment has
been conducted to assess the proposed approach in the context of
a case study. The experiment results confirm that the proposed
approach can improve the quality of organizational data and
facilitate anomaly detection processes.","Poon, L; Farshidi, S; Li, N; Zhao, Z",Dima,score too low,,"(a) Clustering: KNN,
AvgKNN, MedKNN (b)Density: DBSCAN & LOF (c) Ensemble:
IForest (d) Linear (PyOD): One Class Support Vector
Machine (OCSVM), PCA (e) Proximity (PyOD): Histogrambased
Outlier Score (HBOS), Rotation-based Outlier Detection
(ROD)",,,"One automated anomaly detection algorithm for all data quality
problems cannot be chosen.",DBSCAN is selected as the automated data quality control method,"Precision: 0.941,Recall: 0.168",,Results are compared with fake outliers injected into the data set. Precision is the primary metric,,AD7Q8ZU3,"Poorly written paper. Contribution is not clearly defined, no comparison to the baselines.",4,1.0,1.0,1.0,0.0,0.0,1.0,0.0,2,1.0,1.0,,
29,RumbleML: Program the lakehouse with JSONiq [Scalable Data Science],,,journalArticle,2021,,,,"Lakehouse systems have reached in the past few years unprecedented size and heterogeneity and have been embraced by many industry players. However, they are often difficult to use as they lack the declarative language and optimization possibilities of relational engines. This paper introduces RumbleML, a high-level, declarative library integrated into the RumbleDB engine and with the JSONiq language. RumbleML allows using a single platform for data cleaning, data preparation, training, and inference, as well as management of models and results. It does it using a purely declarative language (JSONiq) for all these tasks and without any performance loss over existing platforms (e.g. Spark). The key insights of the design of RumbleML are that training sets, evaluation sets, and test sets can be represented as homogeneous sequences of flat objects; that models can be seamlessly embodied in function items mapping input test sets into prediction-augmented result sets; and that estimators can be seamlessly embodied in function items mapping input training sets to models. We argue that this makes JSONiq a viable and seamless programming language for data lakehouses across all their features, whether database-related or machine-learning-related. While lakehouses bring Machine Learning and Data Wrangling on the same platform, RumbleML also brings them to the same language, JSONiq. In the paper, we present the first prototype and compare its performance to Spark showing the benefit of a huge functionality and productivity gain for cleaning up, normalizing, validating data, feeding it into Machine Learning pipelines, and analyzing the output, all within the same system and language and at scale.MSC Codes 68N99 Copyright  2021, The Authors. All rights reserved.","G., Fourny; D., Dao; C.B., Cikis; C., Zhang; G., Alonso",,score too low - 4,,,,,,,,,,,SKBD37BM,,0,,,,,,,,0,0.0,0.0,,
30,Semi-Supervised Data Cleaning with Raha and Baran.,Academia,Conference on Innovative Data Systems Research (CIDR),journalArticle,2021,ML4DC,tabular,error detection/repair,"… supervised manner. In this paper, we demonstrate how both systems can be used within an end-to-end data cleaning … , both systems can optimize the data cleaning task at hand in terms …","Mahdavi, M; Abedjan, Z",PO,YES,,,,,,,,,,,YAJ728SP,,0,,,,,,,,0,,,,
31,Toward Data Cleaning with a Target Accuracy: A Case Study for Value Normalization,Academia,arxiv,journalArticle,2021,,,error detection/repair,"Many applications need to clean data with a target accuracy. As far as we know, this problem has not been studied in depth. In this paper we take the first step toward solving it. We focus on value normalization (VN), the problem of replacing all string that refer to the same entity with a unique string. VN is ubiquitous, and we often want to do VN with 100% accuracy. This is typically done today in industry by automatically clustering the strings then asking a user to verify and clean the clusters, until reaching 100% accuracy. This solution has significant limitations. It does not tell the users how to verify and clean the clusters. This part also often takes a lot of time, e.g., days. Further, there is no effective way for multiple users to collaboratively verify and clean. In this paper we address these challenges. Overall, our work advances the state of the art in data cleaning by introducing a novel cleaning problem and describing a promising solution template. Copyright  2021, The Authors. All rights reserved.","Ardalan, Adel; Paulsen, Derek; Saini, Amanpreet Singh; Cai, Walter; Doan, AnHai",PO,score too low - 2,,,,,,,,,,,,,0,,,,,,,,0,0.0,0.0,,
32,SPADE: A Semi-supervised Probabilistic Approach for Detecting Errors in Tables,Academia,IJCAI,conferencePaper,2021,ML4DC,tabular,error detection,"Error detection is one of the most important steps in data cleaning and usually requires extensive human interaction to ensure quality. Existing supervised methods in error detection require a significant amount of training data while unsupervised methods rely on fixed inductive biases, which are usually hard to generalize, to solve the problem. In this paper, we present SPADE, a novel semi-supervised probabilistic approach for error detection. SPADE introduces a novel probabilistic active learning model, where the system suggests examples to be labeled based on the agreements between user labels and indicative signals, which are designed to capture potential errors. SPADE uses a two-phase data augmentation process to enrich a dataset before training a deep-learning classifier to detect unlabeled errors. In our evaluation, SPADE achieves an average F1-score of 0.91 over five datasets and yields a 10% improvement compared with the state-of-the-art systems.  2021 International Joint Conferences on Artificial Intelligence. All rights reserved.","Pham, Minh; Knoblock, Craig A.; Chen, Muhao; Vu, Binh; Pujara, Jay",PO,YES,,"(1) Active learning approaches: (1.1)Raha, (1.2)Ed2 (2) Others: (2.1) dBoost, (2.2) NADEEF, (2.3)KATARA, (2.4)ActiveClean",(1) Hospital (2) Beers (3) Rayyan (4) Flights (5) Movies,any,-,"A binary classifier, open for more details",Generally better than other approaches,Compared to other active learning approaches: (1) number of labeled cells generally slightly lower and (2) time consumption slightly above,"precision, recall, F1 score",,,-,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,0.0,2.0,https://github.com/minhptx/spade,
33,TabReformer: Unsupervised Representation Learning for Erroneous Data Detection,Both,ACM/IMS Transactions on Data Science,journalArticle,2021,ML4DC,tabular,error detection,"Error detection is a crucial preliminary phase in any data analytics pipeline. Existing error detection techniques typically target specific types of errors. Moreover, most of these detection models either require user-defined rules or ample hand-labeled training examples. Therefore, in this article, we present TabReformer, a model that learns bidirectional encoder representations for tabular data. The proposed model consists of two main phases. In the first phase, TabReformer follows encoder architecture with multiple self-attention layers to model the dependencies between cells and capture tuple-level representations. Also, the model utilizes a Gaussian Error Linear Unit activation function with the Masked Data Model objective to achieve deeper probabilistic understanding. In the second phase, the model parameters are fine-tuned for the task of erroneous data detection. The model applies a data augmentation module to generate more erroneous examples to represent the minority class. The experimental evaluation considers a wide range of databases with different types of errors and distributions. The empirical results show that our solution can enhance the recall values by 32.95% on average compared with state-of-the-art techniques while reducing the manual effort by up to 48.86%.  2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.","Nashaat, Mona; Ghosh, Aindrila; Miller, James; Quader, Shaikh",PO,YES,10.1145/3447541,(1) Holoclean (2) ED2 (3) Raha (4) ActiveClean (5) NADEEF,(1) Adult (2) Restaurants (3) Flights (4) Movies (5) Hospital (6) Beers,any (error detection),-,Transformer,Recall enhanced by 32.95% on average,Manual labeling effort reduced by 48.86%,(1) Precision (2) Recall (3) F1. Regarding the proportion of error detected - not a end model.,YES,,Pretty solid. We could say that the quality of transformer highly depends on the quality of the data augmentation module,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,4,2.0,2.0,https://github.com/MonaNashaat/TabReformer,
34,Correcting Corrupted Labels Using Mode Dropping of ACGAN,Academia,International Symposium on Medical Information and Communication Technology (ISMICT),conferencePaper,2021,"DC4ML, ML4DC",img,mislabel correction,"Machine learning often requires a large amount of training data, and the training data obtained from various sources is often of poor quality, such as a large number of corrupted labels. Researchers using machine learning often apply some data cleaning techniques to clean up corrupted data. There are two popular methods to clean corrupted data: one is to set manual cleaning rules, and the other is to use positive samples for machine learning or statistical methods. Our work proposes a data cleaning method based on ACGAN since it is difficult to manually formulate cleaning rules, and there are often no positive samples of training data too. Our work does not need to artificially add cleaning rules or positive samples, and subtly uses mode dropping of GAN to eliminate the impact of noisy labels on corrupted data so which can be converted to relatively clean synthetic training data. Mode dropping of ACGAN will naturally happens, which is originally a disadvantage that usually needs to be eliminated in GAN, we tom the disadvantage into advantage, ACGAN will ignore some non-subject features when generating data, so as to eliminate the impact of noisy labels. And we also apply our method to correct noisy labels on corrupted training data.  2021 IEEE.","Su, Jizhong; Gao, Xing; Qin, Yipeng; Guo, Shihui",PO,YES,10.1109/ISMICT51748.2021.9434911,-,(1) MNIST (2) Fashion-MNIST,-,-,ACGAN and MLP,See figures,-,(1) Accuracy of end ML model,,,"Very poorly written, we could consider even removing it from the reading list since I am still not sure what they did",7,2.0,1.0,1.0,1.0,0.0,1.0,1.0,4,2.0,2.0,-,
35,A Model and System for Querying Provenance from Data Cleaning Workflows,,,conferencePaper,2021,,,error detection/repair,"Data cleaning is an essential component of data preparation in machine learning and other data science workflows, and is widely recognized as the most time-consuming and error-prone part when working with real-world data. How data was prepared and cleaned has a significant impact on the reliability and trustworthiness of results of any subsequent analysis. Transparent data cleaning not only requires that provenance (i.e., operation history and value changes) be captured, but also that those changes are easy to explore and evaluate: The data scientists who prepare the data, as well as others who want to reuse the cleaned data for their studies, need to be able to easily explore and query its data cleaning history. We have developed a domain-specific provenance model for data cleaning that supports the kind of provenance questions that data scientists need to answer when inspecting and debugging data preparation histories. The design of the model was driven by the need (i) to answer relevant, user-oriented provenance questions, and (ii) to do so in an effective and efficient manner. The model is a refinement of an earlier provenance model and has been implemented as a companion tool to OpenRefine, a popular, open source tool for data cleaning.  2021, Springer Nature Switzerland AG.","Parulian, Nikolaus Nova; McPhillips, Timothy M.; Ludascher, Bertram",Dima,Not accessible,10.1007/978-3-030-80960-7_11,,,,,,,,,,,,0,,,,,,,,0,0.0,0.0,,
36,Mislabeled Samples Adjustment Based on Self-paced Learning Framework,Academia,International Conference on Computer and Communications (ICCC),conferencePaper,2021,"DC4ML, ML4DC",img,mislabel correction,"Human have ability to detect and correct the mistakes in life events. For instance, it could be easy for a child to find a cat image incorrectly labeled with a dog label. However, supervised learning network directly learns the mapping between features and labels even though some labels are obviously wrong. Label noise surely increases the complexity of model and undermine the model performance. Enlightened by self-paced learning (SPL) framework which can learn samples in the order of complexity, we propose one iteration-based framework called MSASL which can discriminate and correct the possibly mislabeled samples. The approach can not only achieve the data cleansing task, but also ensure the performance of the model.  2021 IEEE.","Huang, Zhongtao; Li, Xiaojuan; Deng, Lingzhu; Wei, Kaizhen; Sui, Yunfeng",PO,YES,10.1109/ICCC54389.2021.9674334,-,(1) FOD dataset (2) VOC dataset,mislabels,-,VGG-19,-,-,Percentage of mislabeled instances,NO,,very difficult to read because of poor english,7,2.0,1.0,1.0,1.0,0.0,1.0,1.0,4,2.0,2.0,-,
37,Deep transfer learning for multi-source entity linkage via domain adaptation,Both,arxiv,journalArticle,2021,ML4DC,tabular,entity matching / duplicate removal,"Multi-source entity linkage focuses on integrating knowledge from multiple sources by linking the records that represent the same real world entity. This is critical in high-impact applications such as data cleaning and user stitching. The state-of-the-art entity linkage pipelines mainly depend on supervised learning that requires abundant amounts of training data. However, collecting well-labeled training data becomes expensive when the data from many sources arrives incrementally over time. Moreover, the trained models can easily overfit to specific data sources, and thus fail to generalize to new sources due to significant differences in data and label distributions. To address these challenges, we present AdaMEL, a deep transfer learning framework that learns generic high-level knowledge to perform multi-source entity linkage. AdaMEL models the attribute importance that is used to match entities through an attribute-level self-attention mechanism, and leverages the massive unlabeled data from new data sources through domain adaptation to make it generic and data-source agnostic. In addition, AdaMEL is capable of incorporating an additional set of labeled data to more accurately integrate data sources with different attribute importance. Extensive experiments show that our framework achieves state-of-the-art results with 8.21% improvement on average over methods based on supervised learning. Besides, it is more stable in handling different sets of data sources in less runtime. Copyright  2021, The Authors. All rights reserved.","Jin, Di; Sisman, Bunyamin; Wei, Hao; Dong, Xin Luna; Koutra, Danai",PO,YES,,(1) TLER (2) DeepMatcher (3) EntityMatcher (4) Ditto (5) CorDel,(1) Data Integration to Knowledge Graphs (DI2KG) challenge (2) Music-1M (3) Music-3K,duplicates,-,NNs and attention mechanisms,Above in almost every case,-,PRAUC,,,-,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,4,2.0,2.0,-,
38,Picket: guarding against corrupted data in tabular data during learning and inference,Academia,VLDB Journal,journalArticle,2021,"DC4ML, DC4ML - intro only, ML4DC",tabular,error detection,"Data corruption is an impediment to modern machine learning deployments. Corrupted data can severely bias the learned model and can also lead to invalid inferences. We present, Picket, a simple framework to safeguard against data corruptions during both training and deployment of machine learning models over tabular data. For the training stage, Picket identifies and removes corrupted data points from the training data to avoid obtaining a biased model. For the deployment stage, Picket flags, in an online manner, corrupted query points to a trained machine learning model that due to noise will result in incorrect predictions. To detect corrupted data, Picket uses a self-supervised deep learning model for mixed-type tabular data, which we call PicketNet. To minimize the burden of deployment, learning a PicketNet model does not require any human-labeled data. Picket is designed as a plugin that can increase the robustness of any machine learning pipeline. We evaluate Picket on a diverse array of real-world data considering different corruption models that include systematic and adversarial noise during both training and testing. We show that Picket consistently safeguards against corrupted data during both training and deployment of various models ranging from SVMs to neural networks, beating a diverse array of competing methods that span from data quality validation models to robust outlier detection models.  2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Liu, Zifan; Zhou, Zhechun; Rekatsinas, Theodoros",PO,YES,10.1007/s00778-021-00699-w,"to many to write here, see page",(1) Wine (2) Adult (3) marketing (4) Restaurant (5) Titanic (6) HTRU2,"any error. noise considered: random, systematic, adversarial",-,Detecting errors: two-stream multi-head self-attention. Open for more details.,(1) better than other approaches to detect errors and (2) no significant improvements on the end model improvement except for when samples are poisoned,"(1) training time: scales quadratically. They suggested an approach to address this issue. (2) at inference, adds a significant overhead (more than inference), but less than a second, so not too bad for humans",(1) test accuracy of downstream model (2) F1 of error detector,,,very well written paper,13,2.0,2.0,2.0,2.0,1.0,2.0,2.0,4,2.0,2.0,,
39,EfficientCLIP: Efficient cross-modal pre-training by Ensemble Confident Learning and language modeling,,,journalArticle,2021,,?,mislabel correction,"While large scale pre-training has achieved great achievements in bridging the gap between vision and language, it still faces several challenges. First, the cost for pre-training is expensive. Second, there is no efficient way to handle the data noise which degrades model performance. Third, previous methods only leverage limited image-text paired data, while ignoring richer single-modal data, which may result in poor generalization to single-modal downstream tasks. In this work, we propose an EfficientCLIP method via Ensemble Confident Learning to obtain a less noisy data subset. Extra rich non-paired single-modal text data is used for boosting the generalization of text branch. We achieve the state-of-the-art performance on Chinese cross-modal retrieval tasks with only 1/10 training resources compared to CLIP and WenLan, while showing excellent generalization to single-modal tasks including text retrieval and text classification. Copyright  2021, The Authors. All rights reserved.","Wang, Jue; Wang, Haofan; Deng, Jincan; Wu, Weijia; Zhang, Debing",PO,score too low,,,,,,,,,,,,,6,1.0,1.0,1.0,1.0,0.0,1.0,1.0,2,1.0,1.0,,
40,Data readiness report,Industry,IEEE International Conference on Smart Data Services (SMDS),conferencePaper,2021,"DC4ML, DC4ML - intro only",any,error detection/repair,"Data exploration and quality analysis is an important yet tedious process in the AI pipeline. Current data cleaning and data readiness assessment practices for machine learning tasks are mostly conducted in an arbitrary manner which limits their reuse and often results in loss of productivity. We introduce the concept of a Data Readiness Report as accompanying documentation to a dataset that allows data consumers to get detailed insights into the quality of data. Data characteristics and challenges on various quality dimensions are identified and documented, keeping in mind the principles of transparency and explainability. The Data Readiness Report also serves as a record of all data assessment operations, including applied transformations. This provides a detailed lineage for data governance and management. In effect, the report captures and documents the actions taken by various personas in a data readiness and assessment workflow. Over time this becomes a repository of best practices and can potentially drive a recommendation system for building automated data readiness workflows on the lines of AutoML [1]. The data readiness report could serve as a valuable asset for organizing and operationalizing data in a Data-as-a-service model as it augments the trust and reliability of the datasets. We anticipate that together with the Datasheets [2], Dataset Nutrition Label [3], FactSheets [4] and Model Cards [5], the Data Readiness Report completes the AI documentation pipeline and increases trust and re-useability of data. 2021 IEEE","Afzal, Shazia; Rajmohan, C.; Kesarwani, Manish; Mehta, Sameep; Patel, Hima",PO,score too low - 2,10.1109/SMDS53860.2021.00016,-,-,-,-,-,-,-,-,,-,-,7,2.0,2.0,1.0,0.0,0.0,2.0,0.0,1,1.0,0.0,-,
41,W2WNET: A two-module probabilistic Convolutional Neural Network with embedded data cleansing functionality,Academia,Expert Syst. Appl.,journalArticle,2021,"DC4ML, ML4DC",img,mislabel correction,"Convolutional Neural Networks (CNNs) are supposed to be fed with only high-quality annotated datasets. Nonetheless, in many real-world scenarios, such high quality is very hard to obtain, and datasets may be affected by any sort of image degradation and mislabelling issues. This negatively impacts the performance of standard CNNs, both during the training and the inference phase. To address this issue we propose Wise2WipedNet (W2WNet), a new two-module Convolutional Neural Network, where a Wise module exploits Bayesian inference to identify and discard spurious images during the training, and a Wiped module takes care of the final classification, while broadcasting information on the prediction confidence at inference time. The goodness of our solution is demonstrated on a number of public benchmarks addressing different image classification tasks, as well as on a real-world case study on histological image analysis. Overall, our experiments demonstrate that W2WNet is able to identify image degradation and mislabelling issues both at training and at inference time, with positive impact on the final classification accuracy.  2021, CC BY.","Ponzio, Francesco; Macii, Enrico; Ficarra, Elisa; Di Cataldo, Santa",PO,YES,,(1) baseline (i.e. CNN without cleansing capabilities) (2) a feature data cleaning approch and (3) a label data cleaning approch (see [2] [16] in paper),(1) MNIST (2) CIFAR10 (3) CRC,any,-,CNN,-,"better than compared approach, however, not significantly",(1) % of corrupted samples removed (2) % of clean samples removed (3) end-model performance,,,-,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,4,2.0,2.0,-,
42,Data cleansing for deep neural networks with storage-efficient approximation of influence functions,Industry,arxiv,journalArticle,2021,"DC4ML, ML4DC",img,mislabel correction,"Identifying the influence of training data for data cleansing can improve the accuracy of deep learning. An approach with stochastic gradient descent (SGD) called SGD-influence to calculate the influence scores was proposed, but, the calculation costs are expensive. It is necessary to temporally store the parameters of the model during training phase for inference phase to calculate influence sores. In close connection with the previous method, we propose a method to reduce cache files to store the parameters in training phase for calculating inference score. We only adopt the final parameters in last epoch for influence functions calculation. In our experiments on classification, the cache size of training using MNIST dataset with our approach is 1.236 MB. On the other hand, the previous method used cache size of 1.932 GB in last epoch. It means that cache size has been reduced to 1/1,563. We also observed the accuracy improvement by data cleansing with removal of negatively influential data using our approach as well as the previous method. Moreover, our simple and general proposed method to calculate influence scores is available on our auto ML tool without programing, Neural Network Console. The source code is also available.  2021, CC BY.","Suzuki, Kenji; Kobayashi, Yoshiyuki; Narihira, Takuya",PO,YES,,"(1) The approach they improved from, (2) no data cleaning, (3) random data cleaning","MNIST, CIFAR10",-,TODO: read on influence functions,?,Minor (~0.5%),"Compared to (1), requires 1,563 times less space",Improvement of a ML model,,,,11,2.0,2.0,1.0,2.0,0.0,2.0,2.0,4,2.0,2.0,,
43,Chef: A cheap and fast pipeline for iteratively cleaning label uncertainties,Academia,arxiv,journalArticle,2021,"DC4ML, ML4DC",any,mislabel correction,"High-quality labels are expensive to obtain for many machine learning tasks, such as medical image classification tasks. Therefore, probabilistic (weak) labels produced by weak supervision tools are used to seed a process in which influential samples with weak labels are identified and cleaned by several human annotators to improve the model performance. To lower the overall cost and computational overhead of this process, we propose a solution called Chef (CHEap and Fast label cleaning), which consists of the following three components. First, to reduce the cost of human annotators, we use Infl, which prioritizes the most influential training samples for cleaning and provides cleaned labels to save the cost of one human annotator. Second, to accelerate the sample selector phase and the model constructor phase, we use Increm-Infl to incrementally produce influential samples, and DeltaGrad-L to incrementally update the model. Third, we redesign the typical label cleaning pipeline so that human annotators iteratively clean smaller batch of samples rather than one big batch of samples. This yields better overall model performance and enables possible early termination when the expected model performance has been achieved. Extensive experiments show that our approach gives good model prediction performance while achieving significant speed-ups. Copyright  2021, The Authors. All rights reserved.","Wu, Yinjun; Weimer, James; Davidson, Susan B.",PO,YES,,"(1) Other versions of influence functions: INFL-D, INFL-Y; (2) Active learning methods: least-confidence based and entropy based; (3) Mislabel detection approaches: O2U and TARS","(1) Fully cleaned datasets: MIMIC-CXR-JPG (MIMIC for short) [19], Chexpert [17] and Diabetic Retinopathy Detection (2) Crowdsourced datasets: Fashion 10000 (Fashion for short)1 [24], Fact Evaluation Judgement (Fact for short)2 , and Twitter sentiment analysis (Twitter for short)",mislabels,-,"models satisfying 𝜇−strong convexity, such as logisitc regression with regression. Note it is possible to use a pretrained deep learning method to transform the dataset if we do not train that NN.",Slightly better performances. The cleaning methods which use the labels suggested by their implementation of influence functions are surprisingly the best.,Open up for details,End-model accuracy,,,Very well written paper.,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,2.0,0.0,https://github.com/thuwuyinjun/Chef,
44,Active label cleaning for improved dataset quality under resource constraints,Both,Nature communications,journalArticle,2021,"DC4ML, ML4DC",img,mislabel correction,"Imperfections in data annotation, known as label noise, are detrimental to the training of machine learning models and have a confounding effect on the assessment of model performance. Nevertheless, employing experts to remove label noise by fully re-annotating large datasets is infeasible in resource-constrained settings, such as healthcare. This work advocates for a data-driven approach to prioritising samples for re-annotation-which we term ""active label cleaning"". We propose to rank instances according to estimated label correctness and labelling difficulty of each sample, and introduce a simulation framework to evaluate relabelling efficacy. Our experiments on natural images and on a new medical imaging benchmark show that cleaning noisy labels mitigates their negative impact on model training, evaluation, and selection. Crucially, the proposed approach enables correcting labels up to 4 more effectively than typical random selection in realistic conditions, making better use of experts' valuable time for improving dataset quality.  2021, CC BY.","Bernhardt, Melanie; Castro, Daniel C.; Tanno, Ryutaro; Schwaighofer, Anton; Tezcan, Kerem C.; Monteiro, Miguel; Bannur, Shruthi; Lungren, Matthew P.; Nori, Aditya; Glocker, Ben; Alvarez-Valle, Javier; Oktay, Ozan",PO,YES,,(1) random selector (2) oracle,(1) NoisyCXR (2) CIFAR10H,mislabels,"(1) “A limitation of data-driven approaches for handling label
noise is that they may still be able to learn from noise patterns
in the data when label errors occur in a consistent manner”
(2) “Under extreme conditions where
the bounded noise rate assumption may not hold (i.e. where on
average there are more incorrect labels than correct in a given
dataset), random selection can become preferable over data-
driven approaches”",RobustML techniques with NNs,“4× more effectively than typical random selection in realistic conditions”,-,percentage of clean labels in the dataset,,,nature papers are so unstructured,11,2.0,2.0,1.0,2.0,2.0,1.0,1.0,4,2.0,2.0,https://github.com/microsoft/InnerEye-DeepLearning/tree/1606729c7a16e1bfeb269694314212b6e2737939/InnerEye-DataQuality,
45,"Automated cleanup of the imagenet dataset by model consensus, explainability and confident learning",,,journalArticle,2021,"DC4ML, ML4DC",img,mislabel correction,"The convolutional neural networks (CNNs) trained on ILSVRC12 ImageNet were the backbone of various applications as a generic classifier, a feature extractor or a base model for transfer learning. This paper describes automated heuristics based on model consensus, explainability and confident learning to correct labeling mistakes and remove ambiguous images from this dataset. After making these changes on the training and validation sets, the ImageNet-Clean improves the model performance by 2-2.4 % for SqueezeNet and EfficientNet-B0 models. The results support the importance of larger image corpora and semisupervised learning, but the original datasets must be fixed to avoid transmitting their mistakes and biases to the student learner. Further contributions describe the training impacts of widescreen input resolutions in portrait and landscape orientations. The trained models and scripts are published on Github (https://github.com/kecsap/imagenetclean) to clean up ImageNet and ImageNetV2 datasets for reproducible research.  2021, CC BY.","Kertesz, Csaba",PO,score too low,,,,,,,,,,,,,6,2.0,1.0,1.0,1.0,1.0,0.0,0.0,0,,,,
46,Cost-effective variational active entity resolution,Both,IEEE ICDE,conferencePaper,2021,ML4DC,tabular,entity matching / duplicate removal,"Accurately identifying different representations of the same real-world entity is an integral part of data cleaning and many methods have been proposed to accomplish it. The challenges of this entity resolution task that demand so much research attention are often rooted in the task-specificity and user-dependence of the process. Adopting deep learning techniques has the potential to lessen these challenges. In this paper, we set out to devise an entity resolution method that builds on the robustness conferred by deep autoencoders to reduce human-involvement costs. Specifically, we reduce the cost of training deep entity resolution models by performing unsupervised representation learning. This unveils a transferability property of the resulting model that can further reduce the cost of applying the approach to new datasets by means of transfer learning. Finally, we reduce the cost of labeling training data through an active learning approach that builds on the properties conferred by the use of deep autoencoders. Empirical evaluation confirms the accomplishment of our cost-reduction desideratum, while achieving comparable effectiveness with state-of-the-art alternatives.  2021 IEEE.","Bogatu, Alex; Paton, Norman W.; Douthwaite, Mark; Davie, Stuart; Freitas, Andre",PO,YES,10.1109/ICDE51399.2021.00114,(1) DeepER (2) DeepMatcher (3) DITTO,(1) Restaurants (2) Citations 1 (3) Citations 2 (3) Cosmetics (4) Software (5) Music (6) Beer (7) Stocks (private) (8) CRM (private),duplicates,-,VAE and NN,(1) F1 (2) Precision (3) Recall,Better than compared approaches,,,,-,10,2.0,2.0,2.0,2.0,0.0,1.0,1.0,2,0.0,2.0,-,
47,A probabilistic database approach to autoencoder-based data cleaning,Academia,arxiv,journalArticle,2021,"DC4ML, DC4ML - intro only, ML4DC",tabular,error detection/repair,"Data quality problems are a large threat in data science. In this paper, we propose a data-cleaning autoencoder capable of near-automatic data quality improvement. It learns the structure and dependencies in the data and uses it as evidence to identify and correct doubtful values. We apply a probabilistic database approach to represent weak and strong evidence for attribute value repairs. A theoretical framework is provided, and experiments show that it can remove significant amounts of noise (i.e., data quality problems) from categorical and numeric probabilistic data. Our method does not require clean data. We do, however, show that manually cleaning a small fraction of the data significantly improves performance. Copyright  2021, The Authors. All rights reserved.","Mauritz, R.R.; Nijweide, F.P.J.; Goseling, J.; van Keulen, M.",PO,YES,,-,(1) synthetic data set crated with a Bayesian Network and (2) unnamed data sets on surgeries  conducted at a hospital and chronic pain questionnaire; available https://zenodo.org/record/5136612#.YsMBotLMLl0,,(1) The model only ingest probabilistic data; data whose attributes are distributed along many values (effectively creating a probability distribution) (2) No idea how it performs on real world data (3) They created dirty data by adding Gaussian noise to the input data. I highly doubt this is representative of real world data (they operate on categorical data).,auto-encoder,"(1) On synthetic data: too many measures to report them all, consult the paper. Notably, they achieve up to 50% quality improvement on varying amount of noise in the semi-supervised setting (2) On real world data: none. They did not had a real data set with ground truth values.",-,(1) To measure the quality of a data set: Jensen-Shannon divergence between the ground truth data and the cleaned one; (2) to measure the improvement of the cleaning algo: the quotient of the JD of dirty data and cleaned data.,,,,13,2.0,2.0,2.0,2.0,1.0,2.0,2.0,4,2.0,2.0,,
48,Research on Error Label Screening Method Based on Convolutional Neural Network,Academia,IEEE International Conference on Signal and Image Processing,conferencePaper,2021,"DC4ML, ML4DC",img,mislabel correction,"Supervised learning methods require a large number of labeled image data sets, but a large number of labeled image data sets are difficult to obtain in many practical applications, so it is necessary to develop weakly supervised learning methods. There is no good method for cleaning existing data sets containing false images that can simultaneously filter images with label noise and background noise. This paper presents a new method to solve the problem of image with label noise and background noise in weakly supervised learning, which can clean the wrong image with label noise and background noise. We first used the existing neural network VGG16_BN to extract the features of the image and delete the full connection layer. Then we added an error image automatic screening module to filter out the poor quality images and possible wrong images in priority. The images screened in this part include images with 40%-60% label noise and background noise. It can effectively reduce the screening range of the wrong image. We verified the effectiveness of the proposed method in the dataset of cat and dog dichoromy in the public dataset. We screened and determined that the dataset contained about 0.8% error images, and designed 200 error images to be screened by the proposed method. Finally, 186 designed error labels were screened out, which verified the effectiveness of the proposed method.  2021 IEEE.","Li, Zhengwen; Du, Wenju; Rao, Nini",,YES,10.1109/ICSIP52628.2021.9688888,"None
The paper claims they improved the accuracy of the network VGG16BN and achieved faster training, but they did not reported the VGG16BN results",images of cats and dogs from 2013 Kaggle contest ,"Label noise (mislabeled)
Background noise (poor quality)",,CNN,"screening error rate= 1.4%
screening accuracy = 53.6%
recall rate = 93%",,"* FER (screening error rate): percentage of the number of potentially wrong images (MW) screened to ALL images (ALL) contained in the
total data set
* PRE (screening accuracy): percentage true error images (TW) among all possible error images (MW) screened out
* PEC (screening recall rate): percentage of the screened true error images (TW) in all the true error images (ATW) in the data set.
",,,"Poor writing, shallow evaluation and not compared to any other approach
",8,2.0,1.0,1.0,2.0,0.0,1.0,1.0,2,1.0,1.0,,
49,IGAEM: Improved Genetic Algorithm based Entity Matching,Academia,Journal of Physics: Conference Series,conferencePaper,2021,ML4DC,tabular,entity matching / duplicate removal,"The presence of duplicate records is a major data quality concern in huge datasets. To detect duplicates, entity matching is used as an essential step of the data cleaning process to map records that refer to the same real-world entity. Most of proposed algorithms require labeled data in order to train a classifier. However, we cannot always obtain labeled data. In our paper we propose an unsupervised approach for entity matching problem using an improved version of genetic algorithm. We explain the main improvements added to genetic algorithm and the encoding strategy to encode partitions in the form of a chromosome. Different similarity functions are used to compute similarities between records. The obtained results prove that our proposition stands as a powerful approach in the entity matching field where it outperforms the traditional genetic algorithm based approach.  Published under licence by IOP Publishing Ltd.","Aassem, Y.; Hafidi, I.; Aboutabit, N.",Dima,score too low - 3,10.1088/1742-6596/1743/1/012001,,Restaurant and DBLP-ACM,,,,,,,NO,,Bad paper with a lot of typos,2,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1,1.0,0.0,,
50,Interactive label cleaning with example-based explanations,Academia,NeurIPS,journalArticle,2021,"DC4ML, ML4DC",any,mislabel correction,"We tackle sequential learning under label noise in applications where a human supervisor can be queried to relabel suspicious examples. Existing approaches are flawed, in that they only relabel incoming examples that look ""suspicious"" to the model. As a consequence, those mislabeled examples that elude (or don't undergo) this cleaning step end up tainting the training data and the model with no further chance of being cleaned. We propose CINCER, a novel approach that cleans both new and past data by identifying pairs of mutually incompatible examples. Whenever it detects a suspicious example, CINCER identifies a counter-example in the training set that-according to the model-is maximally incompatible with the suspicious example, and asks the annotator to relabel either or both examples, resolving this possible inconsistency. The counter-examples are chosen to be maximally incompatible, so to serve as explanations of the model's suspicion, and highly influential, so to convey as much information as possible if relabeled. CINCER achieves this by leveraging an efficient and robust approximation of influence functions based on the Fisher information matrix (FIM). Our extensive empirical evaluation shows that clarifying the reasons behind the model's suspicions by cleaning the counter-examples helps in acquiring substantially better data and models, especially when paired with our FIM approximation. Copyright  2021, The Authors. All rights reserved.","Teso, Stefano; Bontempelli, Andrea; Giunchiglia, Fausto; Passerini, Andrea",PO,YES,,"depends on the experiment, both the most relevant: (1) without counter-examples and (2) without human labeler (i.e. drop sample)",(1) Adult (2) Breast (3) 20NG (4) MNIST (5) Fashion,mislabels,only models with cross-entropy loss,(1) logistic regression (2) feed-forward neural network (3) CNN,"better, see graphs",-,(1) nb of cleaned samples vs number of considered samples (2) end model f1 score,,,-,14,2.0,2.0,2.0,2.0,2.0,2.0,2.0,4,2.0,2.0,https://github.com/abonte/cincer,
51,A supervised learning approach for detecting erroneoussamples in embeddings,,,journalArticle,2020,,,,"… In this work, we propose an error detection algorithm for dimensionality reduction algorithms based on recently developed error prediction algorithms for medical image registration. The …","Saygili, G",,exclusion criteria last step,,,,,,,,,,,PX69SA2G,,0,,,,,,,,0,,,,
52,Grammatical Error Detection with Self Attention by Pairwise Training,Academia,International Joint Conference on Neural Networks (IJCNN),journalArticle,2020,ML4DC,text,error detection/repair,"… -supervised with large unlabeled corpus are popular used in many NLP problems. The current state of the art models for text error detection … investigated for error detection, methods …","Wang, Q; Tan, Y",,YES,10.1109/IJCNN48605.2020.9206715,"(1) sequence labelling task
(2) Bi-LSTM
(3) a model using artificially generated data 
(4) BERT-Base
(5) BERT-Large","for training: 
(i) NUCLE
(ii) Lang-8
(iii) FCE
(iv) Synthetic
for testing:
(i) CoNLL-2014
(ii) JHU FLuency-Extended GUG corpus (JFLEG)
(iii) First Certificate in English (FCE) test set",Grammatical,,6 layers of BERT model and utilizing pairwise training,The proposed model outperforms all other compared models especially after filtering poor-quality synthetic data and using pair wise training ,-,"Precision
Recall
F0.5",,D5SRAPE4,,8,1.0,1.0,2.0,1.0,0.0,2.0,1.0,2,0.0,2.0,,
53,Dfr: Deep feature reconstruction for unsupervised anomaly segmentation,,,journalArticle,2020,ML4DC,img,error detection/repair,"… This paper proposes an effective unsupervised anomaly segmentation approach that can … Ulrich, “Real-time texture error detection on textured surfaces with compressed sensing,” …","Yang, J; Shi, Y; Qi, Z",PO,score too low - 2,,,,,,,,,,,QTQG94DB,,0,,,,,,,,0,0.0,0.0,,
54,MalJPEG: Machine Learning Based Solution for the Detection of Malicious JPEG Images,,,journalArticle,2020,,img,,"In recent years, cyber-attacks against individuals, businesses, and organizations have increased. Cyber criminals are always looking for effective vectors to deliver malware to victims in order to launch an attack. Images are used on a daily basis by millions of people around the world, and most users consider images to be safe for use; however, some types of images can contain a malicious payload and perform harmful actions. JPEG is the most popular image format, primarily due to its lossy compression. It is used by almost everyone, from individuals to large organizations, and can be found on almost every device (on digital cameras and smartphones, websites, social media, etc.). Because of their harmless reputation, massive use, and high potential for misuse, JPEG images are used by cyber criminals as an attack vector. While machine learning methods have been shown to be effective at detecting known and unknown malware in various domains, to the best of our knowledge, machine learning methods have not been used particularly for the detection of malicious JPEG images. In this paper, we present MalJPEG, the first machine learning-based solution tailored specifically at the efficient detection of unknown malicious JPEG images. MalJPEG statically extracts 10 simple yet discriminative features from the JPEG file structure and leverages them with a machine learning classifier, in order to discriminate between benign and malicious JPEG images. We evaluated MalJPEG extensively on a real-world representative collection of 156,818 images which contains 155,013 (98.85%) benign and 1,805 (1.15%) malicious images. The results show that MalJPEG, when used with the LightGBM classifier, demonstrates the highest detection capabilities, with an area under the receiver operating characteristic curve (AUC) of 0.997, true positive rate (TPR) of 0.951, and a very low false positive rate (FPR) of 0.004.  2020 IEEE.","Cohen, Aviad; Nissim, Nir; Elovici, Yuval",,score too low - 4,10.1109/ACCESS.2020.2969022,,,,,,,,,,FZ489MI2,,0,,,,,,,,0,0.0,0.0,,
55,Language modeling in speech recognition for grammatical error detection based on neural machine translation,,,journalArticle,2020,,,,"… application of deep learning, a large number of research studies on deep neural network (DNN)… Finally, we analyze the performance of the proposed LM in grammatical error detection (…","Fu, J; Chiba, Y; Nose, T; Ito, A",,exclusion criteria last step,,,,,,,,,,,SUA4MQQ5,,0,,,,,,,,0,,,,
56,Time Series Data Cleaning Based on Dynamic Speed Constraints,,,journalArticle,2020,DC4ML,tabular,error detection/repair,"… change, the existing data cleaning algorithms based on … other machine learning techniques like the popular deep learning [5… our approach to conduct data cleaning online while holding …","Ding, G; Li, C; Wei, R; Sun, S; Liu, Z; Fan, C",PO,Not accessible,10.1007/978-3-030-62008-0_33,,,,,,,,,,5TMQIBKX,,0,,,,,,,,0,,,,
57,An Automated Data Pre-processing Technique for Machine Learning in Critical Systems,,,journalArticle,2020,ML4DC,tabular,more-than-one,"In this paper, we propose the use of intelligent data cleaning techniques as opposed to traditional deterministic methods. It is shown in this paper that the use of machine learning techniques to clean data, particularly as used for filling-in missing data, improves the quality of subsequent data analysis. The results obtained in the comparative study indicate that the use of machine learning techniques, such as BOSOM and Kmeans clustering, in data preparation, increases the quality of subsequent data analysis. The quality of data analysis was measured using performance metrics such as the Cross-Entropy loss and the Mean Square Error","Madyembwa, M; Mzelikahle, K; ...",Dima,score too low,,"Fill by means, k-means clustering, linear regression, multivariate linear regression, BOSOSM clustering","The data is flight-level data from the US Department of Transportation, Bureau of Transportation Statistics.  Each of the seven (7) datasets is a single
file for each month of interest that includes various carries’ logs. The period covered by the datasets runs from January to July of 2018 ",,Not indicated.,"Use an unsupervised learning technique to cluster data into its inherent clusters for each property. In this study, the unsupervised learning technique of choice is the Bat Optimised Self Organised Map (BOSOM). Use auto-regression to fill-in missing data elements for each property based on each cluster obtained.",only evaluating the accuracy of the model trained on the cleaned dataset,only evaluating the accuracy of the model trained on the cleaned dataset,"The Mean Square Error (MSE) metric was used to calculate the performance of each subsequent technique on a given dataset, for each data cleaning method. Another metric used for assessing the relative performance of data analysis techniques is the Cross-Entropy (CE) loss metric. In this case, the CE loss is used to measure the rate of loss of predicted data elements based on varying data cleaning techniques used.",,Q2I895AM,Very poorly written article. We can’t include it to the review.,4,1.0,1.0,0.0,0.0,0.0,1.0,1.0,2,1.0,1.0,,
58,GraphER: Token-centric entity resolution with graph convolutional neural networks,Academia,AAAI,conferencePaper,2020,ML4DC,tabular,entity matching / duplicate removal,"Entity resolution (ER) aims to identify entity records that refer to the same real-world entity, which is a critical problem in data cleaning and integration. Most of the existing models are attribute-centric, that is, matching entity pairs by comparing similarities of pre-aligned attributes, which require the schemas of records to be identical and are too coarse-grained to capture subtle key information within a single attribute. In this paper, we propose a novel graph-based ER model GraphER. Our model is token-centric: the final matching results are generated by directly aggregating token-level comparison features, in which both the semantic and structural information has been softly embedded into token embeddings by training an Entity Record Graph Convolutional Network (ER-GCN). To the best of our knowledge, our work is the first effort to do token-centric entity resolution with the help of GCN in entity resolution task. Extensive experiments on two real-world datasets demonstrate that our model stably outperforms state-of-the-art models. Copyright  2020, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.","Li, Bing; Wang, Wei; Sun, Yifang; Zhang, Linhan; Ali, Muhammad Asif; Wang, Yi",PO,YES,,"(1) Magellan (2) RNN (Mudgal et al. 2018), (3) Hybrid (Mudgal et al.
2018)",(1) Amazon-Google (2) BeerAdvo-RateBeer,duplicates,-,open up for details,above compared approches,-,precision recall f1-score of detected matches,,BTIGMQDZ,-,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,4,2.0,2.0,https://github.com/windofshadow/GraphER,
59,Tomographic Auto-Encoder: Unsupervised Bayesian Recovery of Corrupted Data,Both,arxiv,journalArticle,2020,ML4DC,img,error detection/repair,"… Traditional data cleaning methods rely on some degree of … in recent years, makes any supervised algorithm impractical in the … to perform automated data cleaning and recovery without …","Tonolini, F; Moreno, PG; Damianou, A; ...",PO,YES,,(1) missing value imputation VAE (MVAE) (2) missing values importance weighted auto encoder (MIWAE),"MNIST (image), Fashion-MNIST (image), UCI HAR (tabular), NYU depth maps (image)","noise, missing value",-,modified VAE (they named it TAE),generally better,-,(1) peak signal to noise ratio (PSNR) for image reconstruction quality and (2) end model accuracy,,34QB87SI,"(1) very mathy, I did not fully understood their approach (2) they have data leaks in their experiments (3) I am not sure whether we should include it in our SLR, if yes, perform snowballing",11,2.0,2.0,1.0,2.0,0.0,2.0,2.0,4,2.0,2.0,-,
60,Training-ValueNet: A new approach for label cleaning on weakly-supervised datasets,Academia,IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob),conferencePaper,2020,ML4DC,img,mislabel correction,… supervised label cleaning and outlier detection. Let us now briefly examine each approach in turn. Semi-supervised label cleaning … partial automation of the label cleaning process. The …,"Smyth, L",PO,YES,,(1) semi-supervised methods and (2) unsupervised methods. See paper for the full list.,(1) Clothing 1M (2) Aircraft-7 ,mislabels,-,Training ValueNet is a MLP with one hidden layer. They use different CNNs for feature extraction. Read paper for more details.,Better than unsupervised methods but worse than semi-supervised ones. Their method is an unsupervised one (it can be semi-supervised if we provide a clean label set),-,(1) accuracy of error detection (2) improvement of the end model,,U3FCC77F,"Clear, short and sweet. the perfect paper.",12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,4,2.0,2.0,-,
61,A Comprehensive Benchmark Framework for Active Learning Methods in Entity Matching,Both,ACM SIGMOD,journalArticle,2020,ML4DC,tabular,entity matching / duplicate removal,"Entity Matching (EM) is a core data cleaning task, aiming to identify different mentions of the same real-world entity. Active learning is one way to address the challenge of scarce labeled data in practice, by dynamically collecting the necessary examples to be labeled by an Oracle and refining the learned model (classifier) upon them. In this paper, we build a unified active learning benchmark framework for EM that allows users to easily combine different learning algorithms with applicable example selection algorithms. The goal of the framework is to enable concrete guidelines for practitioners as to what active learning combinations will work well for EM. Towards this, we perform comprehensive experiments on publicly available EM datasets from product and publication domains to evaluate active learning methods, using a variety of metrics including EM quality, #labels and example selection latencies. Our most surprising result finds that active learning with fewer labels can learn a classifier of comparable quality as supervised learning. In fact, for several of the datasets, we show that there is an active learning combination that beats the state-of-the-art supervised learning result. Our framework also includes novel optimizations that improve the quality of the learned model by roughly 9% in terms of F1-score and reduce example selection latencies by up to 10 without affecting the quality of the model. Copyright  2020, The Authors. All rights reserved.","Meduri, Vamsi; Popa, Lucian; Sen, Prithviraj; Sarwat, Mohamed",PO,YES,,Open page,(1) Abt-Buy (2) Amazon-GoogleProducts (3) DBLP-ACM (4) DBLP-Scholar (5) Cora (6) Walmart-Amazon (7) Amazon-BestBuy (8) BeerAdvocate-RateBeer (9) BuyBuyBaby-BabiesRUs,-,-,-,-,-,See paper. F1-score,,78EGLADL,-,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,0.0,2.0,-,
62,A flexible outlier detector based on a topology given by graph communities,Academia,Big Data Research,journalArticle,2020,DC4ML,tabular,outliers detection,"Outlier, or anomaly, detection is essential for optimal performance of machine learning methods and statistical predictive models. It is not just a technical step in a data cleaning process but a key topic in many fields such as fraudulent document detection, in medical applications and assisted diagnosis systems or detecting security threats. In contrast to population-based methods, neighborhood based local approaches are simple flexible methods that have the potential to perform well in small sample size unbalanced problems. However, a main concern of local approaches is the impact that the computation of each sample neighborhood has on the method performance. Most approaches use a distance in the feature space to define a single neighborhood that requires careful selection of several parameters. This work presents a local approach based on a local measure of the heterogeneity of sample labels in the feature space considered as a topological manifold. Topology is computed using the communities of a weighted graph codifying mutual nearest neighbors in the feature space. This way, we provide with a set of multiple neighborhoods able to describe the structure of complex spaces without parameter fine tuning. The extensive experiments on real-world data sets show that our approach overall outperforms, both, local and global strategies in multi and single view settings. Copyright  2020, The Authors. All rights reserved.","Ramos Terrades, O.; Berenguel, A.; Gil, D.",PO,YES,,"LOF, LOCI, KNN, IF, APS, GMM, SO-GAAL",(1) Iris (2) BCW (3) Ionosphere (4) Letter recognition,-,-,SVM,top 2 approaches in every dataset,-,AUC of detected outliers,,4ECQI72R,a preprint,11,2.0,2.0,1.0,2.0,0.0,2.0,2.0,2,1.0,1.0,-,
63,An Adaptive Parameters Density Cluster Algorithm for Data Cleaning in Big Data,,,conferencePaper,2020,,,,"We have entered the era of information explosion, data has become an important driving force for the development of the industry. The huge wealth hidden in the data, enterprises can obtain a lot of useful information from business management, market analysis, scientific exploration and other aspects to support the development decisions of enterprises. However, the actual data is often intricate with different structures and types such as erroneous data, invalid data and missing duplicate data, greatly increase the difficulty of data analysis. These dirty data can greatly affect the results of data analysis, resulting in inaccurate results or even bad information. Most of the early data cleaning requires human involvement, however the exploding large-scale data is far from being able to meet with the human intervention, requiring smarter and more automated cleaning methods. The rapid development of artificial intelligence in recent years, the emergence of machine learning, provides a new opportunity for the development of data cleaning. Nowadays, there are lots of methods that have been applied to the field of data mining, including popular machine learning, deep learning, as well as classical clustering, bayesian networks, decision trees, and so on. Both provide a large number of solutions for our data cleaning. In this paper, we present a data cleaning method which use adaptive parameters density cluster algorithms based on the DBSCAN.  2020, Springer Nature Switzerland AG.","Zhang, Xiaopeng; Lin, Ruijie; Xu, Haitao",,Not accessible,10.1007/978-3-030-57884-8_48,,,,,,,,,,Z4U2L7FT,,0,,,,,,,,0,,,,
64,Autoencoder-based cleaning of non-categorical data in probabilistic databases,,,,2020,,,,"… better than in the unsupervised situation (for low sampling densities), and having only some of the data be labeled is more realistic than fully supervised learning, as data cleaning is not …","Nijweide, FPJ",,exclusion criteria last step,,,,,,,,,,,VE7TIIW5,,0,,,,,,,,0,,,,
65,Iterative label cleaning for transductive and semi-supervised few-shot learning,,,conferencePaper,2020,,,,"Few-shot learning amounts to learning representations and acquiring knowledge such that novel tasks may be solved with both supervision and data being limited. Improved performance is possible by transductive inference, where the entire test set is available concurrently, and semi-supervised learning, where more unlabeled data is available. These problems are closely related because there is little or no adaptation of the representation in novel tasks. Focusing on these two settings, we introduce a new algorithm that leverages the manifold structure of the labeled and unlabeled data distribution to predict pseudo-labels, while balancing over classes and using the loss value distribution of a limited-capacity classifier to select the cleanest labels, iterately improving the quality of pseudo-labels. Our solution sets new state of the art on four benchmark datasets, namely miniImageNet, tieredImageNet, CUB and CIFAR-FS, while being robust over feature space pre-processing and the quantity of available data. Copyright  2020, The Authors. All rights reserved.","Lazarou, Michalis; Avrithis, Yannis; Stathaki, Tania",,score too low - 4,,,,,,,,,,,WHS7IVTC,,0,,,,,,,,0,0.0,0.0,,
66,Data Repair without Prior Knowledge Using Deep Convolutional Neural Networks,,,journalArticle,2020,,,,"In recent years, the use of wireless sensor networks has become increasingly widespread. Because of the instability of wireless networks, packet loss occasionally occurs. To reduce the impact of packet loss on data integrity, we take advantage of the deep neural network's excellent ability to understand natural data and propose a data repair method based on a deep convolutional neural network with an encoder-decoder architecture. Compared with common interpolation algorithms and compressed sensing algorithms, this method obtains better repair results, is suitable for a wider range of applications, and does not need prior knowledge. This method adopts measures such as preparing training set data as well as the design and optimization of loss functions to achieve faster convergence speed, higher repair accuracy, and better stability. To fairly compare the repair performance of different signals, the mean squared error, relative peak-to-peak average error, and relative peak-to-peak max error are adopted to quantitatively evaluate the repair results of different signals. Comparative experiments prove that this method has better data recovery performance than traditional interpolation and compressed sensing algorithms.  2013 IEEE.","Qie, Youtian; Song, Ping; Hao, Chuangbo",PO,exclusion criteria last step,10.1109/ACCESS.2020.2999960,,,,,,,,,,39NJDAPJ,,0,,,,,,,,0,,,,
67,Detection of Anomalies in a Time Series Data using InfluxDB and Python,Academia,arxiv,journalArticle,2020,ML4DC,tabular,error detection/repair,"Analysis of water and environmental data is an important aspect of many intelligent water and environmental system applications where inference from such analysis plays a significant role in decision making. Quite often these data that are collected through sensible sensors can be anomalous due to different reasons such as systems breakdown, malfunctioning of sensor detectors, and more. Regardless of their root causes, such data severely affect the results of the subsequent analysis. This paper demonstrates data cleaning and preparation for time-series data and further proposes cost-sensitive machine learning algorithms as a solution to detect anomalous data points in a time-series data. The following models: Logistic Regression, Random Forest, Support Vector Machines have been modified to support the cost-sensitive learning which penalizes misclassified samples thereby minimizing the total misclassification cost. Our results showed that Random Forest outperformed the rest of the models at predicting the positive class (i.e anomalies). Applying predictive model improvement techniques like data oversampling seem to provide little or no improvement to the Random Forest model. Interestingly, with recursive feature elimination we achieved a better model performance thereby reducing the dimensions in the data. Finally, with Influxdb and Kapacitor the data was ingested and streamed to generate new data points to further evaluate the model performance on unseen data, this will allow for early recognition of undesirable changes in the drinking water quality and will enable the water supply companies to rectify on a timely basis whatever undesirable changes abound.  2020, CC BY.","John, Anih T.; Amadi, Bede Chika; Umeokpala, Festus Chima",Dima,score too low - 3,,,The data that was used for this research has been measured at different stations near the outflow of a designated waterworks.,,It is not at all clear how the models were trained. No literature review!,"Logistic Regression, Support Vector Machines, and Random Forest",,,"F0.5 score, F1 score",NO,JRS4I99U,Very poorly written article,1,0.0,0.0,1.0,0.0,0.0,0.0,0.0,2,1.0,1.0,,
68,Identifying label noise in time-series datasets,Academia,UBICOMP,journalArticle,2020,,tabular,mislabel correction,,"Atkinson, Gentry; Metsis, Vangelis",PO,YES,,-,(1) Sussex-HuaWei 1 (2) Sussex-HuaWei 2 (3) UniMiB SHAR 1 (4) UniMib SHAR 2,mislabel,-,CNN,-,-,Performance of the end-model,,3B2EN9RI,-,7,2.0,2.0,0.0,1.0,0.0,1.0,1.0,4,2.0,2.0,-,
69,Characterizing label errors: Confident learning for noisy-labeled image segmentation,,,journalArticle,2020,ML4DC,img,mislabel correction,"Convolutional neural networks (CNNs) have achieved remarkable performance in image processing for its mighty capability to fit huge amount of data. However, if the training data are corrupted by noisy labels, the resulting performance might be deteriorated. In the domain of medical image analysis, this dilemma becomes extremely severe. This is because the medical image annotation always requires medical expertise and clinical experience, which would inevitably introduce subjectivity. In this paper, we design a novel algorithm based on the teacher-student architecture for noisy-labeled medical image segmentation. Creatively, We introduce confident learning (CL) method to identify the corrupted labels and endow CNN an anti-interference ability to the noises. Specifically, the CL technique is introduced to the teacher model to characterize the suspected wrong-labeled pixels. Since the noise identification maps are a little away from sufficient precision, the spatial label smoothing regularization technique is utilized to generate soft-corrected masks for training the student model. Since our method identifies and revises the noisy labels of the training data in a pixel-level rather than simply assigns lower weights to the noisy masks, it outperforms the state-of-the-art method in the noisy-labeled image segmentation task on the JSRT dataset, especially when the training data are severely corrupted by noises.  Springer Nature Switzerland AG 2020.","Zhang, Minqing; Gao, Jiantao; Lyu, Zhen; Zhao, Weibing; Wang, Qin; Ding, Weizhen; Wang, Sheng; Li, Zhen; Cui, Shuguang",PO,Not accessible,10.1007/978-3-030-59710-8_70,,,,,,,,,,TUYFN2N9,,0,,,,,,,,0,,,,
70,Time series data cleaning: From anomaly detection to anomaly repairing (technical report),Academia,arxiv,journalArticle,2020,"DC4ML, ML4DC",tabular,error detection/repair,"Errors are prevalent in time series data, such as GPS trajectories or sensor readings. Existing methods focus more on anomaly detection but not on repairing the detected anomalies. By simply filtering out the dirty data via anomaly detection, applications could still be unreliable over the incomplete time series. Instead of simply discarding anomalies, we propose to (iteratively) repair them in time series data, by creatively bonding the beauty of temporal nature in anomaly detection with the widely considered minimum change principle in data repairing. Our major contributions include: (1) a novel framework of iterative minimum repairing (IMR) over time series data, (2) explicit analysis on convergence of the proposed iterative minimum repairing, and (3) efficient estimation of parameters in each iteration. Remarkably, with incremental computation, we reduce the complexity of parameter estimation from O(n) to O(1). Experiments on real datasets demonstrate the superiority of our proposal compared to the state-of-the-art approaches. In particular, we show that (the proposed) repairing indeed improves the time series classification application. Copyright  2020, The Authors. All rights reserved.","Zhang, Aoqian; Song, Shaoxu; Wang, Jianmin; Yu, Philip S.",PO,YES,,(1) AR (2) ARX (3) ARIMA (4) Tsay models (5) EWMA (6) SCREEN,(1) GPS dataset (the collection of the position of a person walking on a known path) (2) Intel Lab Data (a collection of measurements taken from 54 sensors),"Noise on scalar data, missing values",(1) They tested their approach only in scenario without features (only the timestamp),Linear regression,Generally superior to compared approaches,Higher than other techniques because of the iterative approach,RMS (we are doing regression rather than classification),,,,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,2.0,0.0,,
71,PClean: Bayesian data cleaning at scale with domain-specific probabilistic programming,Academia,Proceedings of Machine Learning Research,journalArticle,2020,ML4DC,tabular,error repair,"Data cleaning is naturally framed as probabilistic inference in a generative model, combining a prior distribution over ground-truth databases with a likelihood that models the noisy channel by which the data are filtered, corrupted, and joined to yield incomplete, dirty, and denormalized datasets. Based on this view, we present PClean, a unified generative modeling architecture for cleaning and normalizing dirty data in diverse domains. Given an unclean dataset and a probabilistic program encoding relevant domain knowledge, PClean learns a structured representation of the data as a relational database of interrelated objects, and uses this latent structure to impute missing values, identify duplicates, detect errors, and propose corrections in the original data table. PClean makes three modeling and inference contributions: (i) a domain-general non-parametric generative model of relational data, for inferring latent objects and their network of latent connections; (ii) a domain-specific probabilistic programming language, for encoding domain knowledge specific to each dataset being cleaned; and (iii) a domain-general inference engine that adapts to each PClean program by constructing data-driven proposals used in sequential Monte Carlo and particle Gibbs. We show empirically that short ( 50-line) PClean programs deliver higher accuracy than state-of-the-art data cleaning systems based on machine learning and weighted logic; that PCleans inference algorithm is faster than generic particle Gibbs inference for probabilistic programs; and that PClean scales to large real-world datasets with millions of rows. Copyright  2020, The Authors. All rights reserved.","Lew, Alexander K.; Agrawal, Monica; Sontag, David; Mansinghka, Vikash",Amin,YES,,"Holoclean, NADEEF","(1) Hospital (2) Flights (3) Rents, a synthetic dataset based on census statistics",-,(1) The user has to learn their programming language which is an extension of Julia and ,SMC and MCMC,Equal or better than other approaches,Generally equal or better than other approaches,Number of errors detected (F1 score),,,Though read,9,2.0,1.0,1.0,2.0,0.0,1.0,2.0,2,1.0,1.0,,
72,Batchwise probabilistic incremental data cleaning,Academia,arxiv,journalArticle,2020,"DC4ML, DC4ML - intro only, ML4DC",tabular,error detection/repair,"Lack of data and data quality issues are among the main bottlenecks that prevent further artificial intelligence adoption within many organizations, pushing data scientists to spend most of their time cleaning data before being able to answer analytical questions. Hence, there is a need for more effective and efficient data cleaning solutions, which, not surprisingly, is rife with theoretical and engineering problems. This report addresses the problem of performing holistic data cleaning incrementally, given a fixed rule set and an evolving categorical relational dataset acquired in sequential batches. To the best of our knowledge, our contributions compose the first incremental framework that cleans data (i) independently of user interventions, (ii) without requiring knowledge about the incoming dataset, such as the number of classes per attribute, and (iii) holistically, enabling multiple error types to be repaired simultaneously, and thus avoiding conflicting repairs. Extensive experiments show that our approach outperforms the competitors with respect to repair quality, execution time, and memory consumption. Copyright  2020, The Authors. All rights reserved.","Oliveira, Paulo H.; Traina-Jr, Caetano; Kaster, Daniel S.; Ilyas, Ihab F.",PO,YES,,(1) HC-Sep and (2) HC-Acc; open page for more details,(1) Hospital (2) Food (3) Soccer (corrupted with BART),See Holoclean: Holistic data repairs with probabilistic inference (https://www.notion.so/Holoclean-Holistic-data-repairs-with-probabilistic-inference-42f4c4def823491cb45e6c202ea38b43?pvs=21) ,-,See Holoclean: Holistic data repairs with probabilistic inference (https://www.notion.so/Holoclean-Holistic-data-repairs-with-probabilistic-inference-42f4c4def823491cb45e6c202ea38b43?pvs=21) ,iHC-Re performs almost the same (sometimes even better) than the approach that cleans the whole dataset at once (HC-Acc),Comparable to the approach that considers each batch separately (HC-Sep) in terms of memory and time.,(1) Number of remaining errors (as new batch of data come) (2) Total time (as new batches of data come) (3) Memory consumption (is it in total?),,,-,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,2.0,0.0,-,
73,Does data cleaning improve heart disease prediction?,Academia,Procedia Comput. Sci.,journalArticle,2020,"DC4ML, ML4DC",tabular,entity matching / duplicate removal,"Data quality has become an important issue. This issue becomes more and more important in medicine area, where the need for effective decision making is high. In this context, the need for data cleaning to improve data quality is becoming crucial. Duplicate records elimination is a challenging data cleansing task. In this paper, we present a duplicate records elimination approach to improve the quality of data. We propose a deep learning-based approach for duplicate records detection using a sentence embeddings model. Also, we propose an algorithm for duplicated records correction. Then, we apply the proposed duplicate records elimination approach to analyse the effect of data cleaning on the quality of decisions. We evaluate our proposal on heart disease problem using Cleveland heart disease dataset. Experiments show that the classification performance improves upon the application of the duplicate records elimination approach on datasets compared to that of datasets with duplicate records.  2020 The Authors. Published by Elsevier B.V.","Lattar, Hafsa; Salem, Aicha Ben; Ghezala, Henda Hajjami Ben",PO,YES,10.1016/j.procs.2020.09.109,-,Cleveland heart disease dataset (with noise artificially inserted),duplicates,-,SVM,-,-,(1) F1-score (2) precision (3) recall (4) accuracy,,,-,9,2.0,2.0,0.0,1.0,0.0,2.0,2.0,4,2.0,2.0,-,
74,CORDEL: A contrastive deep learning approach for entity linkage,Both,IEEE International Conference on Data Mining (ICDM),journalArticle,2020,ML4DC,tabular,entity matching / duplicate removal,"Entity linkage (EL) is a critical problem in data cleaning and integration. In the past several decades, EL has typically been done by rule-based systems or traditional machine learning models with hand-curated features, both of which heavily depend on manual human inputs. With the ever-increasing growth of new data, deep learning (DL) based approaches have been proposed to alleviate the high cost of EL associated with the traditional models. Existing exploration of DL models for EL strictly follows the well-known twin-network architecture. However, we argue that the twin-network architecture is sub-optimal to EL, leading to inherent drawbacks of existing models. In order to address the drawbacks, we propose a novel and generic contrastive DL framework for EL. The proposed framework is able to capture both syntactic and semantic matching signals and pays attention to subtle but critical differences. Based on the framework, we develop a contrastive DL approach for EL, called CORDEL, with three powerful variants. We evaluate CORDEL with extensive experiments conducted on both public benchmark datasets and a real-world dataset. CORDEL outperforms previous state-of-the-art models by 5.2% on public benchmark datasets. Moreover, CORDEL yields a 2.4% improvement over the current best DL model on the real-world dataset, while reducing the number of training parameters by 97.6%. Copyright  2020, The Authors. All rights reserved.","Wang, Zhengyang; Sisman, Bunyamin; Wei, Hao; Dong, Xin Luna; Ji, Shuiwang",PO,YES,,(1) non-DL baseline is Magellan (2) DL baseline is Deep Matcher (with 4 versions),"(1) Tabular: BeerAdvo-RateBeer, iTunes-Amazon1, Fodors-Zagats, DBLP-ACM, DBLP-Scholar, Amazon-Google, Walmart-Amazon (2) Textual: Abt-Buy (3) Dirty tabular: iTunes-Amazon, DBLP-ACM, DBLP-Scholar, Walmart-Amazon (4) Real-world (tabular): Amazon-Wikipedia",duplicates,-,"MLP, Attention, pre-trained embeddings","Generally significantly better, open up for more details",requires less parameters than DL baseline,"(1) Area Under the Precision-Recall Curve (PRAUC),  (2) Recall when
Precision=95% (R@P=95%),  (3) F1 score",,,pretty good paper,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,4,2.0,2.0,-,
75,ImageDC: Image Data Cleaning Framework Based on Deep Learning,,,conferencePaper,2020,"DC4ML, ML4DC",img,error detection/repair,"Although user-generated image data increases more and more quickly on the current Internet, many image methods have attracted widespread attention from industry and academia. Recently, some image classification approaches using deep learning have demonstrated that they can potentially enhance the accuracy of the classification based on the high quality datasets. However, the existing methods only consider the accuracy of the classification and ignore the quality of the datasets. To address these issues, we propose a new image data cleaning framework using deep neural networks, named ImageDC, to improve the quality of the datasets. ImageDC not only uses cleaning with the minority class to remove the images of the rarely classes, but also adopts cleaning with the low recognition rate to remove the noisy data to enhance the recognition rate of the datasets. Experimental results conducted on a variety of datasets demonstrate that our model significantly outperforms the whole approaches.  2020 IEEE.","Zhang, Yun; Jin, Zongze; Liu, Fan; Zhu, Weilin; Mu, Weimin; Wang, Weiping",PO,score too low,10.1109/ICAIIS49377.2020.9194803,,They seem to have scrapped images from Twitter,,Same limitations as Data Cleaning of Irrelevant Images Based on Transfer Learning (https://www.notion.so/Data-Cleaning-of-Irrelevant-Images-Based-on-Transfer-Learning-c73a8bedacc24fa79f9551bea63c545f?pvs=21) ,AlexNet and GoogLeNet,,33% increase in time if all data cleaning approaches are applied,2% accuracy improvement,,,,5,1.0,0.0,1.0,1.0,0.0,1.0,1.0,0,,,,
76,A novel data repairing approach based on constraints and ensemble learning,Academia,Expert Syst. Appl.,journalArticle,2020,ML4DC,tabular,error detection/repair,"Data repairing is an important task in data mining. This paper proposes a novel data repairing approach based on a combination of constraints and ensemble learning. At first, functional dependencies (FDs) are used as constraints to identify inconsistent records. For each FD, all repeated values in the correct records are discovered. After that, noisy attributes in erroneous records are detected using correct records and the repeated values. To correct the detected noises, a supervised ensemble learning model is constructed for each attribute. The ensemble model consists of a Bayes classifier, a decision tree, and a MultiLayer Perceptron (MLP). A majority of votes is used as the combination strategy in the ensemble learning model. The proposed approach automatically repairs data without any user interaction. Moreover, the proposed method can detect more than one noise in a record. Experimental results show that our approach outperforms similar repairing algorithms (HoloClean and KATARA) in both terms of precision and recall.  2020 Elsevier Ltd","Ataeyan, Mahdieh; Daneshpour, Negin",PO,YES,10.1016/j.eswa.2020.113511,(1) Holoclean (2) Katara,(1) Adult (2) Protein (3) Car (4) Wine,-,-,"(1) decision tree, (2) a Bayes classifier, (3) and an MLP.",Comparable to other approaches,-,(1) precision (2) recall (3) and other variations of TP and TN,,,"poor English, while the approach is really simple, they managed to make it convuluted",8,2.0,2.0,1.0,1.0,0.0,1.0,1.0,2,0.0,2.0,-,
77,Research on multi-source heterogeneous data cleaning technology based on integrating neural network with fuzzy rules for renewable energy accommodation,,,conferencePaper,2020,,,error detection/repair,"In order to avoid conservative results, when calculating the ability of power system to accommodate renewable energy, social data need to be integrated. Data cleaning is an important step in integration. Traditional data cleaning methods rely only on data and ignore the implicit rules. This paper first analyzes the data requirements for renewable energy accommodation, and then proposes a data cleaning technology. This technology digs out the implicit associations between data, converts them into fuzzy rules in the form of Probabilistic soft logic (PSL), and builds a neural network based on this for data cleaning.  2020 IEEE.","Sun, Rongfu; Wu, Yuhui; Lan, Haibo; Wang, Yulin; Ding, Ran; Xu, Jian; Liao, Siyang; Hu, Jia; Sun, Yamin",PO,exclusion criteria last step,10.1109/EI250167.2020.9346757,,,,,,,,,,,,0,,,,,,,,0,0.0,0.0,,
78,Advancing Data Curation with Metadata and Statistical Relational Learning / Verbesserung der Datenvorbereitung Mit Metadaten und Statistisch-Relationalem Lernen,Academia,proquest,thesis,2020,ML4DC,tabular,error detection,"The foundation of every data science project depends on clean data because the quality
of the data determines the quality of the insights derived from data by using machine
learning or analytics. In this dissertation, we tackle the problem of data cleaning and
provide three approaches to advance data error detection and repair: (1) We establish a
mapping that reflects the connection between data quality issues and extractable dataset’s
metadata, and propose this mapping as a guideline for rapid prototyping of an error
detection strategy; (2) We introduce two holistic approaches for effectively combining
different error detection strategies to increase the efficacy of error detection. Our methods
are based on state-of-the-art ensemble learning algorithms and incorporate the metadata
of the dataset; and (3) We propose an approach for addressing data quality issues by
formulating a set of data cleaning rules without the manual specification of the rules
execution order. The concepts of statistical relational learning and probabilistic inference
provide the foundation for our method. We use the Markov logic formalism, because it
declaratively models data quality rules as first-order logic sentences. Markov logic allows
the usage of probabilistic joint inference over data cleaning rules to detect data errors and
suggest a repair.","Visengeriyeva, Larysa",PO,YES,,,,,,,,,,,,,0,,,,,,,,0,,,,
79,Nearest neighbor classifiers over incomplete information: From certain answers to certain predictions,Both,arxiv,journalArticle,2020,"DC4ML, ML4DC",any,error detection/repair,"Machine learning (ML) applications have been thriving recently, largely attributed to the increasing availability of data. However, inconsistency and incomplete information are ubiquitous in real-world datasets, and their impact on ML applications remains elusive. In this paper, we present a formal study of this impact by extending the notion of Certain Answers for Codd tables, which has been explored by the database research community for decades, into the field of machine learning. Specifically, we focus on classification problems and propose the notion of ""Certain Predictions"" (CP) - a test data example can be certainly predicted (CP'ed) if all possible classifiers trained on top of all possible worlds induced by the incompleteness of data would yield the same prediction. We study two fundamental CP queries: (Q1) checking query that determines whether a data example can be CP'ed; and (Q2) counting query that computes the number of classifiers that support a particular prediction (i.e., label). Given that general solutions to CP queries are, not surprisingly, hard without assumption over the type of classifier, we further present a case study in the context of nearest neighbor (NN) classifiers, where efficient solutions to CP queries can be developed - we show that it is possible to answer both queries in linear or polynomial time over exponentially many possible worlds. We demonstrate one example use case of CP in the important application of ""data cleaning for machine learning (DC for ML)."" We show that our proposed CPClean approach built based on CP can often significantly outperform existing techniques in terms of classification accuracy with mild manual cleaning effort. Copyright  2020, The Authors. All rights reserved.","Karla, Bojan; Li, Peng; Wu, Renzhi; Gurel, Nezihe Merve; Chu, Xu; Wu, Wentao; Zhang, Ce",PO,YES,,"(1) ML model trained on the ground truth (cleaned dataset, serves as an upper bound), (2) Default cleaning (i.e. simple imputation techniques) (3) HoloClean (4) BoostClean (5) random manual cleaning","https://sites.google.com/site/anhaidgroup/projects/data (real errors, they manually created a cleaned version of it by imputing values by searching for the true values), Supreme, Bank, Puma (created a dirty version by removing values). Find the reference of the data sets in the paper.",Missing value,(1) limited to knn classifier and (2) finding the possible worlds is expensive,The model used to guide the cleaning process is knn,Managed to completely close the gap in most experiments.,"(1) To achieve 100% gap closed, not all the samples had to be cleaned. However, they managed between 40% to 100% gap closed with a limited budget of 20% of the instances manually cleaned. (2) Open this page on Notion for a formula of the time complexity of the algorithm to find next samples to clean","“Gap closed”: % of total improvement done, compared with the lower performance bound (i.e. compared approach #2) and the upper performance bound (i.e. compared approach #1)",,,,12,2.0,2.0,1.0,2.0,2.0,1.0,2.0,3,2.0,1.0,,
80,Similarity-learning information-fusion schemes for missing data imputation,Academia,Knowledge-Based Systems,journalArticle,2020,ML4DC,tabular,imputation,"Missing data imputation is a very important data cleaning task for machine learning and data mining with incomplete data. This paper proposes two novel methods for missing data imputation, named kEMI and kEMI+, that are based on the k-Nearest Neighbours algorithm for pre-imputation and the Expectation-Maximization algorithm for posterior-imputation. The former is a local search mechanism that aims to automatically find the best value for k and the latter makes use of the best k nearest neighbours to estimate missing scores by learning global similarities. kEMI+ makes use of a novel information fusion mechanism. It fuses top estimations through the Dempster-Shafer fusion module to obtain the final estimation. They handle both numerical and categorical features. The performance of the proposed imputation techniques are evaluated by applying them on twenty one publicly available datasets with different missingness and ratios, and, then, compared with other state-of-the-art missing data imputation techniques in terms of standard evaluation measures such as the normalized root mean square difference and the absolute error. The attained results indicate the effectiveness of the proposed novel missing data imputation techniques. [All rights reserved Elsevier].","Razavi-Far, R.; Boyuan Cheng; Saif, M.; Ahmadi, M.",,YES,10.1016/j.knosys.2019.06.013,"EMI 
DMI 
kDMI 
kNNI 
LCSR 
LRMC 
CLRMC
CLRMC-EN","21 publicly available dataset: 
BCW, BUPA, Dermatology, Glass, Ionosphere, Iris, Letter, PID, Sheart, Sonar, Spam, Wine, Yeast, Zoo, Car, House Votes, Promoters, SPECT, Splice, TTTEG",missing data (categorical and numerical imputation),although both KEMI and KEMI+ are more accurate compared to other methods their complexity is higher. Also KEMI+ is less scalable than KEMI,"two models:
KEMI based on KNNI and Expectation–Maximization based Imputation (EMI) algorithms
KEMI+ similar to KEMI but integrates an information fusion module (Dempster–Shafer Fusion (DSF))","According to Friedman rank test which compares NRMS: KEMI+ and KEMI have the first and second ranks and significantly outperforms the other methods; however, the difference in performance between KEMI and KEMI+ is not significant.","*complexity of KEMI and KEMI+ is similar :
O(m2k + m2d + mk2d′ + mk3 + kd2 + d3)
assuming d (attributes) << m (records) → O(m2k + mk3) 
assuming d << m AND k (best k values) << m → O(m2)
* has higher complexity compared to other methods especially KMI and KDMI (O(m)) and LRMC (O(tm)
*KEMI is more scalable than KEMI+ in terms of run time with increased dataset size (≥25k) or dimensions (≥200)","normalized root mean square difference (NRMS) 
absolute error (AE)
Friedman rank test",,,,12,2.0,2.0,2.0,2.0,1.0,1.0,2.0,2,0.0,2.0,,
81,An Adaptive Parameters Density Cluster Algorithm for Data Cleaning in Big Data,,,conferencePaper,2020,,,,"We have entered the era of information explosion, data has become an important driving force for the development of the industry. The huge wealth hidden in the data, enterprises can obtain a lot of useful information from business management, market analysis, scientific exploration and other aspects to support the development decisions of enterprises. However, the actual data is often intricate with different structures and types such as erroneous data, invalid data and missing duplicate data, greatly increase the difficulty of data analysis. These dirty data can greatly affect the results of data analysis, resulting in inaccurate results or even bad information. Most of the early data cleaning requires human involvement, however the exploding large-scale data is far from being able to meet with the human intervention, requiring smarter and more automated cleaning methods. The rapid development of artificial intelligence in recent years, the emergence of machine learning, provides a new opportunity for the development of data cleaning. Nowadays, there are lots of methods that have been applied to the field of data mining, including popular machine learning, deep learning, as well as classical clustering, bayesian networks, decision trees, and so on. Both provide a large number of solutions for our data cleaning. In this paper, we present a data cleaning method which use adaptive parameters density cluster algorithms based on the DBSCAN.  2020, Springer Nature Switzerland AG.","Zhang, Xiaopeng; Lin, Ruijie; Xu, Haitao",PO,Not accessible,10.1007/978-3-030-57884-8_48,,,,,,,,,,,,0,,,,,,,,0,,,,
82,Relational pretrained transformers towards democratizing data preparation [Vision] [arXiv],Academia,arxiv,journalArticle,2020,"DC4ML, DC4ML - intro only, ML4DC",tabular,error repair,"Can AI help automate human-easy but computer-hard data preparation tasks (for example, data cleaning, data integration, and information extraction), which currently heavily involve data scientists, practitioners, and crowd workers? We envision that human-easy data preparation for relational data can be automated. To this end, we first identify the desiderata for computers to achieve near-human intelligence for data preparation: computers need a deep-learning architecture (or model) that can read and understand millions of tables; computers require unsupervised learning to perform self-learning without labeled data, and can gain knowledge from existing tasks and previous experience; and computers desire few-shot learn-ing that can adjust to new tasks with a few examples. Our proposal is called Relational Pretrained Transformers (RPTs), a general framework for various data preparation tasks, which typically consists of the following models/methods: (1) transformer, a general and powerful deep-learning model, that can read tables/texts/images;(2) masked language model for self-learning and collaborative train-ing for transferring knowledge and experience; and (3) pattern-exploiting training that better interprets a task from a few examples.We further present concrete RPT architectures for three classical data preparation tasks, namely data cleaning, entity resolution, and information extraction. We demonstrate RPTs with some initial yet promising results. Last but not least, we identify activities that will unleash a series of research opportunities to push forward the field of data preparation.","Nan Tang; Ju Fan; Fangyi Li; Jianhong Tu; Xiaoyong Du; Guoliang Li; Madden, S.; Ouzzani, M.",PO,YES,,,"Abt-Buy, Walmart-Amazon, Amazon-Google",,"(1) They trained and tested on different data sets. Normally, it is not a good practice to test on a different dataset, but here, in NLP, it is common. If they are able to accurately transform tables in natural language, it would be fine. (2) Numeric values are mapped to unknown token. (3) Transformers have a max sequence length in their input, which limits the input size of a table entry.",They call their model RPT. It is composed of a encoder and a decoder (similar to BERT(encoder) + GPT(decoder)). RPT uses BART weights (pre-training).,,not mentioned,"none for data cleaning (they just said “the cleaning propositions make sense”) and for entity linkage, they achive the best results compared to SOTA (.71 F1 score)",,,,7,1.0,1.0,1.0,1.0,1.0,1.0,1.0,4,2.0,2.0,,
83,Unknown Class Label Cleaning for Learning with Open-Set Noisy Labels,Academia,IEEE International Conference on Image Processing (ICIP),conferencePaper,2020,"DC4ML, ML4DC",img,mislabel correction,"Deep neural networks (DNNs) trained on large-scale annotated datasets have achieved impressive results in the area of image classification. Many large-scale datasets have been collected from websites; however, such data are inevitably corrupted with noise. In this study, we researched the open-set noisy label problem, where some outliers are contained in a dataset and annotated through a noisy label but do not belong to any class of training data. To address this problem, we propose a novel unknown class label cleaning framework for the training of DNNs with open-set noisy labels. In addition to general image classification, we also estimate the probability of an input being from an unknown class by assigning a pseudo unknown label to all of the data and correct these labels through an alternating update of the network parameters and labels. The results of experiments conducted on the noisy CIFAR-10 datasets demonstrate that our approach can robustly train DNNs with a high proportion of noisy labels.  2020 IEEE.","Yu, Qing; Aizawa, Kiyoharu",,YES,10.1109/ICIP40778.2020.9190652,"(1) symmetric cross entropy (SCE)
(2) generalized cross entropy (GCE) 
(3) co-teaching+",CIFAR-10,mislabel (outliers),,ResNet-32,highest accuracy (76.45 to 83.15) among compared models and lowest error detection almost in all cases of noise (0.20 to 20.39) except for the added noise (CIFAR-100) where co-teaching+ achieved lower error detection (13.95 vs. 15.78 for that particular noise),-,Mean classification accuracy and detection error,,,Good simple idea but poor evaluation,11,2.0,2.0,2.0,2.0,0.0,1.0,2.0,4,2.0,2.0,,
84,Data Cleaning of Irrelevant Images Based on Transfer Learning,Academia,International Conference on Intelligent Computing Automation and Systems (ICICAS),conferencePaper,2020,"DC4ML, ML4DC",img,mislabel correction,"Considering that there are many irrelevant images in the image data set crawled from the Internet, this paper proposes a new method of cleaning irrelevant images data based on transfer learning. The method consists of two steps that can be done iteratively. Firstly, we use transfer learning to train and get a better image classifier, which makes the single image's recognition effect more accurate. Besides, according to the number of different types of images in the data set, we calculate and determine the threshold value of the image of the minority class and then clean them accordingly. We find that our method can improve the test accuracy of the original data set on VGG16, VGG19, and Inception v3 from 37.41%, 40.62%, and 49.37% to 50.07%, 53.89%, and 65.16%, respectively. Since transfer learning has a good application effect on irrelevant images cleaning, we can use it to create data sets in deep learning.  2020 IEEE.","Liu, Dongzhen; Meng, Yanli; Wang, Lianming",PO,YES,10.1109/ICICAS51530.2020.00099,-,"Custom data set based on ""Atlas of Primary Colors of Marine Fishes in the South China Sea 1"" and ""Atlas of Primary Colors of Marine Fishes in the
South China Sea 2” ",,"(1) They removed minority classes. Obviously they will have a better accuracy, since they removed the most challenging classes. (2) They remove classes. Maybe we do not want to remove these. (3) The performance of their approach to remove samples of poor quality depends heavily on the quality of the CNN to recognize images.","VGG19, InceptionV3, VGG16",around 15% accuracy increase for the 3 models,not mentioned,Accuracy improved between 12-15% depending on the model used,,,,7,1.0,1.0,1.0,2.0,0.0,1.0,1.0,4,2.0,2.0,,
85,Ed2: A case for active learning in error detection,Academia,ACM CIKM,conferencePaper,2019,ML4DC,tabular,error detection,"State-of-the-art approaches formulate error detection as a semi-supervised classification problem. Recent research suggests that active learning is insufficiently effective for error detection and proposes the usage of neural networks and data augmentation to reduce the number of these user-provided labels. However, we can show that using the appropriate active learning strategy, it is possible to outperform the more complex models that rely on data augmentation. To this end, we propose a multi-classifier approach with two-stage sampling for active learning. This intuitive and neat sampling method chooses the most promising cells across rows and columns for labeling. On three datasets, ED2 achieves state-of-the-art detection accuracy while for large datasets, the required number of user labels is lower by one order of magnitude compared to the state of the art.  2019 Association for Computing Machinery.","Neutatz, Felix; Mahdavi, Mohammad; Abedjan, Ziawasch",PO,YES,,(1) NADEEF (2) dBoost (3) KATARA (4) ActiveClean (5) BoostClean (6) Metadata-driven error detection,(1) Flights (2) Movies (3) Beers (4) Address,any,-,XGBoost,"Not the fastest to learn, but on the long run, it outperforms compared approaches","12 minutes on the largest dataset, 1% of instance must be labeled to have good performances",Precision recall and f1-score of detected errors,YES,,,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,0.0,2.0,https://github.com/BigDaMa/ExampleDrivenErrorDetection,Ed2: A case for active learning in error detection (https://www.notion.so/Ed2-A-case-for-active-learning-in-error-detection-38a5012844dd49639218a8fc200ed901?pvs=21) 
86,Neural pixel error detection,,,conferencePaper,2019,ML4DC,img,error detection/repair,"… In sum, we show that simple neural network methods such as autoencoders can perform admirably for real-world production QC tasks, improving scalability for a studio QC workflow. …","Doggett, EV; Wolak, AMC; Tsatsoulis, PD; ...",PO,score too low - 2,10.1145/3306307.3328197,,,,,,,,,,ZBRN8LKH,,0,,,,,,,,0,0.0,0.0,,
87,Automatic grammatical error detection of non-native spoken learner English,Academia,ICASSP,conferencePaper,2019,ML4DC,text,error detection/repair,… The grammatical error detection (GED) system chosen for this work is a state-of-the-art bidirectional recurrrent neural network based framework2 proposed for detecting all kinds of …,"Knill, KM; Gales, MJF; Manakul, PP; ...",,YES,https://doi.org/10.1109/ICASSP.2019.8683080,"(1) error detection for written text (FCE) vs. spoken (NICT-JLE & BULTAS)
(2) error detection using manual transcriptions vs. Automatic transcription (ASR) ","(1) CLC FCE: The Cambridge Learner Corpus (CLC) of ESOL First Certificate in English (written text used to train the baseline model and then fine tuned for the other 2 spoken corpus)
(2) BULATS: The spoken BULATS Business English assessment
test
(3) NICT-JLE: The NICT Japanese Learner English (JLE) Corpus


",Grammatical ,Unavailability of large corpus for speech training data ,"BLSTM 
","(1) The performance of baseline GED for spoken is less than baseline GED for written text which achieves (P=69.9, R=33.9,F0.5=57.6). However, when GED is fine-tuned using the spoken dataset, the performance improved (for BULTAS: P=66.7, R=33.8,F0.5=55.8; for NICT-JLE: P=60.6, R=28.9, F0.5=49.7) and be close to the level of GED for written text.

(2) Baseline GED for manual transcription has higher performance (P=52.4, R=27.0, F0.5=44.1) compared to baseline GED for ASR transcription (P=28.1, R=22.0, F0.5=26.6)",-,"Precision
Recall
F0.5 (assign higher weight to precision)",,P27VEW2B,"Unlike others techniques applied to written text, the detection of grammatical errors in this paper is applied to speech (transcript provided either by ASR or manually).
They use the existing state-of-the-art GED model.
Using ASR transcriptions is more challenging to the GED model because ASR-related errors increase with grammatical errors and disfluencies leading to degrade GED performance.",13,2.0,2.0,2.0,2.0,1.0,2.0,2.0,2,0.0,2.0,,
88,Context is key: Grammatical error detection with contextual word representations,Academia,,journalArticle,2019,ML4DC,text,error detection/repair,… error detection (GED) in nonnative writing requires systems to identify a wide range of errors in text written by language learners. Error detection as a purely supervised … of unsupervised …,"Bell, S; Yannakoudakis, H; Rei, M",,exclusion criteria last step,http://dx.doi.org/10.18653/v1/W19-4410,"*base-model: bi-LSTM sequence labeler over token embeddings (Rei (2017)) , 
*another two models (Rei et al. (2017) and Kasewa
et al. (2018)) improving base model by additionally augmenting base
model with artificial training data.
*extended base-model with BERT contextual embeddings
*extended base-model with ELMo contextual embeddings
*extended base-model with Flair contextual embeddings","for training: First Certificate in English (FCE) training dataset
for testing: FCE test set, the CoNLL-2014 test set, the Johns Hopkins University (JHU) FLuency-Extended GUG Corpus (JFLEG) test
set, and the Building Educational Applications (BEA) 2019 shared task development and test sets.",Grammatical,"while contextual embeddings always improve aggregate performance on GED, no model performs well on all types, thus, selecting appropriate model depends on the error type specific properties","*extended base-model (bi-LSTM sequence labeler) with BERT contextual embeddings
*extended base-model with ELMo contextual embeddings
*extended base-model with Flair contextual embeddings","The use of contextual embeddings improved the results for most of the datasets compared to base and improved models. 
BERT base and BERT large have the highest recall, precision and F0.5 compared to ELMo and Flair.",,"Precision
Recall
F0.5",,U5JMU222,"well written paper 
provide comprehensive evaluation ",13,2.0,2.0,2.0,2.0,1.0,2.0,2.0,2,0.0,2.0,,
89,Prediction Based Deep Autoencoding Model for Anomaly Detection,,,conferencePaper,2019,ML4DC,any,outliers detection,"Latent variables and reconstruction error generated from auto encoder are the common means for anomaly detection dealing with high dimensional signals. They are exclusively typical representations of the original input, and a plenty of methods utilizing them for anomaly detection have achieved good results. In this paper, we propose a new method combining these two features together to generate proper scores for anomaly detection. As both these two features contain useful information contributing to anomaly detection, good results can be expected by fusion of those two. The architecture proposed in this paper comprises of two networks, and we only use normal data for training. To compress and rebuild an input, a deep auto encoder (AE) is utilized where low dimensional latent variables and reconstruction error can be obtained, and compactness loss is introduced on latent variables to maintain a low intra-variance. Meanwhile, multi-layer perceptron (MLP) network which takes the generated latent variables as input is established aiming at predicting its corresponding reconstruction error. By introducing MLP network, anomalies sharing similar reconstruction error yet different distribution of latent variables to normal data or vice versa can be separated. These two networks, AE and MLP are trained jointly in our model and the prediction error form MLP network is used as the final score for anomaly detection. Experiments on several benchmarks including image and multivariable datasets demonstrate the effectiveness and practicability of this new approach when comparing with several up-to-data algorithms.  2019, Springer Nature Switzerland AG.","Pang, Zhanzhong; Yu, Xiaoyi; Sun, Jun; Hiroya, Inakoshi",PO,Not accessible,10.1007/978-3-030-21074-8_33,,,,,,,,,,S2CFEKSB,,0,,,,,,,,0,,,,
90,HoloDetect: Few-Shot Learning for Error Detection [arXiv],Academia,ACM SIGMOD,journalArticle,2019,ML4DC,tabular,error detection,"We introduce a few-shot learning framework for error detection. We show that data augmentation (a form of weak supervision) is key to training high-quality, ML-based error detection models that require minimal human involvement. Our framework consists of two parts: (1) an expressive model to learn rich representations that capture the inherent syntactic and semantic heterogeneity of errors; and (2) a data augmentation model that, given a small seed of clean records, uses dataset-specific transformations to automatically generate additional training data. Our key insight is to learn data augmentation policies from the noisy input dataset in a weakly supervised manner. We show that our framework detects errors with an average precision of ~94% and an average recall of ~93% across a diverse array of datasets that exhibit different types and amounts of errors. We compare our approach to a comprehensive collection of error detection methods, ranging from traditional rule-based methods to ensemble-based and active learning approaches. We show that data augmentation yields an average improvement of 20 F1 points while it requires access to 3 fewer labeled examples compared to other ML approaches. [ACM SIGMOD 2019 doi:10.1145/3299869.3319888].","Heidari, A.; McGrath, J.; Ilyas, I.F.; Rekatsinas, T.",PO,YES,,(1) Constraint Violations (2) HoloClean (3) Outlier Detection (4) Forbidden Item Sets (5) Simple logistic regression,(1) Hospital (2) Food (3) Soccer (4) Adult (5) Animal. The last 3 datasets had the ground truth.,"not mentioned, seems to be any error on string values",-,2 layer NN to detect errors,"Performance, Recall and F1 score of error detection","Slower than compared approaches, but same order of magnitude",,YES,PNUGTE37,-,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,0.0,2.0,-,
91,Uni-detect: A unified approach to automated error detection in tables,,,journalArticle,2019,ML4DC,tabular,error detection,"… In order to enable automatic and unsupervised detection of data errors, in this work we propose a data-driven approach that leverages a large corpus of (mostly clean [50]) tables T. …","Wang, P; He, Y",PO,score too low,10.1145/3299869.3319855,,,,,,,,,,6JHTRFZ5,,0,,,,,,,,0,0.0,0.0,,
92,Piclean: A probabilistic and interactive data cleaning system,,,journalArticle,2019,ML4DC,tabular,error detection/repair,"We proposePIClean, a probabilistic and interactive datacleaning system that aims at addressing the aforementionedlimitations.PICleanproducesprobabilistic errorsandprob-abilistic fixesusing low-rank approximation, which implic-itly discovers and uses relationships between columns of adataset for cleaning. The probabilistic errors and fixes areconfirmed or rejected by users, and the user feedbacks areconstantly incorporated byPICleanto produce more accu-rate and higher-coverage cleaning results.","Yu, Z; Chu, X",Dima,score too low,10.1145/3299869.3320214,"Theodoros Rekatsinas, Xu Chu, Ihab F. Ilyas, and Christopher Ré. 2017.HoloClean: Holistic Data Repairs with Probabilistic Inference. 10, 11(2017), 1190–1201","Hospital dataset (http://data.medicare.gov/). Hospital data is from the US government. There are 17 string attributes, including Provider # (PN), measure code (MC) and name
(MN), phone (PHO), emergency service (ES) and has 115k tuples.",,"No performance evaluation, only two practical use cases description. It is mostly based on the user feedback, it’s not clear how good the initial predictions are and how long it takes to converge to good solutions",No model considered,No performance evaluation,No performance evaluation,No metrics,NO,IJCQ567S,"The paper does not present strong evidence that the tool should work. Neither theoretically, nor empirically. The performance was not evaluated. The only advantage of the approach is that it allows to clean the data interactively.",3,1.0,1.0,1.0,0.0,0.0,0.0,0.0,4,2.0,2.0,,
93,Interactive correction of mislabeled training data,Academia,IEEE Conference on Visual Analytics Science and Technology (VAST),journalArticle,2019,DC4ML,img,mislabel correction,… of a label cleaning network. The network is then integrated with a multitask neural network for … These methods integrate label cleaning with classification frameworks using deep neural …,"Xiang, S; Ye, X; Xia, J; Wu, J; Chen, Y; ...",PO,YES,,-,(1) MNIST (2) Clothing,-,-,-,managed to improve against doing nothing,-,% of mislabels,,ZXCPRZGJ,-,10,2.0,2.0,1.0,1.0,0.0,2.0,2.0,2,2.0,0.0,,
94,Learning functional dependencies with sparse regression,Academia,arxiv,journalArticle,2019,ML4DC,tabular,error detection/repair,… on the task of weakly supervised data repairing. Recent work [… -of-the-art machine learning-based data repairing systems. We … to automating weakly supervised data preparation …,"Guo, Z; Rekatsinas, T",Amin,YES,,"PYRO, Reliable Fraction of Information (RFI), Graphical Lasso (GL), ","synthetic dataset, and three noisy dataset: Hospital, Food, and Physician dataset form http://medicare.gov/",-,working only for discrete random variables,"PGM, learning the structure of linear causal networks (undirected) via inverse covariance estimation",better than other approches ,"worse than GL, but equal or better than others","Precision, Recall, and F1",YES,6WFKWVSM,,11,2.0,2.0,1.0,2.0,0.0,2.0,2.0,1,0.0,1.0,-,
95,Countering noisy labels by learning from auxiliary clean labels,,,journalArticle,2019,,,,… (2) We show that we can exploit additional training signals from all the provided images and strengthen the data cleansing mechanism with the self-supervised rotation task. (3) The …,"Tsai, TW; Li, C; Zhu, J",,score too low - 4,,,,,,,,,,,AT4376RE,,0,,,,,,,,0,0.0,0.0,,
96,AUTO-CDD: automatic cleaning dirty data using machine learning techniques,,,journalArticle,2019,ML4DC,tabular,error detection/repair,… better data cleaning. It can be achieved by introducing automatic data cleaning process with the help of Machine Learning (ML)… These abilities of data cleaning process can enhance the …,"Jesmeen, MZH; Hossen, A; Hossen, J; ...",PO,score too low - 4,,,,,,,,,,,L3S2TV6N,,5,1.0,1.0,0.0,1.0,0.0,1.0,1.0,4,2.0,2.0,,
97,Multi-index dialogue data cleaning model,Academia,Joint International Information Technology and Artificial Intelligence Conference (ITAIC),conferencePaper,2019,ML4DC,text,mislabel correction,"… index dialogue data cleaning model in this paper is based on the unsupervised data cleaning … The model is under supervised training. After the training, the model is saved. The score of …","Ke, X; Bai, J; Wen, L; Cao, B",,YES,https://doi.org/10.1109/ITAIC.2019.8785558,Dual encoder using LSTM,Xiaohuangji dialogue corpus and the Shooter network film script,poorly paired question answer ,,Bi-GRU with attention,"The proposed model has slightly better accuracy (before cleaning:68.8, after: 96.8) than compared model (before: 67.5, after: 96.2)
Also distinguishes the quality of the question-and-answer pair better. as the distribution of predictions probabilities is higher for probabilities that is more close to 0 or 1.",-,"Accuracy
Model prediction results distribution",,A9AM4ZE4,"They have no real contribution in cleaning. Actually, the proposed model (Bi-GRU with attention) that is used in the adopted cleaning framework is performing slightly better than compared model even before data is cleaned.",8,1.0,2.0,1.0,1.0,0.0,2.0,1.0,1,1.0,0.0,,
98,Predictive Data Transformation Suggestions in Grafterizer Using Machine Learning,,,conferencePaper,2019,,,,"Data preprocessing is a crucial step in data analysis. A substantial amount of time is spent on data transformation tasks such as data formatting, modification, extraction, and enrichment, typically making it more convenient for users to work with systems that can recommend most relevant transformations for a given dataset. In this paper, we propose an approach for generating relevant data transformation suggestions for tabular data preprocessing using machine learning (specifically, the Random Forest algorithm). The approach is implemented for Grafterizer, a Web-based framework for tabular data cleaning and transformation, and evaluated through a usability study.  2019, Springer Nature Switzerland AG.","Sajid, Saliha; von Zernichow, Bjorn Marius; Soylu, Ahmet; Roman, Dumitru",,score too low - 4,10.1007/978-3-030-36599-8_12,,,,,,,,,,Y5RUAI9H,,0,,,,,,,,0,0.0,0.0,,
99,Learn2Clean: Optimizing the sequence of tasks for web data preparation,Academia,ACM WWW,conferencePaper,2019,"DC4ML, ML4DC",any,holistic,"Data cleaning and preparation has been a long-standing challenge in data science to avoid incorrect results and misleading conclusions obtained from dirty data. For a given dataset and a given machine learning-based task, a plethora of data preprocessing techniques and alternative data curation strategies may lead to dramatically different outputs with unequal quality performance. Most current work on data cleaning and automated machine learning, however, focus on developing either cleaning algorithms or user-guided systems or argue to rely on a principled method to select the sequence of data preprocessing steps that can lead to the optimal quality performance of. In this paper, we propose Learn2Clean, a method based on Q-Learning, a model-free reinforcement learning technique that selects, for a given dataset, a ML model, and a quality performance metric, the optimal sequence of tasks for preprocessing the data such that the quality of the ML model result is maximized. As a preliminary validation of our approach in the context of Web data analytics, we present some promising results on data preparation for clustering, regression, and classification on real-world data.  2019 IW3C2 (International World Wide Web Conference Committee), published under Creative Commons CC-BY 4.0 License.","Berti-Equille, Laure",PO,YES,10.1145/3308558.3313602,(1) Random data pre-processing selection (2) manual cleaning by a DS expert (3) a auto-ML approach obtained by MLBox (4) no pre-processing (baseline),(1) Google Play Store Apps (2) Google Play Store users (3) House prices,Any error that can be fixed depending on the data preparation tool used.,(1) They compared their approach to manual data cleaning under time constraints (under a minute). I highly doubt the data scientist expert had enough time to clean a significant amount of records. (2) The state seems to be the last data cleaning tool used (3) The performance was on a model with default parameters,"Tabular Q-learning, model-free","Half of the time, they had better or equal results compared to other approaches (e.g. manual cleaning by an expert under time constraints and an auto ML tool)","For data sets with thousands of rows, under a minute.",(ML) Performance of a ML model,YES,,,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,4,2.0,2.0,,
100,"Revisiting conditional functional dependency discovery: Splitting the ""c"" from the ""fd""",,,conferencePaper,2019,ML4DC,tabular,error detection/repair,"Many techniques for cleaning dirty data are based on enforcing some set of integrity constraints. Conditional functional dependencies (CFDs) are a combination of traditional Functional dependencies (FDs) and association rules, and are widely used as a constraint formalism for data cleaning. However, the discovery of such CFDs has received limited attention. In this paper, we regard CFDs as an extension of association rules, and present three general methodologies for (approximate) CFD discovery, each using a different way of combining pattern mining for discovering the conditions (the ""C"" in CFD) with FD discovery. We discuss how existing algorithms fit into these three methodologies, and introduce new techniques to improve the discovery process. We show that the right choice of methodology improves performance over the traditional CFD discovery method CTane. Code related to this paper is available at: https://github.com/j-r77/cfddiscovery, https://codeocean.com/2018/06/20/discovering-conditional-functional-dependencies/code.  2019, Springer Nature Switzerland AG.","Rammelaere, Joeri; Geerts, Floris",PO,Not accessible,10.1007/978-3-030-10928-8_33,,,,,,,,,,,,0,,,,,,,,0,,,,
101,When Considering More Elements: Attribute Correlation in Unsupervised Data Cleaning under Blocking,,,journalArticle,2019,,,entity matching / duplicate removal,"In banks, governments, and internet companies, due to the increasing demand for data in various information systems and continuously shortening of the cycle for data collection and update, there may be a variety of data quality issues in a database. As the expansion of data scales, methods such as pre-specifying business rules or introducing expert experience into a repair process are no longer applicable to some information systems requiring rapid responses. In this case, we divided data cleaning into supervised and unsupervised forms according to whether there were interventions in the repair processes and put forward a new dimension suitable for unsupervised cleaning in this paper. For weak logic errors in unsupervised data cleaning, we proposed an attribute correlation-based (ACB)-Framework under blocking, and designed three different data blocking methods to reduce the time complexity and test the impact of clustering accuracy on data cleaning. The experiments showed that the blocking methods could effectively reduce the repair time by maintaining the repair validity. Moreover, we concluded that the blocking methods with a too high clustering accuracy tended to put tuples with the same elements into a data block, which reduced the cleaning ability. In summary, the ACB-Framework with blocking can reduce the corresponding time cost and does not need the guidance of domain knowledge or interventions in repair, which can be applied in information systems requiring rapid responses, such as internet web pages, network servers, and sensor information acquisition.",Pei Li; Chaofan Dai; Wenqian Wang,PO,score too low,10.3390/sym11040575,,,,,,,,,,,,0,,,,,,,,0,0.0,0.0,,
102,Predictive Data Transformation Suggestions in Grafterizer Using Machine Learning,,,conferencePaper,2019,ML4DC,tabular,error detection/repair,"Data preprocessing is a crucial step in data analysis. A substantial amount of time is spent on data transformation tasks such as data formatting, modification, extraction, and enrichment, typically making it more convenient for users to work with systems that can recommend most relevant transformations for a given dataset. In this paper, we propose an approach for generating relevant data transformation suggestions for tabular data preprocessing using machine learning (specifically, the Random Forest algorithm). The approach is implemented for Grafterizer, a Web-based framework for tabular data cleaning and transformation, and evaluated through a usability study.  2019, Springer Nature Switzerland AG.","Sajid, Saliha; von Zernichow, Bjorn Marius; Soylu, Ahmet; Roman, Dumitru",PO,Not accessible,10.1007/978-3-030-36599-8_12,,,,,,,,,,,,0,,,,,,,,0,,,,
103,AlphaClean: Automatic Generation of Data Cleaning Pipelines,Academia,arxiv,journalArticle,2019,"DC4ML, DC4ML - intro only, ML4DC",any,holistic,"The analyst effort in data cleaning is gradually shifting away from the design of hand-written scripts to building and tuning complex pipelines of automated data cleaning libraries. Hyperparameter tuning for data cleaning is very different than hyperparmeter tuning for machine learning since the pipeline components and objective functions have structure that tuning algorithms can exploit. This paper proposes a framework, called AlphaClean, that rethinks parameter tuning for data cleaning pipelines. AlphaClean provides users with a rich library to define data quality measures with weighted sums of SQL aggregate queries. AlphaClean applies generate-then-search framework where each pipelined cleaning operator contributes candidate transformations to a shared pool. Asynchronously, in separate threads, a search algorithm sequences them into cleaning pipelines that maximize the user-defined quality measures. This architecture allows AlphaClean to apply a number of optimizations including incremental evaluation of the quality measures and learning dynamic pruning rules to reduce the search space. Our experiments on real and synthetic benchmarks suggest that AlphaClean finds solutions of up-to 9x higher quality than naively applying state-of-the-art parameter tuning methods, is significantly more robust to straggling data cleaning methods and redundancy in the data cleaning library, and can incorporate state-of-the-art cleaning systems such as HoloClean as cleaning operators. Copyright  2019, The Authors. All rights reserved.","Krishnan, Sanjay; Wu, Eugene",PO,YES,,(1) Gridsearch (try different tools’ hyperparameter combinaisons) (2) hyperopt (an optimized gridsearch) (3) greedy (tuning each tool independently of others),(1) Hospital (2) London Air Quality (3) Physician. They seem to have dirty and ground truth versions of the data set!,Any,-,They use logistic regression to predict the best data cleaning tool to use on a sample. ,Better results than other traditional hyper-parameter optimization techniques such as Bayesian optimization. Better results than using data cleaning tools alone.,Converges 3x time faster than the next optim. tool on some data set.,(1) Suboptimality (the quotient between the user-defined quality measure for the ground truth data set and the cleaned one) (2) % Errors (the % of errors left during the cleaning process),YES,,,11,2.0,2.0,1.0,2.0,0.0,2.0,2.0,3,2.0,1.0,,
104,Fast record linkage for company entities,,,journalArticle,2019,ML4DC,tabular,entity matching / duplicate removal,"Record linkage is an essential part of nearly all real-world systems that consume structured and unstructured data coming from different sources. Typically no common key is available for connecting records. Massive data cleaning and data integration processes often have to be completed before any data analytics and further processing can be performed. Although record linkage is frequently regarded as a somewhat tedious but necessary step, it reveals valuable insights into the data at hand. These insights guide further analytic approaches to the data and support data visualization. In this work we focus on company entity matching, where company name, location and industry are taken into account. Our contribution is an end-to-end, highly scalable, enterprise-grade system that uses rule-based linkage algorithms extended with a machine learning approach to account for short company names. Linkage time is greatly reduced by efficient decomposition of the search space using MinHash. High linkage accuracy is achieved by the proposed thorough scoring process of the matching candidates. Based on real-world ground truth datasets, we show that our approach reaches a recall of 91% compared to 73% for baseline approaches. These results are achieved while scaling linearly with the number of nodes used in the system. Copyright  2019, The Authors. All rights reserved.","Gschwind, Thomas; Miksovic, Christoph; Minder, Julian; Mirylenka, Katsiaryna; Scotton, Paolo",PO,exclusion criteria last step,,,,,,,,,,,,,0,,,,,,,,0,0.0,0.0,,
105,Research on data cleaning technology based on instance level,,,conferencePaper,2019,,,,"In the era of current data explosion, data cleaning becomes an important part of data analysis, and it is also one of the important means to improve data quality. In this paper, the concept, principle, process, detection method and related cleaning algorithm of structural data cleaning are introduced in detail through the data cleaning technology based on instance level. In view of the outstanding data quality problems based on instance level, relevant experiment is designed, the operation and verification process of structural data cleaning will explain concretely through visual programming technology and machine learning algorithm. Finally, the research of data cleaning technology in the future is prospected.  2019 IOP Publishing Ltd. All rights reserved.","Li, Chuan; Hou, Yunqi; Yu, Zhang",PO,exclusion criteria last step,10.1088/1742-6596/1213/2/022021,,,,,,,,,,,,0,,,,,,,,0,,,,
106,A Method for Duplicate Record Detection Using Deep Learning,,,conferencePaper,2019,ML4DC,?,entity matching / duplicate removal,"As the scale of data in the database is growing rapidly, there exists the increasing number of duplicate information, which leads to data redundancy. Effective detection of duplicate records is of great significance for improving data quality and is an important issue in the field of data cleaning. At present, traditional duplicate record detection approaches use discrete features to build classification models which cannot express the semantic information well, and the classification accuracy needs to be improved. The deep learning model has good performance in feature extraction and classification. Therefore, this paper proposes a novel two-stage duplicate record detection model based on deep learning. In the first stage, the doc2vec model based on deep learning is applied to attribute vectorization construction, and the vector of record comparison pairs is constructed by concatenating attribute vectors. The second stage uses a Convolutional Neural Networks (CNN) to build a classification model for all record comparison vectors. The experimental results show that the proposed method is superior to the traditional duplicate record detection method.  2019, Springer Nature Switzerland AG.","Gu, Qing; Dong, Yongquan; Hu, Yang; Liu, Yali",PO,Not accessible,10.1007/978-3-030-30952-7_10,,,,,,,,,,,,0,,,,,,,,0,,,,
107,Combining Outlier Detection and Reconstruction Error Minimization for Label Noise Reduction,Academia,IEEE International Conference on Big Data and Smart Computing,conferencePaper,2019,"DC4ML, ML4DC",img,mislabel correction,"Label noise is a common phenomenon when labeling a large-scale dataset for supervised learning. Outlier detection is a recently proposed method to handle this issue by treating the outliers of each class as potential data points with label noise and remove them before training. However, this approach could lead to high false positive rate and hurt the performance. In this paper, we propose a novel and effective method to deal with this issue by combining the strength of outlier detection and reconstruction error minimization (REM). The main idea is add a second verification step (i.e., REM) to the outputs of outlier detection so as to reduce the risk of discarding those points which do not fit the underlying data distribution well but with correct label. Particularly, we first find the outliers in each class by a robust deep autoencoders-based outlier detector, through which not only did we get candidate mislabeled data but also a group of well-learned deep autoencoders. Then a reconstruction error minimization based approach is applied to these outliers to further filter and relabel the mislabeled data. The experimental results on MNIST dataset show that the proposed method could significantly reduce the false positive rate of outlier detection and improve the performance of both data cleaning and classification in the presence of label noise.","Zhang, WN; Tan, XY; IEEE",PO,YES,,"For goal (1): other approaches that can re-label a dataset (1.1) ICCN-SMO (1.2) TC-SVM (1.3) ALNR (1.4) LN-RDA, for goal (2): robust cleaning approaches and some of (1) solutions",MNIST,mislabels,-,robust auto-encoder,Superior to other methods for almost every level of label noise,Significantly lower than other methods,(1) Accuracy of fixing mislabels (2) perfomance of the end classifier,,,short and sweet,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,4,2.0,2.0,-,
108,Statistical relational learning based automatic data cleaning,,,journalArticle,2019,ML4DC,tabular,error detection/repair,"In this paper, we focus on the problem of cleaning dirty data without either existing data quality patterns/rules or involvement of human experts. We proposed an unsupervised data cleaning method based on statistical relational learning. Firstly, we learn a model of data in the form of Bayesian network, which reflects the dependency relationships between different attributes of the database table. Then, we translate the dependency relationships between attributes into first-order logic formulas, and convert first-order logic formulas into Markov logic networks by assigning a weight for each formula. Secondly, we transform the Markov logic networks into DeepDive inference rules and execute these rules on DeepDive platform. The results of inference are used to estimate the most likely repairs of dirty in data.",Weibang Li; Ling Li; Zhanhuai Li; Mengtian Cui,PO,exclusion criteria last step,10.1007/s11704-018-7066-4,,,,,,,,,,,,0,,,,,,,,0,,,,
109,Scaling entity resolution: A loosely schema-aware approach,,,journalArticle,2019,ML4DC,tabular,entity matching / duplicate removal,"In big data sources, real-world entities are typically represented with a variety of schemata and formats (e.g., relational records, JSON objects, etc.). Different profiles (i.e., representations) of an entity often contain redundant and/or inconsistent information. Thus identifying which profiles refer to the same entity is a fundamental task (called Entity Resolution) to unleash the value of big data. The naïve all-pairs comparison solution is impractical on large data, hence blocking methods are employed to partition a profile collection into (possibly overlapping) blocks and limit the comparisons to profiles that appear in the same block together. Meta-blocking is the task of restructuring a block collection, removing superfluous comparisons. Existing meta-blocking approaches rely exclusively on schema-agnostic features, under the assumption that handling the schema variety of big data does not pay-off for such a task. In this paper, we demonstrate how “loose” schema information (i.e., statistics collected directly from the data) can be exploited to enhance the quality of the blocks in a holistic loosely schema-aware (meta-)blocking approach that can be used to speed up your favorite Entity Resolution algorithm. We call it Blast (Blocking with Loosely-Aware Schema Techniques). We show how Blast can automatically extract the loose schema information by adopting an LSH-based step for efficiently handling volume and schema heterogeneity of the data. Furthermore, we introduce a novel meta-blocking algorithm that can be employed to efficiently execute Blast on MapReduce-like systems (such as Apache Spark). Finally, we experimentally demonstrate, on real-world datasets, how Blast outperforms the state-of-the-art (meta-)blocking approaches.","Simonini, Giovanni; Gagliardelli, Luca; Bergamaschi, Sonia; Jagadish, H.V.",PO,score too low - 2,10.1016/j.is.2019.03.006,,,,,,,,,,,,0,,,,,,,,0,0.0,0.0,,
110,Confident learning: Estimating uncertainty in dataset labels,Both,Journal of Artificial Intelligence Research,journalArticle,2019,"DC4ML, ML4DC",any,mislabel correction,"Learning exists in the context of data, yet notions of confidence typically focus on model predictions, not label quality. Confident learning (CL) is an alternative approach which focuses instead on label quality by characterizing and identifying label errors in datasets, based on the principles of pruning noisy data, counting with probabilistic thresholds to estimate noise, and ranking examples to train with confidence. Whereas numerous studies have developed these principles independently, here, we combine them, building on the assumption of a class-conditional noise process to directly estimate the joint distribution between noisy (given) labels and uncorrupted (unknown) labels. This results in a generalized CL which is provably consistent and experimentally performant. We present sufficient conditions where CL exactly finds label errors, and show CL performance exceeding seven recent competitive approaches for learning with noisy labels on the CIFAR dataset. Uniquely, the CL framework is not coupled to a specific data modality or model (e.g., we use CL to find several label errors in the presumed error-free MNIST dataset and improve sentiment classification on text data in Amazon Reviews). We also employ CL on ImageNet to quantify ontological class overlap (e.g., estimating 645 missile images are mislabeled as their parent class projectile), and moderately increase model accuracy (e.g., for ResNet) by cleaning data prior to training. These results are replicable using the open-source cleanlab release. Copyright  2019, The Authors. All rights reserved.","Northcutt, Curtis G.; Jiang, Lu; Chuang, Isaac L.",PO,YES,,"Different approaches to improve model performances in presence of label noise (one data cleaning approach, other robust ML approaches) and a baseline (i.e. a vanilla model, without data cleaning or robust ML). They also compare against the random removal of data.",(1) CIFAR (2) MNIST (3) Amazon reviews (4) ImageNet,mislabels,-,depends on the dataset,open this page for details,-,"(1) test accuracy of ML model trained on the cleaned dataset (2) Accuracy, F1, precision, recall of errors found in a data set",,,,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,4,2.0,2.0,,
111,Application of attribute correlation in unsupervised data cleaning,,,conferencePaper,2019,,,error detection/repair,"Referring to the supervised learning and unsupervised learning in machine learning, we divide the data cleaning processes into supervised and unsupervised two forms too, and then, we reclassify the data quality problems into canonicalization error, redundancy error, strong logic error and weak logic error according to the characteristics of unsupervised cleaning. For the weak logic errors, we propose a repair framework AC-Framework and an algorithm AC-Repair based on the attribute correlation. When repairing, we first establish a priority queue(PQ) for elements to be repaired according to the minimum cost idea and take the corresponding conflict-free data set() as a training set to learn the correlation among attributes. Then, we select the first element in PQ list as the candidate element to repair, and recompute the PQ list after one repair round to improve the efficiency. Finally, in order to prevent the algorithm from endless loops, we set a label flag to mark the repaired elements, in this way, every error element will be repaired at most once. In the experimental part, we compare the AC-Repair algorithm with the interpolation-based repair algorithm to verify its validity.  2019 Association for Computing Machinery.","Li, Pei; Dai, Chaofan; Wang, Wenqian",PO,score too low,10.1145/3312714.3312717,,,,,,,,,,,,0,,,,,,,,0,0.0,0.0,,
112,A hybrid data cleaning framework using Markov logic networks,Academia,IEEE Transactions on Knowledge and Data Engineering,journalArticle,2019,ML4DC,tabular,error detection/repair,"With the increase of dirty data, data cleaning turns into a crux of data analysis. Most of the existing algorithms rely on either qualitative techniques (e.g., data rules) or quantitative ones (e.g., statistical methods). In this paper, we present a novel hybrid data cleaning framework on top of Markov logic networks (MLNs), termed as MLNClean, which is capable of cleaning both schema-level and instance-level errors. MLNClean mainly consists of two cleaning stages, namely, first cleaning multiple data versions separately (each of which corresponds to one data rule), and then deriving the final clean data based on multiple data versions. Moreover, we propose a series of techniques/concepts, e.g., the MLN index, the concepts of reliability score and fusion score, to facilitate the cleaning process. Extensive experimental results on both real and synthetic datasets demonstrate the superiority of MLNClean to the state-of-the-art approach in terms of both accuracy and efficiency. Copyright  2019, The Authors. All rights reserved.","Gao, Yunjun; Ge, Congcong; Miao, Xiaoye; Wang, Haobo; Yao, Bin; Li, Qing",Dima,YES,,"HoloClean (T. Rekatsinas, X. Chu, I. F. Ilyas, and C. R ́e, “Holoclean: Holistic datarepairs with probabilistic inference,”PVLDB, vol. 10, no. 11, pp. 1190–1201, 201)","https://data.medicare.gov/data/hospital-comparis a real dataset that provides information about healthcare associated infections occurred in hospitals. It contains 231,265 tuples.                                        https://www.cars.com/ contains the used vehicle information, including model,make, type, year, condition, wheel Drive, doors. It consists of 30,760 tuples.                                                                         https://www.notion.so/ce4c3e5544e34df5ac2be15c79938c76?pvs=21 is a benchmark for performance metrics for systems operating.",,"For MLNClean, there are two reasons for the decline. The first reason is that, with the increase of error percentage, AGP is prone to wrongly treat more normal groups as abnormal ones, No replication package",Evaluation only in terms of the repaired attributes,"F1 score (where precision is equal to the ratio of correctly repaired attribute values to the total number of updated attribute values, and recall equals the ratio of correctly repaired attribute values to the total number of erroneous values)",Runtime,"reliability score, ",,,Extensive experimental results on both real and synthetic datasets demonstrate the superiority of MLNClean to the state-of-the-art approach in terms of both accuracy and efficiency. Very thorough evaluation indeed!,12,2.0,2.0,2.0,2.0,1.0,1.0,2.0,3,2.0,1.0,,
113,Data cleansing for models trained with SGD,Academia,NeurIPS,journalArticle,2019,"DC4ML, ML4DC",img,mislabel correction,"Data cleansing is a typical approach used to improve the accuracy of machine learning models, which, however, requires extensive domain knowledge to identify the influential instances that affect the models. In this paper, we propose an algorithm that can suggest influential instances without using any domain knowledge. With the proposed method, users only need to inspect the instances suggested by the algorithm, implying that users do not need extensive knowledge for this procedure, which enables even non-experts to conduct data cleansing and improve the model. The existing methods require the loss function to be convex and an optimal model to be obtained, which is not always the case in modern machine learning. To overcome these limitations, we propose a novel approach specifically designed for the models trained with stochastic gradient descent (SGD). The proposed method infers the influential instances by retracing the steps of the SGD while incorporating intermediate models computed in each step. Through experiments, we demonstrate that the proposed method can accurately infer the influential instances. Moreover, we used MNIST and CIFAR10 to show that the models can be effectively improved by removing the influential instances suggested by the proposed method. Copyright  2019, The Authors. All rights reserved.","Hara, Satoshi; Nitanday, Atsushi; Maehara, Takanori",PO,YES,,(1) Influence function of K&L (2) two outlier detection techniques (auto-encoder and isolation forest),(1) MNIST (2) CIFAR,any,-,(1) logistic regression and (2) 2-layer NN,The only method (in the compared approaches) that achieve statistically significant improvements,-,misclassification rate (i.e. 1-accuracy) of the end model,,,-,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,2.0,0.0,https://github.com/sato9hara/sgd-influence,
114,AI for Data Quality: Automating Data Science Pipelines,,,conferencePaper,2019,"DC4ML, DC4ML - intro only, ML4DC",tabular,error detection/repair,"Data scientists spend big chunk of their time preparing, cleaning, and transforming raw data before getting the chance to feed this data to their well-crafted models. Despite the efforts to build robust predication and classification models, data errors still the main reason for having low quality results. This massive laborintensive exercises to clean data remain the main impediment to automatic end-to-end AI pipeline for data science. In this talk, I focus on data cleaning as an inference problem that can be automated by leveraging the great advancements in AI and ML in the last few years. I will describe The HoloClean++ framework, a machine learning framework for data profiling and cleaning (error detection and repair). The framework has multiple successful deployments with cleaning census data, and pilots with commercial enterprises to boost the quality of source (training) data before feeding them to downstream analytics. HoloClean++ builds two main probabilistic models: a data generation model (describing how data was intended to look like); and a realization model (describing how errors might be introduced to the intended clean data). The framework uses few-shot learning, data augmentation, and weak supervision to learn the parameters of these models, and use them to predict both error and their possible repairs. While the idea of using statistical inference to model the joint data distribution of the underlying data is not new, the problem has been always: (1) how to scale a model with millions of data cells (corresponding to random variables); and (2) how to get enough training data to learn the complex models that are capable of accurately predicting the anomalies and the repairs. HoloClean++ tackles exactly these two problems.","Ilyas, I.F.",PO,Not accessible,,,,,,,,,,,,,0,,,,,,,,0,,,,
115,Raha: A Configuration-Free Error Detection System,Academia,ACM SIGMOD,conferencePaper,2019,ML4DC,tabular,error detection,,"Mahdavi, Mohammad; Abedjan, Ziawasch; Fernandez, Raul Castro; Madden, Samuel; Ouzzani, Mourad; Stonebraker, Michael; Tang, Nan",PO,YES,,,"Most of them have both the GT and dirty versions: Hostpital, Flights, Address, Beers, Rayyan, Movies, IT, Tax","Any (it depends on the primary error detection tools used); missing values, formatting issues, etc.",(1) The quality of the predictions and the time it takes to complete depends on the primary error detection tool used,"They tried multiple error-detection models: AdaBoost, Decision Trees, Gradient Boosting, Gaussian Naive Bayes, SVM",between .8 to 1,between 100 secs to 1000 secs for datasets of size 20k lines and (?) lines respectively,F1 score of detected errors (this is a error detection tool only),YES,,,14,2.0,2.0,2.0,2.0,2.0,2.0,2.0,4,2.0,2.0,,
116,Deep Learning based Radial Blur Estimation and Image Enhancement,Academia,IEEE International Conference on Electronics Computing and Communication Technologies (CONECCT),conferencePaper,2019,"DC4ML, DC4ML - intro only, ML4DC",img,error detection/repair,"In this paper, we propose a deep learning based pipeline to estimate the radial blur and enhance the deblurred image. The radial blur is introduced in the image as an effect of ego motion in autonomous vehicle systems. The deblurring of the image with radial blur is challenging since most of the blur models do not estimate radial blur. Hence, we design a deep learning based pipeline with estimation and enhancement modules. The estimation module is designed with CuratorNet to estimate radial PSF in two stages. The estimated PSF is used for deblurring of input radial blurred images. The enhancement module is designed with convolutional autoencoder which enhances the deblurred image to remove artefacts in order to detect the traffic signs. We demonstrate the results of the proposed pipeline on synthetic and real images with traffic signs and compare the results with existing methods.  2019 IEEE.","Hurakadli, Vaishnavi; Kulkarni, Sujaykumar; Patil, Ujwala; Tabib, Ramesh; Mudengudi, Uma",Dima,YES,10.1109/CONECCT47791.2019.9012864,,Custom dataset,,,,,,PSNR and SSIM authors do not say what it is!!,,,,11,2.0,2.0,2.0,1.0,1.0,2.0,1.0,2,1.0,1.0,,
117,Toward a view-based data cleaning architecture,,,journalArticle,2019,"DC4ML, DC4ML - intro only",any,error detection/repair,"Big data analysis has become an active area of study with the growth of machine learning techniques. To properly analyze data, it is important to maintain high-quality data. Thus, research on data cleaning is also important. It is difficult to automatically detect and correct inconsistent values for data requiring expert knowledge or data created by many contributors, such as integrated data from heterogeneous data sources. An example of such data is metadata for scientific datasets, which should be confirmed by data managers while handling the data. To support the efficient cleaning of data by data managers, we propose a data cleaning architecture in which data managers interactively browse and correct portions of data through views. In this paper, we explain our view-based data cleaning architecture and discuss some remaining issues. Copyright  2019, The Authors. All rights reserved.","Shimizu, Toshiyuki; Omori, Hiroki; Yoshikawa, Masatoshi",PO,exclusion criteria last step,,,,,,,,,,,,,0,,,,,,,,0,0.0,0.0,,
118,AutoBlock: A hands-off blocking framework for entity matching,Both,International Conference on Web Search and Data Mining,journalArticle,2019,ML4DC,tabular,entity matching / duplicate removal,"Entity matching seeks to identify data records over one or multiple data sources that refer to the same real-world entity. Virtually every entity matching task on large datasets requires blocking, a step that reduces the number of record pairs to be matched. However, most of the traditional blocking methods are learning-free and key-based, and their successes are largely built on laborious human effort in cleaning data and designing blocking keys. In this paper, we propose AutoBlock, a novel hands-off blocking framework for entity matching, based on similarity-preserving representation learning and nearest neighbor search. Our contributions include: (a) Automation: AutoBlock frees users from laborious data cleaning and blocking key tuning. (b) Scalability: AutoBlock has a sub-quadratic total time complexity and can be easily deployed for millions of records. (c) Effectiveness: AutoBlock outperforms a wide range of competitive baselines on multiple large-scale, real-world datasets, especially when datasets are dirty and/or unstructured. Copyright  2019, The Authors. All rights reserved.","Zhang, Wei; Dong, Xin Luna; Wei, Hao; Faloutsos, Christos; Sisman, Bunyamin; Page, David",PO,YES,,(1) Key-based blocking (2) MinHash blocking (3) DeepER,(1) Movie (from Amazon and Wikipedia) (2) Music (from IMDb and WikiData) (3) Grocery (from Amazon and ShopFoodEx),duplicates,-,NN and attention mechanisms,slightly better / comaparable,no comparison with other approaches,(1) recall (2) p/e ratio,,,-,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,0.0,2.0,,
119,"Data Cleaning for Accurate, Fair, and Robust Models: A Big Data - AI Integration Approach [arXiv]",,,journalArticle,2019,"DC4ML, DC4ML - intro only",tabular,error detection/repair,"The wide use of machine learning is fundamentally changing the software development paradigm (a.k.a. Software 2.0) where data becomes a first-class citizen, on par with code. As machine learning is used in sensitive applications, it becomes imperative that the trained model is accurate, fair, and robust to attacks. While many techniques have been proposed to improve the model training process (in-processing approach) or the trained model itself (post-processing), we argue that the most effective method is to clean the root cause of error: the data the model is trained on (pre-processing). Historically, there are at least three research communities that have been separately studying this problem: data management, machine learning (model fairness), and security. Although a significant amount of research has been done by each community, ultimately the same datasets must be preprocessed, and there is little understanding how the techniques relate to each other and can possibly be integrated. We contend that it is time to extend the notion of data cleaning for modern machine learning needs. We identify dependencies among the data preprocessing techniques and propose MLClean, a unified data cleaning framework that integrates the techniques and helps train accurate and fair models. This work is part of a broader trend of Big data -- Artificial Intelligence (AI) integration.","Ki Hyun Tae; Yuji Roh; Young Hun Oh; Hyunsu Kim; Whang, S.E.",PO,score too low - 4,,(1) No pre-processing algorithms (2) Only on pre-processing algo (3) All sequentially,(1) Census income (2) German Credit,"unfairness, poisoning, any dirty data","They only shared the ideas, not the implementation",Tested onto a linear regression model,The same as (3),Faster than (3),"Accuracy, Fairness",,,,8,2.0,2.0,2.0,2.0,0.0,,,0,,,,
120,Automated Evaluation of Out-of-Context Errors,,,conferencePaper,2018,,,,… means of out-of-context error detection. Through the novel design of our … unsupervised models. A standard binary classification neural network assesses the performance of supervised …,"Huber, P; Niehues, J; Waibel, A",,score too low - 4,,,,,,,,,,,CSZNNLWM,,0,,,,,,,,0,0.0,0.0,,
121,Grammatical error checking systems: A review of approaches and emerging directions,,,journalArticle,2018,,,,… [37] investigated a character-level LSTM neural network enabling it to handle previously … to train a neural network on unlabeled data for word-level grammatical error detection. They …,"Madi, N; Al-Khalifa, HS",,exclusion criteria last step,,,,,,,,,,,RKFIN76I,,0,,,,,,,,0,,,,
122,Detecting annotation noise in automatically labelled data,Academia,Annual Meeting of the Association for Computational Linguistics,conferencePaper,2018,"DC4ML, ML4DC",text,mislabel correction,"… We provide a novel approach to error detection that is able to identify errors in automatically … We show how AL can be used to guide an unsupervised generative model, and we will …","Rehbein, I; Ruppenhofer, J",,YES,http://dx.doi.org/10.18653/v1/P17-1107,"Majority vote
Multi-Annotator Competence Estimation
(MACE)",standard newspaper text (English Penn Treebank and English Web treebank),Annotation error (in automatically annotated text),"Most of failed cases are where an adjective (JJ) was mistaken for a past participle (VBN). Also, since it depends on human, the model is affected by under-specified/unclear cases for humans. ",Adopted the generative model (MACE) in Active Learning  ,"Testing on POS: 
Error detection accuracy is significantly improved using proposed approach (after 1000 iterations: 95.1 to 98.6) compared to majority vote and MACE where both had almost similar accuracy (87.4 to 93.9)
using variational inference (VI - AL) gives a substantially higher precision and recall when guiding AL compared to using QBC (difference in precision between 6% to 10% and 10% to 18% in recall)",-,"Accuracy, Recall and Precision",,ASQGRQHN,,9,2.0,2.0,1.0,1.0,1.0,1.0,1.0,4,2.0,2.0,http://www.cl/.http://uni-heidelberg.de/%CB%9Crehbein/resources (not found),
123,Auto-detect: Data-driven error detection in tables,,,journalArticle,2018,ML4DC,tabular,error detection,"… To overcome these issues, instead of relying on supervised methods and human labelers to measure precision, we resort to an unsupervised approach, known as distant-supervision in …","Huang, Z; He, Y",PO,score too low,10.1145/3183713.3196889,,,,,,,,,,7MEWUTXE,,0,,,,,,,,0,0.0,0.0,,
124,Multiple Data Quality Evaluation and Data Cleaning on Imprecise Temporal Data,,,journalArticle,2018,,,,"… However, existing data repairing methods fails to pay attention … in data integration [12], data cleaning approaches have … ER, including probabilistic matching [25], supervised learning [22 …","Ding, X",,Not accessible,10.1007/978-3-030-01391-2_14,,,,,,,,,,HMYT3YDV,,0,,,,,,,,0,,,,
125,Automated Cleaning of Identity Label Noise in A Large-scale Face Dataset Using A Face Image Quality Control,Academia,proquest,thesis,2018,ML4DC,img,mislabel correction,"… We also apply our identity label cleaning method on a subset of … Due to recent advances in using the deep learning techniques … In the current automated id label cleaning methods, low-…","Guo, G; Adjeroh, D; Li, X",PO,YES,,semantic bootstrapping (see [5]) in paper,MS-Celeb-1M.v1 dataset,mislabels,-,SVM and CNNs,-,-,-,,PYXVZK5E,Poor English. Requires manually selecting threshold; thus it is not scalable.,8,2.0,2.0,1.0,1.0,0.0,1.0,1.0,2,1.0,1.0,-,
126,DeepClean: Data Cleaning via Question Asking,Academia,International Conference on Data Science and Advanced Analytics,journalArticle,2018,DC4ML,tabular,error detection/repair,"… in §IV, to generate questions effective for data cleaning, it is … attribute a∗ , we apply a weakly supervised reward- guided … The input to this neural network is the sequence concatenated …","Zhang, X; Ji, Y; Nguyen, C; Wang, T",PO,YES,,Katara,"(1) WikiTables, (2) DBPedia, (3) WebTables, and (4) RelationalTables",any,-,(1) BiLSTM to predict “correlation” between attributes (open page) (2) DrQA for QA engine,Comparable to Katara,-,Precision and recall of error detection ,,LCE89FRZ,I considered it to be ML 4 DC because DrQA is a central component (and it uses ML (NLP) to query Wikipedia),12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,1,0.0,1.0,-,
127,Study on Record Linkage regarding Accuracy and Scalability,,,,2018,ML4DC,tabular,entity matching / duplicate removal,"… for lots of practices including data cleaning, data management, and business in- telligence. Machine learning methods include both unsupervised and supervised learning methods …","Dannelöv, J",PO,exclusion criteria last step,,,,,,,,,,,5IHH4JL8,,0,,,,,,,,0,,,,
128,Power Data Cleaning Method Based on Isolation Forest and LSTM Neural Network,,,journalArticle,2018,,,,"… , data cleaning of power operation and maintenance data can effectively improve data quality, making a good base for data analysis. In the process of data cleaning, the … a data cleaning …","Li, XN; Cai, Y; Zhu, WH",,exclusion criteria last step,10.1007/978-3-030-00018-9_47,,,,,,,,,,V72Z2L46,,0,,,,,,,,0,,,,
129,Performance analysis of machine learning algorithms for missing value imputation,Academia,International Journal of Advanced Computer Science and Applications,journalArticle,2018,ML4DC,tabular,imputation,"Data mining requires a pre-processing task in which the data are prepared, cleaned, integrated, transformed, reduced and discretized for ensuring the quality. Missing values is a universal problem in many research domains that is commonly encountered in the data cleaning process. Missing values usually occur when a value of stored data absent for a variable of an observation. Missing values problem imposes undesirable effect on analysis results, especially when it leads to biased parameter estimates. Data imputation is a common way to deal with missing values where the missing value's substitutes are discovered through statistical or machine learning techniques. Nevertheless, examining the strengths (and limitations) of these techniques is important to aid understanding its characteristics. In this paper, the performance of three machine learning classifiers (K-Nearest Neighbors (KNN), Decision Tree, and Bayesian Networks) are compared in terms of data imputation accuracy. The results shows that among the three classifiers, Bayesian has the most promising performance.","Abidin, N.Z.; Ismail, A.R.",PO,YES,,(1) KNN (2) Bayesian Networks (3) Decision Trees,Open up to see the full list,missing values,-,(1) KNN (2) Bayesian Networks (3) Decision Trees,"Bayesian Network is usually better, but prohibitively expensive on large datasets. Second best is DT.",BN is expensive on large datasets,Different metrics to evaluate the error of the imputation method for missing values for numerical fields: (1) MAE (2) MSE (3) RMSE ,,AMPP66IC,-,0,,,,,,,,0,,,-,
130,Inconsistent data cleaning based on the maximum dependency set and attribute correlation,,,journalArticle,2018,DC4ML,tabular,error detection/repair,"… inconsistency in databases, then we propose an inconsistent data cleaning framework and … corresponding conflict-free data instance using an unsupervised machine learning method …","Li, P; Dai, C; Wang, W",Amin,score too low,,,,,,,,,,,FHDGR22K,,0,,,,,,,,0,0.0,0.0,,
131,Cleaning Crowdsourced Labels Using Oracles For Supervised Learning,Academia,VLDB Endowment,conferencePaper,2018,ML4DC,tabular,mislabel correction,"… supervised learning algorithm for noisy labels. Instead, we aim to develop a label cleaning … the best use of oracle-based cleaning for supervised learning. As shown in Figure 1, suppose …","Dolatshah, M; Teoh, M; Wang, J; Pei, J",PO,YES,,"(1) Random selection of instances (2) Clean instances with highest label noise (not considering its impact on the end model) (3) ActiveClean (4) Uncertainty sampling (i.e. clean the instance the model is the most uncertain about) (5) Expected Error Reduction (similar to what they are doing, read paper for more details) (6) Hung","Pure synthetic datasets (i.e. features and labels): (1.1) 2-d gaussian (small) (1.2) 2-d gaussian (large). Real datasets with synthetic label noise: (2.1) Heart (2.2) diabetes (2.3) cancer. Real dataset, real crowdsource labeling: (3.1) restaurant",mislabel,-,-,It generally is better (i.e. it improve model’s performances the fastest and the most),"Very poor, to return only on instance to be relabeled, models without one instance in the dataset must be trained (i.e. if dataset size is 10, then 10 models must be trained to find the best dataset version). They provide an optimization which they do not explain (pruning)",Accuracy of the end model,,GPE4HXJT,"The paper is way too complicated for what they did. Furthermore, the contribution is almost trivial and the method is highly inefficient. At each iteration, x model must be trained, where x is the size of the dataset.",8,2.0,2.0,1.0,1.0,0.0,1.0,1.0,2,2.0,0.0,,
132,How to Address the Data Quality Issues in Regression Models: A Guided Process for Data Cleaning,Academia,Symmetry,journalArticle,2018,,,error detection/repair,"Today, data availability has gone from scarce to superabundant. Technologies like IoT, trends in social media and the capabilities of smart-phones are producing and digitizing lots of data that was previously unavailable. This massive increase of data creates opportunities to gain new business models, but also demands new techniques and methods of data quality in knowledge discovery, especially when the data comes from different sources (e.g., sensors, social networks, cameras, etc.). The data quality process of the data set proposes conclusions about the information they contain. This is increasingly done with the aid of data cleaning approaches. Therefore, guaranteeing a high data quality is considered as the primary goal of the data scientist. In this paper, we propose a process for data cleaning in regression models (DC-RM). The proposed data cleaning process is evaluated through a real datasets coming from the UCI Repository of Machine Learning Databases. With the aim of assessing the data cleaning process, the dataset that is cleaned by DC-RM was used to train the same regression models proposed by the authors of UCI datasets. The results achieved by the trained models with the dataset produced by DC-RM are better than or equal to that presented by the datasets' authors.","Corrales, D.C.; Corrales, J.C.; Ledezma, A.",Dima,score too low - 3,10.3390/sym10040099,,"UCI Repository of Machine
Learning Databases.",,,,,,Mean Absolute Errors (MAE,NO,CTSHMHVY,Good for snowbowling. Authors present a general approach not a concrete approach.,4,0.0,0.0,1.0,1.0,0.0,0.0,2.0,0,0.0,0.0,,
133,Workload-Aware Discovery of Integrity Constraints for Data Cleaning.,,,journalArticle,2018,DC4ML,tabular,error detection/repair,… Eduardo HM Pena supervised by Eduardo Cunha de Almeida Federal … the effectiveness of current methods for data repairing is highly … Our goal is mining ICs for data cleaning …,"Peña, E",PO,exclusion criteria last step,,,,,,,,,,,F2P7XT3D,,0,,,,,,,,0,,,,
134,An importance-and-semantics-aware approach for entity resolution using MLP,,,conferencePaper,2018,ML4DC,tabular,entity matching / duplicate removal,"Entity resolution (ER), as the process of identifying records which depict the same real-world entity, plays a fundamental role in data integration and data cleaning tasks. Although deep learning techniques of data science have transformed various applications, there are few efforts to leverage these techniques to deal with entity resolution. We also observe the importance of overlapped tokens and the semantic similarity from pre-trained word vectors can benefit ER. To this end, we propose a deep learning based framework for ER, which can leverage the state-of-the-art techniques in deep neural network communities. We also propose an importance-and-semantics-aware approach for ER using a multilayer perceptron (MLP), to combine the importance of overlapped tokens, semantic similarity and textual similarity of corresponding attribute values of pairs. Comparative experiments demonstrate that our method outperforms the traditional method.  Springer Nature Singapore Pte Ltd. 2018.","Xu, Yaoli; Li, Zhanhuai; Qi, Wanhua",PO,Not accessible,10.1007/978-981-13-2203-7_8,,,,,,,,,,G6SIL7EJ,,0,,,,,,,,0,,,,
135,A comparative evaluation of outlier detection algorithms: Experiments and analyses  ,Both,Pattern Recognit.,journalArticle,2018,ML4DC,tabular,outliers detection,"We survey unsupervised machine learning algorithms in the context of outlier detection. This task challenges state-of-the-art methods from a variety of research fields to applications including fraud detection, intrusion detection, medical diagnoses and data cleaning. The selected methods are benchmarked on publicly available datasets and novel industrial datasets. Each method is then submitted to extensive scalability, memory consumption and robustness tests in order to build a full overview of the algorithms characteristics.  2017 Elsevier Ltd","Domingues, Remi; Filippone, Maurizio; Michiardi, Pietro; Zouaoui, Jihane",,YES,10.1016/j.patcog.2017.09.037,"14 methods categorized into:
* probabilistic methods (most of them falls here)
* distance based
* Neighbor based
* information theory
* Neural Networks
* Domain based 
* Isolation methods","15 datasets (synthetic and real) ranging from 723 to 20,000 samples and containing from 6 to 107 features (12 public and 3 proprietary)",outliers,,NA (comparative),"basic results:

robustness: robustness measures on synthetic datasets confirm the poor performance of abod and gwr. 
Good average results were observed for iforest, ocsvm, lof, rkde, dpgmm and gmm. The nearest-neighbor-based methods showed difficulties in handling datasets with a high background noise.","memory:  ocsvm, gwr and abod have the best memory requirements and
scalability and never exceed 250MB RAM, at the cost of a higher
computation time

computation time: iforest and lsa show a very good training and prediction time scaling for both increasing number of features and samples, along with a very small base computation time. dpgmm, gmm and bgm scale well on datasets with a large number of samples and thus could be suitable for systems where fast predictions matter. The base computation time of dpgmm is however an important issue when the number of features becomes higher than a hundred. rkde, ocsvm and sod which have good outlier detection performance on real
datasets are thus computationally expensive, which adds interest to iforest, dpgmm and simpler models such as gmm, kl, ppca or Mahalanobis.","ROC AUC and PR AUC 
robustness (for increasing dimensionality, samples, and noise density), scalability (computation and prediction time when increasing dimensionality and samples), memory usage (for increasing dimensionality, samples)",,PZLJ5JTE,,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,0.0,2.0,,
136,A citeseerx-based dataset for record linkage and metadata extraction,,,conferencePaper,2018,"DC4ML, ML4DC",tabular,entity matching / duplicate removal,"Data cleaning constitutes an important problem in information science. Collecting data about the same entities from multiple sources or following distinct methodologies might result in slightly different, inconsistent data. The objective of data cleaning is to produce a fused version combining the differing data, resulting in a cleaner dataset. In this paper we collect document metadata records from CiteSeerX and build a supervised record linker to Crossref. The supervised method is trained using a manually linked dataset containing 512 verified DOIs-to our knowledge, up to now being the largest such dataset for bibliographic record linkage. We experiment using different supervised learning methods, and also prove experimentally that the accuracy of the attached metadata records can improve the performance of automatic metadata extraction systems.  2018 IEEE.","Bodo, Zalan",PO,exclusion criteria last step,10.1109/SYNASC.2018.00044,,,,,,,,,,,,0,,,,,,,,0,,,,
137,Joint multi-field siamese recurrent neural network for entity resolution,,,conferencePaper,2018,ML4DC,tabular,entity matching / duplicate removal,"Entity resolution which deals with determining whether two records refer to the same entity has a wide range of applications in both data cleaning and integration. Traditional approaches focus on using string metrics to calculate the matching scores of recorded pairs or employing the machine learning technique with hand-crafted features. However, the effectiveness of these methods largely depends on designing good domain-specific metric methods or extracting discriminative features with rich domain knowledge. Also, traditional learning-based methods usually ignore the discrepancy between citations fields. In this paper, to decrease the impact of information gaps between different fields and fully take advantage of semantical and contextual information in each field, we present a novel joint multi-field siamese recurrent architecture. In particular, our method employs word-based Long Short-Term Memory (LSTM) for the fields with the strong relevance between each word and character-based Recurrent Neural Network (RNN) for the fields with the weak relevance between each word, which can exploit each fields temporal information effectively. Experimental results on three datasets demonstrate that our model can learn discriminative features and outperforms several baseline methods and other RNN-based methods.  Springer International Publishing AG, part of Springer Nature 2018.","Lv, Yang; Qi, Lei; Huo, Jing; Wang, Hao; Gao, Yang",PO,Not accessible,10.1007/978-3-319-97310-4_55,,,,,,,,,,,,0,,,,,,,,0,,,,
138,Data civilizer 2.0: A holistic framework for data preparation and analytics,,,journalArticle,2018,"DC4ML, DC4ML - intro only",any,error detection/repair,"Data scientists spend over 80% of their time (1) parameter-tuning machine learning models and (2) iterating between data cleaning and machine learning model execution. While there are existing efforts to support the first requirement, there is currently no integrated workflow system that couples data cleaning and machine learning development. The previous version of Data Civilizer was geared towards data cleaning and discovery using a set of pre-defined tools. In this paper, we introduce Data Civilizer 2.0, an end-to-end workflow system satisfying both requirements. In addition, this system also supports a sophisticated data debugger and a workflow visualization system. In this demo, we will show how we used Data Civilizer 2.0 to help scientists at the Massachusetts General Hospital build their cleaning and machine learning pipeline on their 30TB brain activity dataset.  2019 VLDB Endowment.","Rezig, El Kindi; Cao, Lei; Stonebraker, Michael; Simonini, Giovanni; Tao, Wenbo; Madden, Samuel; Ouzzani, Mourad; Tang, Nan; Elmagarmid, Ahmed K.",PO,score too low,10.14778/3352063.3352108,,,,,,,,,,,,5,2.0,2.0,1.0,0.0,0.0,0.0,0.0,0,0.0,0.0,,
139,Online reasoning for semantic error detection in text,,,journalArticle,2017,ML4DC,text,error detection/repair,"… error detection method using predefined errors for extraction rules [10] and machine learning-… In this paper, we propose online reasoning for semantic error detection, a new method for …","Gutierrez, F; Dou, D; Silva, N de; Fickas, S",,score too low,10.1007/s13740-017-0079-6,,,,,,,,,,XFWX792J,"Not relevant, because not using ML for identifying semantically incorrect content, instead it is based on logic reasoning (consists of two steps: in the first step, sentences are transformed into logic clauses through a combination of IE and vocabulary mapping) and domain knowledge. ",0,,,,,,,,0,0.0,0.0,,
140,Finding and correcting syntax errors using recurrent neural networks,Academia,PeerJ,journalArticle,2017,ML4DC,text,error detection/repair,"… To approximate such a function, we used machine learning to map contexts to categorical … We describe a two-LSTM system, and its syntax error detection strategy. We then describe our …","Santos, EA; Campbell, JC; Hindle, A; Amaral, JN",,YES,https://doi.org/10.7287/peerj.preprints.3123v1,n-gram model of order 10,Built corpus from over 9000 JavaScript repositories mined from Github,Syntax Error,"Low speed for providing suggestions (6 seconds)
Scalability Issue
Evolvement of language definitions cause the tool to fail to find the appropriate syntax error where it otherwise was able to produce a valid fix
",Two LSTM models: one forward and one backward,"correct location of the syntax error: 54.74% in its top 4 suggestions 
exact fix up to 35.50% of the time",- (although they mentioned it is slow they did not show or discuss experiments related to this),"Mean Reciprocal Rank (MRR) for finding syntax error
Percentage and raw number of valid fixes
",,3S8ZRTJP,"not peer reviewed 
shows only the final results when comparing to the other approach but does not show any details or conducted experiments ",9,1.0,1.0,1.0,1.0,2.0,2.0,1.0,2,0.0,2.0,https://github.com/eddieantonio/training-grammar-guru/blob/icsme2017/bin/detect.py,
141,Deep Context Model for Grammatical Error Correction.,,,journalArticle,2017,ML4DC,text,error detection/repair,"… than coverage in error detection. The Precision, recall and F0.5 are defined as follows: … We propose a new neural network architecture to learn context representation and then use …","Wang, C; Li, R; Lin, H",,exclusion criteria last step,,"per error type: CUUI (best classifier in CoNLL-2014 combining rules and machine translation methods)
general (avg over all 5 types): CUUI, top-2 in CoNLL-2014 (classifier based), encoder-decoder recurrent
neural network with an attention mechanism [8], and another classifier-based [10]","wiki dump for training
CoNLL-2014 test dataset for evaluation","Grammatical 
(article, preposition, verb form, noun number, and subjective agreement)",,bidirectional Gated Recurrent Units ,"F0.5: 42.1, 19.1, 15.3, 42.4, 49.9 for article, preposition, verb form, noun number, and subjective agreement, respectively.
Outperforms CUUI in 4 out of 5 error types but mostly non-significant difference (0.1- 1.3) except for article error (8.4)
Outperforms other compared approaches which achieved 36.8 to 40.1 compared to 41.6 for proposed approach",-,"Precision
Recall
F0.5 (assign higher weight to precision)",,HLMC3MI9,"workshop in a c conference, but outperforms top approaches in CONLL-2014. However, no related work section (brief discussion about existing approaches in introduction)",9,2.0,2.0,1.0,2.0,0.0,1.0,1.0,2,0.0,2.0,,
142,Duplicated record detection based on improved RBF neural network,Both,IAEAC,journalArticle,2017,ML4DC,tabular,entity matching / duplicate removal,… Attention towards the data cleaning is a critical issue for the organization of data in many applications [1]. Duplicated record detection is an important part of data cleaning and it is …,"Liu, X; Cai, X; Li, B; Chen, M",PO,score too low - 4,,QL,-,duplicates,-,RBF NN,comparable,-,(1) Accuracy (2) Recall,,T54PFA6Q,-,6,2.0,1.0,0.0,1.0,0.0,1.0,1.0,2,0.0,2.0,-,
143,Holoclean: Holistic data repairs with probabilistic inference,Academia,arxiv,journalArticle,2017,ML4DC,tabular,error repair,"… First, we focus on data repairing methods that rely on integrity constraints [5, 8, 12]. These … • SCARE [39]: This is a state-of-the-art data cleaning method that relies on machine learning …","Rekatsinas, T; Chu, X; Ilyas, IF; Ré, C",PO,YES,,(1) Holistic (2) Katara (3) SCARE,(1) Hospital (2) Flights (3) Food (4) Physicians. All with ground truth values (either it was already available or they manually labeled it),wrong values,-,Factor graph,Holoclean consistently outperforms other approaches,Slower than compared approaches (mostly because it combines other approaches),(1) Precision (i.e. the fraction of correct repairs) (2) Recall (3) F1 Score,YES,PGFQMSFN,-,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,4,2.0,2.0,https://github.com/HoloClean/holoclean,
144,Label denoising based on Bayesian aggregation,Academia,International Journal of Machine Learning and Cybernetics,journalArticle,2017,ML4DC,tabular,mislabel correction,"Label noise is a common problem that affects supervised learning and can produce misleading results. It is shown that only 5% of switched labels lead to a decrease of performances. Therefore, the true class of an instance must be distinguished from its observed label. In the past decade, classification in presence of label noise was the topic of interest. Several scholars focused on kNN-based approaches for data cleansing. These types of approaches often are susceptible to high label noise rate and when a batch of instances with noisy labels are exist they may deteriorate the results. The problem arises since the methods have a local view of instances. Another approach is to have a global view of instances. In a global view, instances with large distance from their respective classes are detected as noisy. A potential problem however is the determination of a threshold. An inappropriate threshold may lead to detection of a correct instance as noisy instance. In this paper a new method for label denoising based on Bayesian aggregation is proposed which solves the problems of kNN-based approaches by aggregating the local and global views of instances. The aggregation of local and global information leads to a more robust and accurate detection of instances with noisy labels and estimation of their true labels. The experimental results show the capabilities and robustness of the proposed method.  2015, Springer-Verlag Berlin Heidelberg.","Bagherzadeh, Parsa; Sadoghi Yazdi, Hadi",Dima,YES,10.1007/s13042-015-0474-y,"IB2, DROP, CCTree, MCTree, WkNN, KDBMS","UCI data sets (https://archive.ics.uci.edu/ml/index.php): BUPA, Ionosphere, Alabone, Pen digits",,Compared approaches are dated from 90ies,SVM with linear kernel,"Precision, Sensitivity, F1",no such performance metrics,Ranking algorithms based on the Friedman test ,,IRWZDJP4,,9,1.0,2.0,1.0,2.0,0.0,1.0,2.0,4,2.0,2.0,,
145,ERBlox: Combining matching dependencies with machine learning for entity resolution,Both,International Journal of Approximate Reasoning,journalArticle,2017,ML4DC,tabular,entity matching / duplicate removal,"Entity resolution (ER), an important and common data cleaning problem, is about detecting data duplicate representations for the same external entities, and merging them into single representations. Relatively recently, declarative rules called matching dependencies (MDs) have been proposed for specifying similarity conditions under which attribute values in database records are merged. In this work we show the process and the benefits of integrating four components of ER: (a) Building a classifier for duplicate/non-duplicate record pairs built using machine learning (ML) techniques; (b) Use of MDs for supporting the blocking phase of ML; (c) Record merging on the basis of the classifier results; and (d) The use of the declarative language LogiQLan extended form of Datalog supported by the LogicBlox platformfor all activities related to data processing, and the specification and enforcement of MDs.  2017 Elsevier Inc.","Bahmani, Zeinab; Bertossi, Leopoldo; Vasiloglou, Nikolaos",PO,score too low,10.1016/j.ijar.2017.01.003,-,(1) Core (2) DBLP,duplicates,-,SVM,-,-,(1) Recall (2) Precision,,,-,6,2.0,1.0,0.0,1.0,0.0,1.0,1.0,0,,,-,
146,Unsupervised record matching with noisy and incomplete data,,,journalArticle,2017,"DC4ML, DC4ML - intro only",tabular,entity matching / duplicate removal,"We consider the problem of duplicate detection in noisy and incomplete data: given a large data set in which each record has multiple entries (attributes), detect which distinct records refer to the same real world entity. This task is complicated by noise (such as misspellings) and missing data, which can lead to records being different, despite referring to the same entity. Our method consists of three main steps: creating a similarity score between records, grouping records together into ""unique entities"", and refining the groups. We compare various methods for creating similarity scores between noisy records, considering different combinations of string matching, term frequency-inverse document frequency methods, and n-gram techniques. In particular, we introduce a vectorized soft term frequency-inverse document frequency method, with an optional refinement step. We also discuss two methods to deal with missing data in computing similarity scores. We test our method on the Los Angeles Police Department Field Interview Card data set, the Cora Citation Matching data set, and two sets of restaurant review data. The results show that the methods that use words as the basic units are preferable to those that use 3-grams. Moreover, in some (but certainly not all) parameter ranges soft term frequency-inverse document frequency methods can outperform the standard term frequency-inverse document frequency method. The results also confirm that our method for automatically determining the number of groups typically works well in many cases and allows for accurate results in the absence of a priori knowledge of the number of unique entities in the data set. Copyright  2017, The Authors. All rights reserved.","Van Gennip, Yves; Hunter, Blake; Ma, Anna; Moyer, Daniel; De Vera, Ryan; Bertozzi, Andrea L.",PO,exclusion criteria last step,,,,,,,,,,,,,0,,,,,,,,0,0.0,0.0,,
147,A framework for assessing achievability of data-quality constraints,,,journalArticle,2017,,,error detection/repair,"Toward addressing this problem, we develop a new framework that abstracts data-processing tools as black-box procedures with only some of the properties exposed, such as the applicability requirements, the parts of the data that the procedure modifies, and the conditions that the data satisfy once the procedure has been applied. We show how common database tasks such as data cleaning and data migration are encapsulated into our framework and, as a proof of concept, we study basic properties of the framework for the case of procedures described by standard relational constraints. We show that, while reasoning in this framework may be computationally infeasible in general, there exist well-behaved special cases with potential practical applications.Assessing and improving the quality of data are fundamental challenges for data-intensive systems that have given rise to numerous applications targeting transformation and cleaning of data. However, while schema design, data cleaning, and data migration are nowadays reasonably well understood in isolation, not much attention has been given to the interplay between the tools addressing issues in these areas. We focus on the problem of determining whether the available data-processing procedures can be used together to bring about the desired quality characteristics of the given data. For an illustration, consider an organization that is introducing new data-analysis tasks. Depending on the tasks, it may be a priority for the organization to determine whether its data can be processed and transformed using the available data-processing tools to satisfy certain properties or quality assurances needed for the success of the task. Here, while the organization may control some of its tools, some other tools may be external or proprietary, with only basic information available on how they process data. The problem is then, how to decide which tools to apply, and in which order, to make the data ready for the new tasks? Copyright  2017, The Authors. All rights reserved.","Chirkova, Rada; Doyle, Jon; Reutter, Juan L.",PO,exclusion criteria last step,,,,,,,,,,,,,0,,,,,,,,0,0.0,0.0,,
148,Data Improving in Time Series Using ARX and ANN Models,Academia,IEEE Transactions on Power Systems,journalArticle,2017,"DC4ML, ML4DC",tabular,error detection/repair,"Anomalous data can negatively impact energy forecasting by causing model parameters to be incorrectly estimated. This paper presents two approaches for the detection and imputation of anomalies in time series data. Autoregressive with exogenous inputs (ARX) and artificial neural network (ANN) models are used to extract the characteristics of time series. Anomalies are detected by performing hypothesis testing on the extrema of the residuals, and the anomalous data points are imputed using the ARX and ANN models. Because the anomalies affect the model coefficients, the data cleaning process is performed iteratively. The models are re-learned on “cleaner” data after an anomaly is imputed. The anomalous data are reimputed to each iteration using the updated ARX and ANN models. The ARX and ANN data cleaning models are evaluated on natural gas time series data. This paper demonstrates that the proposed approaches are able to identify and impute anomalous data points. Forecasting models learned on the unclean data and the cleaned data are tested on an uncleaned out-of-sample dataset. The forecasting model learned on the cleaned data outperforms the model learned on the unclean data with 1.67% improvement in the mean absolute percentage errors and a 32.8% improvement in the root mean squared error. Existing challenges include correctly identifying specific types of anomalies such as negative flows.",H. N. Akouemo; R. J. Povinelli,Dima,YES,10.1109/TPWRS.2017.2656939,,,,,,,,,,,Good for snowbowling,10,1.0,2.0,2.0,1.0,1.0,1.0,2.0,2,1.0,1.0,,
149,Automated data cleansing through meta-learning,Both,AAAI,conferencePaper,2017,"DC4ML, DC4ML - intro only, ML4DC",any,holistic,"Data preprocessing or cleansing is one of the biggest hurdles
in industry for developing successful machine learning applications. The process of data cleansing includes data imputation, feature normalization & selection, dimensionality reduction, and data balancing applications. Currently such preprocessing is manual. One approach for automating this process
is meta-learning. In this paper we experiment with state of
the art meta-learning methodologies and identify the inadequacies and research challenges for solving such a problem.","Gemp, Ian; Theocharous, Georgios; Ghavamzadeh, Mohammad",PO,YES,,None,(1) Scikit-Learn’s make classification method (2) Adobe’s internal dataset (3) classification tasks downloaded from http://openml.org/,-,Does not works. I suppose the meta feature they use are bad. They should have used embeddings or a model that directly output similarity scores.,-,-,-,"Normalized relative rank (worst results of the experiments tend toward 0, while the best, 1)",YES,,,9,2.0,2.0,1.0,2.0,0.0,1.0,1.0,4,2.0,2.0,,
150,A novel cost-based model for data repairing,,,journalArticle,2016,DC4ML,tabular,error detection/repair,"In this paper, we
propose a revised semantics of violations and data consistency w.r.t. a set of ICs. The revised semantics relies on string similarities, in
contrast to traditional methods that use syntactic error detection using string equality. Along with the revised semantics, we also
propose a new cost model to quantify the cost of data repair by considering distances between strings. We show that the revised
semantics provides a significant change for better detecting and grouping errors, which in turn improves both precision and recall of the
following data repairing step. We prove that finding minimum-cost repairs in the new model is NP-hard, even for a single FD. We devise
efficient algorithms to find approximate repairs. In addition, we develop indices and optimization techniques to improve the efficiency.
Experiments show that our approach significantly outperforms existing automatic repair algorithms in both precision and recall.","Hao, S; Tang, N; Li, G; He, J; Ta, N; ...",Dima,score too low,,"We compared with NADEEF [11], Unified Repair Model
(URM) [37] and Llunatic [38] for FD repairs. For URM, to
ensure a fair comparison, we implemented it with only data
repair option without constraint repair. For Llunatic, we
chose the frequency cost-manager and Metric 0.5 was used
to measure the repair quality (for each cell repaired to a variable,
it was counted as a partially correct change). [11] M. Dallachiesa, et al., “NADEEF: A commodity data cleaning
system,” in Proc. ACM SIGMOD Int. Conf. Manage. Data, 2013,
pp. 541–552., [37] F. Chiang and R. J. Miller, “A unified model for data and constraint
repair,” in Proc. IEEE 27th Int. Conf. Data Eng., 2011,
pp. 446–457. [38] F. Geerts, G. Mecca, P. Papotti, and D. Santoro, “The LLUNATIC
data-cleaning framework,” Proc. VLDB Endowment, vol. 6, no. 9,
pp. 625–636, 2013.","HOSP was taken from the US Department of
Health Services (http://www.hospitalcompare.hhs.gov/).
We used 20k records with 19 attributes and 9 FDs.",,I think the main limitation is that still all the FD (functional dependencies) relations need to be manually defined. ,,,"Greedy-S ran faster than NADEEF and Llunatic but slower than URM, NADEEF and Llunatic were slow as they
were DBMS-based algorithms. When handling multiple FDs,
Appro-M with pruning ran fastest. After getting the repair
targets in each constraint, Appro-M joined them and computed
the best repair for each tuple utilizing an effective
tree index."," We used precision and recall to evaluate
the repairing quality: precision is the ratio of correctly
repaired attribute values to the number of all the repaired
attributes; and recall is the ratio of correctly repaired attribute
values to the number of all erroneous values.",,FXKZHDSH,"The paper is well written, however it’s quite difficult to understand the details of the algorithm to find the independent set with minimal repair cost. They give an example, but still it’s not clear enough as for me. ",12,2.0,1.0,2.0,2.0,1.0,2.0,2.0,0,0.0,0.0,,
151,Numerically grounded language models for semantic error correction,Academia,arxiv,conferencePaper,2016,ML4DC,text,error detection/repair,… Semantic error detection and correction is an important task for applications such as fact … Our contributions are: 1) a straightforward extension to recurrent neural network (RNN) …,"Spithourakis, GP; Augenstein, I; Riedel, S",,YES,http://dx.doi.org/10.18653/v1/D16-1101,"1. random scorer: assigns random scores from a uniform distribution. 
2 always (never) scorers: assign the lowest (highest) score to the original document and uniformly random scores to the corrections.
3. base-LM (a single-layer LSTM)
4. LM grounded in numeric quantities mentioned inline with text 
5. LM conditioned on a potentially incomplete KB 
6. 4&5",clinical records from the London Chest Hospital,Semantical ,,"LM grounded in numeric quantities mentioned inline with text 
LM conditioned on a potentially incomplete KB 
6. grounded-conditional (g-conditional)"," g-conditional models has the best results and improve the base-LM. While, grounded models has better results than base-LM, conditional models has worse results. 
Compared to baseline (random, always, never), LM-based models improved the results significantly.",-,"Mean Average Precision (MAP)
Precision
Recall
F1
perplexity (PP) 
adjusted perplexity (APP)",,5VI3A7PB,"they compared to baseline (random, always, never) as no previous approach has explored inline grounded numbers",9,2.0,2.0,1.0,2.0,0.0,1.0,1.0,2,0.0,2.0,,
152,A density-based data cleaning approach for deduplication with data consistency and accuracy,,,journalArticle,2016,DC4ML,tabular,more-than-one,… ] and unsupervised learning techniques [30] tried to solve the drawbacks of the supervised … Another data repair approach that deals with consistency and accuracy which is also based …,"Al-janabi, S; Janicki, R",PO,score too low,,,,,,,,,,,I32E5C3E,,0,,,,,,,,0,0.0,0.0,,
153,Repair diversification: A new approach for data repairing,,,journalArticle,2016,DC4ML,tabular,error detection/repair,"… risk of losing critical data, the guided data repairing framework [24] is recently proposed to … are first presented to the users, and machine learning techniques are then applied to user …","He, C; Tan, Z; Chen, Q; Sha, C",PO,score too low,,,,,,,,,,,3FS2X9T2,,0,,,,,,,,0,0.0,0.0,,
154,Entity matching across multiple heterogeneous data sources,,,journalArticle,2016,ML4DC,tabular,entity matching / duplicate removal,"… It is a well known and paramount problem that arises in many research fields, including data cleaning and integration, information retrieval and machine learning. There are many …","Kong, C; Gao, M; Xu, C; Qian, W; Zhou, A",PO,Not accessible,10.1007/978-3-319-32025-0_9,,,,,,,,,,PFLF9MZP,,0,,,,,,,,0,,,,
155,Detecting data errors: Where are we and what needs to be done?,,,journalArticle,2016,DC4ML,any,error detection/repair,… data cleaning tools that utilize a variety of error detection techniques. We also collected five real-… After each round we retrain the machine learning algorithms and compute precision and …,"Abedjan, Z; Chu, X; Deng, D; Fernandez, RC; ...",PO,score too low,10.14778/2994509.2994518,,,,,,,,,,S7YH7ING,,0,,,,,,,,0,0.0,0.0,,
156,Improving Data Quality by Leveraging Statistical Relational Learning.,Academia,ICIQ,journalArticle,2016,DC4ML,tabular,error detection/repair,"… SRL is a branch of machine learning that models joint distributions over relational data. … We define data cleaning rules in the form of CFDs and MDs. For example, we express φ as …","Visengeriyeva, L; Akbik, A; Kaul, M; Rabl, T; Markl, V",PO,YES,,against using integrity constraints individually,(1) hospital (2) TPC-h (3) MSAG,anything that can be discrovered by integrity constraints,-,probabilistic graphical model,better than compared approaches (obvs),-,precision recall f1,YES,KPW96E84,"not worth covering in details, just mention it in the SLR.",8,2.0,2.0,1.0,1.0,0.0,1.0,1.0,2,0.0,2.0,-,
157,Asking for a second opinion: Re-querying of noisy multi-class labels,Industry,ICASSP,journalArticle,2016,DC4ML,any,mislabel correction,… several different scenarios including data cleansing as a pre… represents most large-scale supervised learning tasks. We … nonlinear classifier such as a neural network or decision tree. In …,"Stokes, JW; Kapoor, A; Ray, D",Dima,YES,,,,,,,,,maximum negative margin,,DH9SVUGN,,10,1.0,2.0,1.0,2.0,1.0,1.0,2.0,2,1.0,1.0,,
158,WENN for individualized cleaning in imbalanced data,Academia,International Conference on Pattern Recognition (ICPR),conferencePaper,2016,"DC4ML, DC4ML - intro only",any,outliers detection,"This paper proposes individualized cleaning for diverse imbalanced data sets. Existing techniques for data cleaning have difficulties with rare cases and outliers in minority class, especially, in highly unbalanced data. The drawback leads incomplete and imprecise examples to removal. In order to enhance the robustness and perform thorough data cleaning, we propose a weighted edited nearest neighbor (WENN), which detects and removes noisy examples from both classes intelligently. It considers individual characteristics of each imbalanced data, involving global class imbalance and local distribution. The main idea of the proposed method is to carefully put more focus on the majority class than the minority class during data cleaning. Extensive experiments over synthetic and real data clearly validate the superiority of our approach against other data cleaning methods.","Hongjiao Guan; Yingtao Zhang; Min Xian; Cheng, H.D.; Xianglong Tang",PO,YES,10.1109/ICPR.2016.7899676,(1) ENN (the method they improve) (2) IPF ,a lot of real and synthetic ones,any (outliers),-,-,"on average, slightly better on real datasets. On synthetic ones, it is clearly better..",-,AUC (tp rate vs fp rate for different classification thresholds) and sensitivity (whatever that is - not explained),,,,7,1.0,1.0,1.0,2.0,0.0,1.0,1.0,2,2.0,0.0,,
159,Entity Resolution Using Convolutional Neural Network,Academia,Procedia Comput. Sci.,journalArticle,2016,ML4DC,img,entity matching / duplicate removal,"Entity resolution is an important application in field of data cleaning. Standard approaches like deterministic methods and probabilistic methods are generally used for this purpose. Many new approaches using single layer perceptron, crowdsourcing etc. are developed to improve the efficiency and also to reduce the time of entity resolution. The approaches used for this purpose also depend on the type of dataset, labeled or unlabeled. This paper presents a new method for labeled data which uses single layered convolutional neural network to perform entity resolution. It also describes how crowdsourcing can be used with the output of the convolutional neural network to further improve the accuracy of the approach while minimizing the cost of crowdsourcing. The paper also discusses the data pre-processing steps used for training the convolutional neural network. Finally it describes the airplane sensor dataset which is used for demonstration of this approach and then shows the experimental results achieved using convolutional neural network.  2016 The Authors.","Gottapu, Ram Deepak; Dagli, Cihan; Ali, Bharami",PO,YES,10.1016/j.procs.2016.09.306,Jaccard similarity (more on that on the Notion page),A private sensor description dataset from Boeing,duplicates,-,CNN,"53% accuracy, better than Jaccard’s similarity",8 times slower than Jaccard’s similarity,accuracy,,,…,9,2.0,2.0,2.0,1.0,0.0,1.0,1.0,2,0.0,2.0,-,
160,Data cleansing using clustering,,International Conference on Man–Machine Interactions ICMMI,conferencePaper,2016,"DC4ML, ML4DC",tabular,mislabel correction,"One of the data quality issues, that heavily influences the performance of the classifiers learned from data is the amount of examples, that are indistinguishable but belong to different classes. Such situation occurs not only if the data (either original or preprocessed) contain contradictions, i. e. examples that have same values of input attributes but different class labels but also if different (but very similar) examples of different classes remain indistinguishable during the subsequent machine learning step. We propose a clustering based approach that tries to resolve such situation by identifying and removing these ""weak"" contradictions. The effect of data cleansing is then evaluated using decision tree learning algorithm on the reduced data set. To experimentally evaluate our method, we used some benchmark data from the UCI Machine Learning repository.  Springer International Publishing Switzerland 2016.","Berka, Petr",Dima,Not accessible,10.1007/978-3-319-23437-3_33,"K-medoid [17], DBSCAN [18], APCluster [8], StdHier","Gene Expression Omnibus (GEO) is one of the largest,
best-known biomedical databases (Barrett T, Wilhite SE, Ledoux P, et al. Ncbi geo: archive for functional
genomics data sets – update. Nucleic Acids Res. 2013;41:991–5)",,"It did not
perform very well on skewed clustering, which means
that some clusters possessed a large amount of keys while
the others had few. Thresholds must be experimentally determined.",,"F-Score (FS), Entropy (E) and Rand Index (RI)",,,,,,0,,,,,,,,2,0.0,2.0,,
161,Data cleaning using complementary fuzzy support vector machine technique,,,conferencePaper,2016,"DC4ML, DC4ML - intro only, ML4DC",tabular,error detection/repair,"In this paper, a Complementary Fuzzy Support Vector Machine (CMTFSVM) technique is proposed to handle outlier and noise in classification problems. Fuzzy membership values are applied for each input point to reflect the degree of importance of the instances. Datasets from the UCI and KEEL are used for the comparison. In order to confirm the proposed methodology, 40% random noise is added to the datasets. The experiment results of CMTFSVM are analysed and compared with the Complementary Neural Network (CMTNN). The outcome indicated that the combined CMTFSVM outperformed the CMTNN approach.  Springer International Publishing AG 2016.","Pruengkarn, Ratchakoon; Wong, Kok Wai; Fung, Chun Che",PO,Not accessible,10.1007/978-3-319-46672-9_19,,,,,,,,,,,,0,,,,,,,,0,,,,
162,ActiveClean: An interactive data cleaning framework for modern machine learning,Academia,ACM SIGMOD,conferencePaper,2016,"DC4ML, ML4DC",tabular,error detection/repair,"Databases can be corrupted with various errors such as missing, incorrect, or inconsistent values. Increasingly, modern data analysis pipelines involve Machine Learning, and the effects of dirty data can be difficult to debug. Dirty data is often sparse, and naive sampling solutions are not suited for high-dimensional models. We propose ActiveClean, a progressive framework for training Machine Learning models with data cleaning. Our framework updates a model iteratively as the analyst cleans small batches of data, and includes numerous optimizations such as importance weighting and dirty data detection. We designed a visual interface to wrap around this framework and demonstrate ActiveClean for a video classification problem and a topic modeling problem.  2016 ACM.","Krishnan, Sanjay; Franklin, Michael J.; Goldberg, Ken; Wang, Jiannan; Wu, Eugene",PO,YES,10.1145/2882903.2899409,"(1) 2 methods that randomly sample instances, (2) Active learning (i.e. selecting instances to clean based on the uncertainty of the model) (3) Oracle (i.e. the fastest way to improve model performances) (4) No sampling (i.e. no cleaning)",(1) Real datasets: (1.1) IMDB (1.2) Dollar for docs (3) (2) Synthetic datasets (2): (2.1) Income Classiﬁcation (Adult) and (2.2) Seizure Classiﬁcation (EEG) (2.3) MNIST numbers,"It could support any, but in their experiment, they used rule-based detection and outlier detection.",(1) The approach is only compatible with convex-loss models ,The models used to select samples to clean (based on its gradient) are convex-loss models.,Converges faster to a lower level of (1) model error and (2) test error,"generally converges faster than other approaches - time, complexity, etc. not mentioned","For the real datasets (1): (1.1) Model error, which is the distance between the trained model and true
model if all data were cleaned θ − θ(c), and (1.2) test error, which is the prediction accuracy of the model on a held-out set of clean data.
For the synthetic datasets (2): (2.1) test error and (2.2) % of detected errors",,,,8,1.0,2.0,1.0,1.0,1.0,1.0,1.0,4,2.0,2.0,,
163,Accurate Data Cleansing through Model Checking and Machine Learning Techniques,,,conferencePaper,2015,,,,"Most researchers agree that the quality of real-life data archives is often very poor, and this makes the definition and realisation of automatic techniques for cleansing data a relevant issue. In such a scenario, the Universal Cleansing framework has recently been proposed to automatically identify the most accurate cleansing alternatives among those synthesised through model-checking techniques. However, the identification of some values of the cleansed instances still relies on the rules defined by domain-experts and common practice, due to the difficulty to automatically derive them (e.g. the date value of an event to be added). In this paper we extend this framework by including well-known machine learning algorithms - trained on the data recognised as consistent - to identify the information that the model based cleanser couldn't produce. The proposed framework has been implemented and successfully evaluated on a real dataset describing the working careers of a population.","Boselli, R; Cesarini, M; Mercorio, F; Mezzanzanica, M",PO,Not accessible,10.1007/978-3-319-25936-9_5,,,,,,,,,,,,0,,,,,,,,0,,,,
