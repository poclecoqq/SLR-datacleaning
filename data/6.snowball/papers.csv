Name,Author's affiliation,venue name,Item Type,Publication Year,from,Subject category,Data type,task,Abstract Note,Author,Read by,Relevant,DOI,Compared approaches,Dataset,Error type,Limitations and shortcomings,Model,"Performance (ML-wise e.g. accuracy, etc.)","Performance (engineering-wise e.g. time, memory, etc.)",Quality measurements,Key,Q1,Q1.1,Q1.2,Q1.3,Q1.4,Q1.5,Q1.6,Q1.7,Q2,Q2.1,Q2.2,In SLR,Personal comments,Replication package link
BoostClean: Automated Error Detection and Repair for Machine Learning,Academia,arxiv,conferencePaper,2017.0,Nearest neighbor classifiers over incomplete information: From certain answers to certain predictions (https://www.notion.so/Nearest-neighbor-classifiers-over-incomplete-information-From-certain-answers-to-certain-prediction-7dd5a6e7a6bd40c6aa37268572360652?pvs=21) ,"DC4ML, ML4DC",tabular,error detection/repair,,"Sanjay Krishnan, Michael J. Franklin, Ken Goldberg, Eugene Wu",PO,YES,,"dumb baselines, see section “6.1.1 methods” in paper (note it was one of the first paper in the field, thus not a lot of tools to compare against)","12 datasets, open to see the list",domain value violations,(1) limited to domain value violations (2) shown to overfit if the number of models in the ensemble is too large ,"random forest (end model that does predictions, not data cleaning)","better in most cases, except when the datasets had a lot of errors",around 30 min for a 6M records dataset,accuracy of end ML model,,13,2.0,2.0,2.0,2.0,1.0,2.0,2.0,4,2.0,2.0,YES,-,-
Zeroer: Entity resolution using zero labeled examples,Academia,ACM SIGMOD,conferencePaper,2020.0,CleanML: A study for evaluating the impact of data cleaning on ml classification tasks (https://www.notion.so/CleanML-A-study-for-evaluating-the-impact-of-data-cleaning-on-ml-classification-tasks-69eb5196671541a9bf9ab6413f900222?pvs=21) ,ML4DC,tabular,entity matching / duplicate removal,,"R. Wu, S. Chaba, S. Sawlani, X. Chu, and S. Thirumuruganathan",,YES,,See papers (there a re 10),(1) Fodors-Zagat [2] (2) DBLP-ACM [1] (3) DBLP-Scholar [1] (4) Abt-Buy [1] (5) Amazon-Google products [1],duplicates,-,gaussian mixture,"better than unsupervised methods, close to supervised ones",Generally lower,F-score,,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,0.0,2.0,,,https://github.com/chu-data-lab/zeroer
"Deep learning for entity matching: A
design space exploration",Both,ACM SIGMOD,conferencePaper,2018.0,CleanML: A study for evaluating the impact of data cleaning on ml classification tasks (https://www.notion.so/CleanML-A-study-for-evaluating-the-impact-of-data-cleaning-on-ml-classification-tasks-69eb5196671541a9bf9ab6413f900222?pvs=21) ,ML4DC,tabular,entity matching / duplicate removal,,"S. Mudgal, H. Li, T. Rekatsinas, A. Doan, Y. Park, G. Krishnan, R. Deep,
E. Arcaute, and V. Raghavendra",PO,YES,,Magellan,See appendix B.1,duplicate,-,-,Generally above,Generally above,F1 score,,11,2.0,2.0,2.0,2.0,0.0,1.0,2.0,2,0.0,2.0,,They spend a lot of time explaining things that are not their work…,http://sites.google.com/site/anhaidgroup/projects/magellan
Distributed representations of tuples for entity resolution.,Academia,VLDB Endowment,conferencePaper,2018.0,CleanML: A study for evaluating the impact of data cleaning on ml classification tasks (https://www.notion.so/CleanML-A-study-for-evaluating-the-impact-of-data-cleaning-on-ml-classification-tasks-69eb5196671541a9bf9ab6413f900222?pvs=21) ,ML4DC,tabular,entity matching / duplicate removal,,"M. Ebraheem, S. Thirumuruganathan, S. Joty, M. Ouzzani, and N. Tang.",,YES,,(1) Magellan (2) other crowd-sourced approaches,(1) Walmart-Amazon (2) Amazon-Google (3) DBLP-ACM (4) DBLP-Scholar (5) DBLP-Citeseer (6) Fodors-Zagat,duplicate,-,see paper,comparable to Magellan,-,F1 score,,11,2.0,2.0,1.0,2.0,0.0,2.0,2.0,2,0.0,2.0,,-,-
Baran: Effective Error Correction via a Unified Context Representation and Transfer Learning,Academia,VLDB Endowment,conferencePaper,2020.0,Semi-Supervised Data Cleaning with Raha and Baran. (https://www.notion.so/Semi-Supervised-Data-Cleaning-with-Raha-and-Baran-f996d8b9319a4a928594545863346a8f?pvs=21) ,ML4DC,tabular,error repair,,,PO,YES,,(1) KATARA (2) SCARE (3) Holistic (4) HoloClean,(1) Hospital (2) Flights (3) Address (4) Beers (5) Rayyan (6) IT (7) Tax,any,-,"adaboost. Others have been tried, with comparable performance",Better on every dataset,"(1) Comparable time to complete, (2) requires only a few dozen of manually cleaned instances","Precision, Recall and F1 score of the repairs (how accurate the repairs are)",,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,4,2.0,2.0,YES,,https://github.com/bigdama/raha
Metadata-driven error detection,Academia,International Conference on Scientific and Statistical Database Management,conferencePaper,2018.0,Advancing Data Curation with Metadata and Statistical Relational Learning / Verbesserung der Datenvorbereitung Mit Metadaten und Statistisch-Relationalem Lernen (https://www.notion.so/Advancing-Data-Curation-with-Metadata-and-Statistical-Relational-Learning-Verbesserung-der-Datenvo-9cdc61d755194452b4490a5edb160f16?pvs=21) ,ML4DC,tabular,error detection,,Larysa Visengeriyeva and Ziawasch Abedjan.,PO,YES,,"UnionAll, min-K, and Majority wins",(1) Address (dirty version given) (2) HOSPITAL (dirty version obtained using BART) (3) Salaries (dirty version obtained using BART) (4) Flights (dirty version given),any,-,"log reg, Neural Network, Decision Tree, and Naive Bayes",better on all datasets (but the compared approach are bad),-,precision recall f1-score,,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,0.0,2.0,YES,"Their idea of using metadata to predict errors can sometimes be seen as some sort of feature engineering (e.g. knowing the distribution of data), some other times, another sub-error detection tool (e.g. they create functional dependencies).",https://github.com/visenger/DetectEr
Complaint-driven Training Data Debugging for Query 2.0,Industry,ACM SIGMOD,conferencePaper,2020.0,Complaint-Driven Training Data Debugging at Interactive Speeds (https://www.notion.so/Complaint-Driven-Training-Data-Debugging-at-Interactive-Speeds-072249e2d4704c56bcf21d6baaa336b8?pvs=21) ,DC4ML,tabular,error detection,,"Weiyuan Wu, Eugene Wu, Lampros Flokas, Jiannan Wang",PO,YES,,(1) Loss: giving the users samples in the training set that had the highest training loss (2) InfLoss: use influence analysis and use total training loss as a loss function,(1) DBLP-GOOG (2) ADULT (3) ENRON (4) MNIST,any,-,"depends on the one used for prediction. They used Linear models in this paper, but also shared their results with NN in the associated technical report.",better than compared approaches. Open up for more details.,comparable to other approaches (i.e. 1 sec on DBLP-GOOG dataset). open up for more details,(1) recall in top-k samples (2) F1-score (3) AUC of the curve created by (1) ,,8,1.0,2.0,2.0,1.0,0.0,1.0,1.0,3,2.0,1.0,,(1) limited to binary predictions (2) the authors do not mention what were the exact queries they used in their experiments; hence it is difficult to evaluate their method (3) ambiguous definition of problems and ambiguous figures ,-
O2u-net: A simple noisy label detection approach for deep neural networks,Industry,IEEE/CVF international conference on computer vision,conferencePaper,2019.0,Chef: A cheap and fast pipeline for iteratively cleaning label uncertainties (https://www.notion.so/Chef-A-cheap-and-fast-pipeline-for-iteratively-cleaning-label-uncertainties-e46c0151e99f4d46867dad821aa8c900?pvs=21) ,,any,mislabel correction,,"Jinchi Huang, Lie Qu, Rongfei Jia, and Binqiang Zhao.",PO,YES,,(1) Direct Training (classifier trained on dirty dataset) (2) Bootstrapping (?) (3) Co-teaching (4) MentorNet (5) CurriculumNet,"(1) CIFAR-10, (2) CIFAR-100, (3) Mini-ImageNet , (4) Clothing1M.
1,2,3 with synthetic noise (random and paired synthetic noise) and 4 with real noise.",Mislabels,-,Any,Significantly above,-,"precision, recall of detected mislabels, and end-model performance (after noisy labels are removed)",,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,4,2.0,2.0,,Elegant,https://github.com/hjimce/O2U-Net
Deep Entity Matching with Pre-Trained Language Models,Both,arxiv,journalArticle,2020.0,Deep entity matching with adversarial active learning (https://www.notion.so/Deep-entity-matching-with-adversarial-active-learning-f75397bd923d4671b0e9102e91c7b654?pvs=21) ,,,entity matching / duplicate removal,,,PO,YES,,(1) DeepMatcher (both versions) and (2) different baselines of Ditto (the approach they propose),“with all the 13 publicly available datasets used for evaluating DeepMatcher [34]”,duplicate,-,transformer,Better in almost all cases,Better in almost all cases,F1 score,,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,0.0,2.0,,-,https://github.com/megagonlabs/ditto
Deep sequence-to-sequence entity matching for heterogeneous entity resolution,Both,ACM CIKM,conferencePaper,2019.0,Deep entity matching with adversarial active learning (https://www.notion.so/Deep-entity-matching-with-adversarial-active-learning-f75397bd923d4671b0e9102e91c7b654?pvs=21) ,,tabular,entity matching / duplicate removal,,,PO,YES,,(1) DeepMatcher (2) Magellan,(1) Walmart-Amazon (2) DBLP-ACM (3) DBLP-Scholar (4) Hema-Taobao,duplicates,-,see paper,Above,-,precision recall f1,,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,0.0,2.0,,-,-
Low-resource deep entity resolution with transfer and active learning,Both,arxiv,journalArticle,2019.0,Deep entity matching with adversarial active learning (https://www.notion.so/Deep-entity-matching-with-adversarial-active-learning-f75397bd923d4671b0e9102e91c7b654?pvs=21) ,,tabular,entity matching / duplicate removal,,,PO,YES,,"Magellan and Deep learning for entity matching: A
design space exploration (https://www.notion.so/Deep-learning-for-entity-matching-A-design-space-exploration-332397a5ffcc4d74b72d56a876090432?pvs=21) ",(1) DBLP-ACM (2) DBLP-Scholar (3) Cora (4) Fodors-Zagats (5) Zomato-Yelp (6) Amazon-Google,duplicates,-,see paper,generally better after 1000 samples labeled,-,"F1, precision, recall",,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,0.0,2.0,,-,-
Active cleaning of label noise,Academia,Pattern Recognit.,journalArticle,2016.0,Combining Outlier Detection and Reconstruction Error Minimization for Label Noise Reduction (https://www.notion.so/Combining-Outlier-Detection-and-Reconstruction-Error-Minimization-for-Label-Noise-Reduction-f9eb0ef3d6174207a38579eb0359bbf2?pvs=21) ,,any,mislabel correction,,,PO,YES,,-,"UCI Letter recognition dataset, the MNIST digit dataset, the wine quality dataset [16], and the Wisconsin Breast cancer dataset",mislabels,-,SVM,-,-,many,,11,2.0,2.0,1.0,2.0,0.0,2.0,2.0,4,2.0,2.0,,-,-
Learning from noisy large-scale datasets with minimal supervision.,Both,IEEE/CVF CVPR,conferencePaper,2017.0,Interactive correction of mislabeled training data (https://www.notion.so/Interactive-correction-of-mislabeled-training-data-7dbbda238f09473c9230f756cb8e32a4?pvs=21) ,,,mislabel correction,,,PO,YES,,"(1) train the classifier on the large dirty dataset and finetune on a hand-cleaned dataset (2) similar to 1, but finetune on a mix of clean and dirty sample 9:1 ratio (3) Variations of their approach: (3.1) while pre-training the cleaning network and then  (3.2) without pre-training the cleaning network",Open Image dataset,mislabels,-,NN and CNN,Better,-,"performance of the end-model (accuracy, recall, precision, etc.)",,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,4,2.0,2.0,,nice read,-
"Cleannet: Transfer learning
for scalable image classiﬁer training with label noise.",Industry,IEEE/CVF CVPR,conferencePaper,2018.0,Interactive correction of mislabeled training data (https://www.notion.so/Interactive-correction-of-mislabeled-training-data-7dbbda238f09473c9230f756cb8e32a4?pvs=21) ,,,mislabel correction,,,PO,YES,,"A bunch of trivial baselines, see section 4.2 in paper for more detail.",(1) Food-101N (2) Clothing1M (3) WebVision,mislabels,-,NN with self attention,better..,-,(1) Accuracy of the end model (2) error rate (?),,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,4,2.0,2.0,,-,https://github.com/kuanghuei/clean-net
Training set debugging using trusted items.,Academia,AAAI,conferencePaper,2018.0,Interactive correction of mislabeled training data (https://www.notion.so/Interactive-correction-of-mislabeled-training-data-7dbbda238f09473c9230f756cb8e32a4?pvs=21) ,,,mislabel correction,,,PO,YES,,(1) Influence function (Koh & Liang) (2) Nearest neighbor (3) Label noise detection (Oracle) (Bhadra et Hein),(1) Fairness datasets: (1.1) Adult (1.2) German; (2) Handwritten Digits,mislabels,Only for classifiers that are strongly convex and twice differentiable (e.g. logistic regression),-,Generally better,-,precision-recall curve,,14,2.0,2.0,2.0,2.0,2.0,2.0,2.0,3,2.0,1.0,,-,http://pages/.http://cs.wisc.edu/~jerryzhu/DUTI
Compositional sequence labeling models for error detection in learner writing,Academia,arxiv,journalArticle,2016.0,,ML4DC,text,error detection,"In this paper, we present the first experiments using neural network models for the task of error detection in learner writing. We perform a systematic comparison
of alternative compositional architectures and propose a framework for error detection based on bidirectional LSTMs. Experiments on the CoNLL-14 shared task dataset show the model is able to outperform other participants on detecting errors in learner writing. Finally, the model
is integrated with a publicly deployed self-assessment system, leading to performance comparable to human annotators.",,,YES,https://doi.org/10.48550/arXiv.1607.06153,"*CRF model
*top 3 participants in the CONLL-14 shared task:
1. CAMB
2. CCUI
3. AMU
*combined models: P1+P2+S1+S2

**for essay scoring: Human annotators and SAT","**for training:
*FCE-public
*NUCLE (the NUS Corpus of Learner English)
*IELTS (subset)
*FCE (a larger selection of FCE texts from the CLC)
*CPE (essays from the proficient examination level in the CLC)
*CAE (essays from the advanced examination level in the CLC)
**for testing:
CoNLL-14
FCE-test (only for essay scoring)","all error types 

*unlike others it’s not specific for preposition, verbs, etc. but they did not define whether it’s grammatical only or also semantical, spelling,.. ","The proposed model outperforms other approaches (CAMB, CUUI, AMU and P1+P2+S1+S2) but it can only detects errors while other approaches can detect and correct erros.","different NN composition architectures:
CNN
Deep CNN
Bi-RNN
Deep Bi-RNN
Bi-LSTM
Deep Bi-LSTM","Among the different architectural NN, Bi-LSTM has the highest F0.5 (41.1) FCE-test. This score increase to 64.3 when additionally trained on all datasets (NUCLE, IELTS, CPE, FCE, CAE). Besides, CRF has the lowest F0.5 (25.9) compared to different NN models. 


Compared to CAMB, CUUI, AMU and (P1+P2+S1+S2), Bi-LSTM trained on full dataset has the highest F0.5 score (34.3 ad 44.0) on the two official annotations for CONLL-14 dataset, while Bi-LSTM trained on FCE-public only has the least score (16.4 and 23.9)

For essay scoring, (SAT + Bi-LSTM (full)) (78.0 and 79.9)  improves SAT (75.1 and 76.0) on Pearson’s correlation r and Spearman’s correlation ρ, and outperforms  human annotators (79.2) by less than1% on Spearman’s correlation ρ.

",,"Precision
Recall
F0.5

for scoring essays: Pearson’s correlation r and Spearman’s correlation ρ ",,10,1.0,1.0,2.0,1.0,1.0,2.0,2.0,2,0.0,2.0,,"they compare the publicly available results on CONLL-14 with Bi-LSTM  trained on FCE-public as well as Bi-LSTM trained on all available 6 datasets, so the latter is not a fair comparison?!",
Auto-EM: End-to-end Fuzzy Entity-Matching using Pre-trained Deep Models and Transfer Learning,Both,ACM WWW,conferencePaper,2019.0,,,tabular,entity matching / duplicate removal,,,PO,YES,,(1) Magellan (2) DeepMatcher,Magellan’s datasets,duplicates,-,see page,generally better,-,precision recall f1 score,,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,0.0,2.0,,-,https://github.com/henryzhao5852/AutoEM
Entity Matching with Transformer Architectures - A Step Forward in Data Integration,Academia,International Conference on Extending Database Technology,conferencePaper,2020.0,,,tabular,entity matching / duplicate removal,,,PO,YES,,Magellan and DeepMatcher,(1) Abt-Buy (2) iTunes-Amazon (3) Walmart-Amazon (4) DBLP-ACM (5) DBLP-Scholar,duplicates,-,transformers,significantly better,"worse than Magellan, better than deepmatcher",F1 score,,11,2.0,2.0,1.0,2.0,2.0,1.0,1.0,2,0.0,2.0,,-,https://github.com/brunnurs/entity-matching-transformer
Hierarchical matching network for heterogeneous entity resolution,Academia,IJCAI,conferencePaper,2021.0,,,tabular,entity matching / duplicate removal,,,PO,YES,,"Magellan, DeepMatcher, MPM, Seq2SeqMatcher",See paper,duplicates,-,NN with attention,Generally better,-,F1 score,,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,0.0,2.0,,-,
Generative Adversarial Active Learning for Unsupervised Outlier Detection,Academia,IEEE Trans. Knowl. Data Eng.,journalArticle,2019.0,,ML4DC,tabular,outliers detection,"Outlier detection is an important topic in machine learning and has been used in a wide range of applications. In this paper, we approach outlier detection as a binary-classification issue by sampling potential outliers from a uniform reference distribution. However, due to the sparsity of data in high-dimensional space, a limited number of potential outliers may fail to provide sufficient information to assist the classifier in describing a boundary that can separate outliers from normal data effectively. To address this, we propose a novel Single-Objective Generative Adversarial Active Learning (SO-GAAL) method for outlier detection, which can directly generate informative potential outliers based on the mini-max game between a generator and a discriminator. Moreover, to prevent the generator from falling into the mode collapsing problem, the stop node of training should be determined when SO-GAAL is able to provide sufficient information. But without any prior information, it is extremely difficult for SO-GAAL. Therefore, we expand the network structure of SO-GAAL from a single generator to multiple generators with different objectives (MO-GAAL), which can generate a reasonable reference distribution for the whole dataset. We empirically compare the proposed approach with several state-of-the-art outlier detection methods on both synthetic and real-world datasets. The results show that MO-GAAL outperforms its competitors in the majority of cases, especially for datasets with various cluster types or high irrelevant variable ratio. The experiment codes are available at: https://github.com/leibinghe/GAAL-based-outlier-detection.",https://ieeexplore.ieee.org/author/37577989000; https://ieeexplore.ieee.org/author/37088435805; https://ieeexplore.ieee.org/author/37087236305; https://ieeexplore.ieee.org/author/37085699174; https://ieeexplore.ieee.org/author/38570332800; https://ieeexplore.ieee.org/author/37406961300; https://ieeexplore.ieee.org/author/37086064412,,YES,https://doi.org/10.1109/TKDE.2019.2905606,"They can be divided into seven categories: (i) two density-based methods, LOF [18] and KDEOS [37]; (ii) two density estimators, GMM [11] and Parzen [17]; (iii) a typical distance-based approach, kNN [36]; (iv) an angle-based model, FastABOD [37]; (v) a cluster-based model, k-means; (vi) a popular one-class classification model, OC-SVM [34] and (vii) the Active-Outlier detection model, AO [24]",4 synthetic datasets and 14 real datasets,outliers,,NN,"Compared to several state-of-the-art outlier detection methods, MO-GAAL achieves the best average ranking on the real-world datasets, and shows strong robustness to varying parameters","Compared to several state-of-the-art outlier detection methods, MO-GAAL achieves the best average ranking on the real-world datasets, and shows strong robustness to varying parameters","ROC AUC
Friedman non-parametric statistical test 
runtime",,12,2.0,2.0,2.0,2.0,0.0,2.0,2.0,2,0.0,2.0,,,https://github.com/leibinghe/GAAL-based-outlier-detection
Outlier Detection in Heterogeneous Datasets using Automatic Tuple Expansion,Academia,Computer Science and Artificial Intelligence Laboratory,technical report,2016.0,,,tabular,outliers detection,,"Clement Pit--Claudel, Zelda Mariet, Rachael Harding, and Sam Madden",PO,YES,,-,"Synthetic datasets, CSAIL Directory, Intel lab data, ",,-,"Gaussian modeling, GMM",-,linear complexity,accuracy,,11,2.0,2.0,1.0,2.0,0.0,2.0,2.0,1,0.0,1.0,,,https://github.com/cpitclaudel/dBoost
